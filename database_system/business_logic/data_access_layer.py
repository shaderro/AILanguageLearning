"""
æ•°æ®è®¿é—®å±‚ (DAL) - ç»Ÿä¸€ç®¡ç†å™¨æ¨¡å¼ï¼Œæ”¯æŒ JSON â†’ DB é€æ­¥è¿ç§»
"""
from typing import List, Optional, Dict, Any
from sqlalchemy.orm import Session
from .models import VocabExpression, GrammarRule, User
from .crud import (
    VocabCRUD, GrammarCRUD, TextCRUD, TokenCRUD, 
    AskedTokenCRUD, StatsCRUD, UserCRUD
)
from .crud.notation_crud import VocabNotationCRUD, GrammarNotationCRUD


class VocabDataAccessLayer:
    """è¯æ±‡æ•°æ®è®¿é—®å±‚"""
    
    def __init__(self, session: Session):
        self.session = session
        self._crud = VocabCRUD(session)
    
    def get_vocab(self, vocab_id: int) -> Optional[VocabExpression]:
        """æ ¹æ®IDèŽ·å–è¯æ±‡"""
        return self._crud.get_by_id(vocab_id)
    
    def find_vocab_by_body(self, vocab_body: str) -> Optional[VocabExpression]:
        """æ ¹æ®è¯æ±‡å†…å®¹æŸ¥æ‰¾"""
        return self._crud.get_by_body(vocab_body)
    
    def list_all_vocabs(self, skip: int = 0, limit: int = 100) -> List[VocabExpression]:
        """åˆ—å‡ºæ‰€æœ‰è¯æ±‡"""
        return self._crud.get_all(skip, limit)
    
    def add_vocab(self, vocab_body: str, explanation: str, 
                  source: str = "auto", is_starred: bool = False, user_id: int = None,
                  language: str = None) -> VocabExpression:
        """æ·»åŠ æ–°è¯æ±‡ï¼ˆå¦‚æžœå·²å­˜åœ¨åˆ™è¿”å›žçŽ°æœ‰è®°å½•ï¼‰"""
        # ðŸ”§ ä½¿ç”¨ get_or_create é€»è¾‘ï¼šå¦‚æžœå·²å­˜åœ¨åˆ™è¿”å›žï¼Œä¸å­˜åœ¨åˆ™åˆ›å»º
        return self._crud.get_or_create(vocab_body, explanation, source, is_starred, user_id, language)
    
    def get_vocab_with_examples(self, vocab_id: int) -> Optional[Dict[str, Any]]:
        """èŽ·å–è¯æ±‡åŠå…¶ä¾‹å¥"""
        vocab = self.get_vocab(vocab_id)
        if not vocab:
            return None
        
        return {
            "vocab_id": vocab.vocab_id,
            "vocab_body": vocab.vocab_body,
            "explanation": vocab.explanation,
            "source": vocab.source.value,
            "is_starred": vocab.is_starred,
            "examples": [
                {
                    "example_id": ex.example_id,
                    "text_id": ex.text_id,
                    "sentence_id": ex.sentence_id,
                    "context_explanation": ex.context_explanation,
                    "token_indices": ex.token_indices
                }
                for ex in vocab.examples
            ]
        }
    
    def search_vocabs(self, keyword: str) -> List[VocabExpression]:
        """æœç´¢è¯æ±‡"""
        return self._crud.search(keyword)
    
    def get_starred_vocabs(self) -> List[VocabExpression]:
        """èŽ·å–æ”¶è—çš„è¯æ±‡"""
        return self._crud.get_starred()
    
    def update_vocab(self, vocab_id: int, **kwargs) -> Optional[VocabExpression]:
        """æ›´æ–°è¯æ±‡"""
        return self._crud.update(vocab_id, **kwargs)
    
    def delete_vocab(self, vocab_id: int) -> bool:
        """åˆ é™¤è¯æ±‡"""
        return self._crud.delete(vocab_id)


class GrammarDataAccessLayer:
    """è¯­æ³•è§„åˆ™æ•°æ®è®¿é—®å±‚"""
    
    def __init__(self, session: Session):
        self.session = session
        self._crud = GrammarCRUD(session)
    
    def get_grammar(self, rule_id: int) -> Optional[GrammarRule]:
        """æ ¹æ®IDèŽ·å–è¯­æ³•è§„åˆ™"""
        return self._crud.get_by_id(rule_id)
    
    def find_grammar_by_name(self, rule_name: str) -> Optional[GrammarRule]:
        """æ ¹æ®åç§°æŸ¥æ‰¾è¯­æ³•è§„åˆ™"""
        return self._crud.get_by_name(rule_name)
    
    def list_all_grammar_rules(self, skip: int = 0, limit: int = 100) -> List[GrammarRule]:
        """åˆ—å‡ºæ‰€æœ‰è¯­æ³•è§„åˆ™"""
        return self._crud.get_all(skip, limit)
    
    def add_grammar_rule(self, rule_name: str, rule_summary: str,
                        source: str = "auto", is_starred: bool = False, user_id: int = None,
                        language: str = None) -> GrammarRule:
        """æ·»åŠ æ–°è¯­æ³•è§„åˆ™ï¼ˆå¦‚æžœå·²å­˜åœ¨åˆ™è¿”å›žçŽ°æœ‰è®°å½•ï¼‰"""
        # ðŸ”§ ä½¿ç”¨ get_or_create é€»è¾‘ï¼šå¦‚æžœå·²å­˜åœ¨åˆ™è¿”å›žï¼Œä¸å­˜åœ¨åˆ™åˆ›å»º
        return self._crud.get_or_create(rule_name, rule_summary, source, is_starred, user_id, language)
    
    def search_grammar_rules(self, keyword: str) -> List[GrammarRule]:
        """æœç´¢è¯­æ³•è§„åˆ™"""
        return self._crud.search(keyword)
    
    def get_starred_grammar_rules(self) -> List[GrammarRule]:
        """èŽ·å–æ”¶è—çš„è¯­æ³•è§„åˆ™"""
        return self._crud.get_starred()
    
    def update_grammar_rule(self, rule_id: int, **kwargs) -> Optional[GrammarRule]:
        """æ›´æ–°è¯­æ³•è§„åˆ™"""
        return self._crud.update(rule_id, **kwargs)
    
    def delete_grammar_rule(self, rule_id: int) -> bool:
        """åˆ é™¤è¯­æ³•è§„åˆ™"""
        return self._crud.delete(rule_id)


class TextDataAccessLayer:
    """æ–‡ç« æ•°æ®è®¿é—®å±‚"""
    
    def __init__(self, session: Session):
        self.session = session
        self._crud = TextCRUD(session)
    
    def create_text(self, text_title: str, user_id: int = None, language: str = None, processing_status: str = 'completed'):
        """åˆ›å»ºæ–‡ç« """
        return self._crud.create_text(text_title, user_id, language, processing_status)
    
    def get_text_by_id(self, text_id: int):
        """æ ¹æ®IDèŽ·å–æ–‡ç« """
        return self._crud.get_text_by_id(text_id)
    
    def get_all_texts(self, user_id: int = None):
        """èŽ·å–æ‰€æœ‰æ–‡ç« ï¼ˆå¯é€‰ç”¨æˆ·è¿‡æ»¤ï¼‰"""
        return self._crud.get_all_texts(user_id=user_id)
    
    def search_texts(self, keyword: str, user_id: int = None):
        """æœç´¢æ–‡ç« ï¼ˆå¯é€‰ç”¨æˆ·è¿‡æ»¤ï¼‰"""
        return self._crud.search_texts(keyword, user_id=user_id)
    
    def create_sentence(
        self,
        text_id: int,
        sentence_id: int,
        sentence_body: str,
        difficulty_level: Optional[str] = None,
        paragraph_id: Optional[int] = None,
        is_new_paragraph: Optional[bool] = None,
    ):
        """åˆ›å»ºå¥å­ï¼ˆæ”¯æŒæ®µè½ä¿¡æ¯ï¼‰"""
        return self._crud.create_sentence(
            text_id,
            sentence_id,
            sentence_body,
            difficulty_level=difficulty_level,
            paragraph_id=paragraph_id,
            is_new_paragraph=is_new_paragraph,
        )
    
    def get_sentences_by_text(self, text_id: int):
        """èŽ·å–æ–‡ç« çš„æ‰€æœ‰å¥å­"""
        return self._crud.get_sentences_by_text(text_id)
    
    def get_sentence_by_id(self, text_id: int, sentence_id: int):
        """æ ¹æ®IDèŽ·å–å¥å­"""
        return self._crud.get_sentence_by_id(text_id, sentence_id)
    
    def update_text(self, text_id: int, text_title: str = None, language: str = None, processing_status: str = None):
        """æ›´æ–°æ–‡ç« """
        return self._crud.update_text(text_id, text_title, language, processing_status)
    
    def delete_text(self, text_id: int) -> bool:
        """åˆ é™¤æ–‡ç« """
        return self._crud.delete_text(text_id)


class TokenDataAccessLayer:
    """è¯æ±‡æ ‡è®°æ•°æ®è®¿é—®å±‚"""
    
    def __init__(self, session: Session):
        self.session = session
        self._crud = TokenCRUD(session)
    
    def create_token(self, text_id: int, sentence_id: int, token_body: str,
                    token_type: str, **kwargs):
        """åˆ›å»ºè¯æ±‡æ ‡è®°"""
        return self._crud.create(text_id, sentence_id, token_body, token_type, **kwargs)
    
    def get_tokens_by_sentence(self, text_id: int, sentence_id: int):
        """èŽ·å–å¥å­çš„æ‰€æœ‰è¯æ±‡æ ‡è®°"""
        return self._crud.get_tokens_by_sentence(text_id, sentence_id)
    
    def get_tokens_by_vocab(self, vocab_id: int):
        """èŽ·å–å…³è”åˆ°ç‰¹å®šè¯æ±‡çš„æ‰€æœ‰æ ‡è®°"""
        return self._crud.get_tokens_by_vocab(vocab_id)


class AskedTokenDataAccessLayer:
    """å·²æé—®Tokenæ•°æ®è®¿é—®å±‚"""
    
    def __init__(self, session: Session):
        self.session = session
        self._crud = AskedTokenCRUD(session)
    
    def create_asked_token(self, user_id: str, text_id: int, 
                          sentence_id: int, sentence_token_id: Optional[int] = None,
                          type: str = 'token'):
        """
        åˆ›å»ºå·²æé—®tokenè®°å½•
        
        Args:
            user_id: ç”¨æˆ·ID
            text_id: æ–‡ç« ID
            sentence_id: å¥å­ID
            sentence_token_id: Token IDï¼ˆå¯é€‰ï¼‰
            type: æ ‡è®°ç±»åž‹ï¼Œ'token' æˆ– 'sentence'ï¼Œé»˜è®¤ 'token'
        """
        return self._crud.create(user_id, text_id, sentence_id, sentence_token_id, type)
    
    def get_asked_token(self, user_id: str, text_id: int, 
                        sentence_id: int, sentence_token_id: Optional[int] = None,
                        type: Optional[str] = None):
        """
        èŽ·å–æŒ‡å®šçš„å·²æé—®tokenè®°å½•
        
        Args:
            user_id: ç”¨æˆ·ID
            text_id: æ–‡ç« ID
            sentence_id: å¥å­ID
            sentence_token_id: Token IDï¼ˆå¯é€‰ï¼‰
            type: æ ‡è®°ç±»åž‹ï¼ˆå¯é€‰ï¼‰
        """
        return self._crud.get(user_id, text_id, sentence_id, sentence_token_id, type)
    
    def get_asked_tokens_for_article(self, text_id: int):
        """èŽ·å–æŒ‡å®šæ–‡ç« çš„æ‰€æœ‰å·²æé—®tokenè®°å½•"""
        return self._crud.get_for_article(text_id)
    
    def get_asked_tokens_for_user_article(self, user_id: str, text_id: int):
        """èŽ·å–æŒ‡å®šç”¨æˆ·åœ¨æŒ‡å®šæ–‡ç« çš„å·²æé—®tokenè®°å½•"""
        return self._crud.get_for_user_article(user_id, text_id)
    
    def delete_asked_token(self, user_id: str, text_id: int, 
                           sentence_id: int, sentence_token_id: Optional[int] = None,
                           type: Optional[str] = None) -> bool:
        """
        åˆ é™¤å·²æé—®tokenè®°å½•
        
        Args:
            user_id: ç”¨æˆ·ID
            text_id: æ–‡ç« ID
            sentence_id: å¥å­ID
            sentence_token_id: Token IDï¼ˆå¯é€‰ï¼‰
            type: æ ‡è®°ç±»åž‹ï¼ˆå¯é€‰ï¼‰
        """
        return self._crud.delete(user_id, text_id, sentence_id, sentence_token_id, type)


class StatsDataAccessLayer:
    """ç»Ÿè®¡æŸ¥è¯¢æ•°æ®è®¿é—®å±‚"""
    
    def __init__(self, session: Session):
        self.session = session
        self._crud = StatsCRUD(session)
    
    def get_vocab_stats(self) -> Dict:
        """èŽ·å–è¯æ±‡ç»Ÿè®¡ä¿¡æ¯"""
        return self._crud.get_vocab_stats()
    
    def get_grammar_stats(self) -> Dict:
        """èŽ·å–è¯­æ³•è§„åˆ™ç»Ÿè®¡ä¿¡æ¯"""
        return self._crud.get_grammar_stats()
    
    def get_learning_progress(self) -> Dict:
        """èŽ·å–å­¦ä¹ è¿›åº¦ç»Ÿè®¡"""
        return self._crud.get_learning_progress()
    
    def get_asked_token_stats(self) -> Dict:
        """èŽ·å–å·²æé—®tokenç»Ÿè®¡ä¿¡æ¯"""
        return self._crud.get_asked_token_stats()


class DataAccessManager:
    """æ•°æ®è®¿é—®ç®¡ç†å™¨ - ç»Ÿä¸€å…¥å£ï¼Œä»¿ç…§ DatabaseManager æ¨¡å¼"""
    
    def __init__(self, session: Session):
        self.session = session
        self.vocab = VocabDataAccessLayer(session)
        self.grammar = GrammarDataAccessLayer(session)
        self.text = TextDataAccessLayer(session)
        self.token = TokenDataAccessLayer(session)
        self.asked_token = AskedTokenDataAccessLayer(session)
        self.stats = StatsDataAccessLayer(session)
        # æ–°å¢žï¼šNotation CRUD
        self.vocab_notation_crud = VocabNotationCRUD(session)
        self.grammar_notation_crud = GrammarNotationCRUD(session)
    
    def close(self):
        """å…³é—­ä¼šè¯"""
        self.session.close()
    
    def commit(self):
        """æäº¤äº‹åŠ¡"""
        self.session.commit()
    
    def rollback(self):
        """å›žæ»šäº‹åŠ¡"""
        self.session.rollback()


class UserDataAccessLayer:
    """ç”¨æˆ·æ•°æ®è®¿é—®å±‚"""
    
    def __init__(self, session: Session):
        self.session = session
        self._crud = UserCRUD(session)
    
    def get_user(self, user_id: int) -> Optional[User]:
        """æ ¹æ®IDèŽ·å–ç”¨æˆ·"""
        return self._crud.get_by_id(user_id)
    
    def create_user(self, password: str) -> User:
        """åˆ›å»ºæ–°ç”¨æˆ·"""
        return self._crud.create(password)
    
    def list_users(self, skip: int = 0, limit: int = 100) -> List[User]:
        """åˆ—å‡ºæ‰€æœ‰ç”¨æˆ·"""
        return self._crud.get_all(skip, limit)
    
    def update_user(self, user_id: int, **kwargs) -> Optional[User]:
        """æ›´æ–°ç”¨æˆ·"""
        return self._crud.update(user_id, **kwargs)
    
    def delete_user(self, user_id: int) -> bool:
        """åˆ é™¤ç”¨æˆ·"""
        return self._crud.delete(user_id)
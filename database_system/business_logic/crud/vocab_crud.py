"""
è¯æ±‡ç›¸å…³ CRUD æ“ä½œ
"""
from sqlalchemy.orm import Session
from sqlalchemy import or_
from typing import List, Optional
from ..models import VocabExpression, VocabExpressionExample, SourceType, LearnStatus


class VocabCRUD:
    """è¯æ±‡ CRUD æ“ä½œ"""
    
    def __init__(self, session: Session):
        self.session = session
    
    def _coerce_source(self, value: Optional[str]) -> SourceType:
        """è½¬æ¢æºç±»å‹"""
        if isinstance(value, SourceType):
            return value
        if value is None:
            return SourceType.AUTO
        try:
            return SourceType(value)
        except Exception:
            return SourceType.AUTO
    
    def _coerce_learn_status(self, value) -> LearnStatus:
        """è½¬æ¢å­¦ä¹ çŠ¶æ€"""
        if isinstance(value, LearnStatus):
            return value
        if value is None:
            return LearnStatus.NOT_MASTERED
        if isinstance(value, str):
            if value == 'mastered':
                return LearnStatus.MASTERED
            elif value == 'not_mastered':
                return LearnStatus.NOT_MASTERED
        try:
            return LearnStatus(value)
        except Exception:
            return LearnStatus.NOT_MASTERED
    
    def create(self, vocab_body: str, explanation: str, 
               source: str = "auto", is_starred: bool = False, user_id: int = None, 
               language: str = None) -> VocabExpression:
        """åˆ›å»ºè¯æ±‡"""
        vocab = VocabExpression(
            vocab_body=vocab_body,
            explanation=explanation,
            language=language,
            source=self._coerce_source(source),
            is_starred=is_starred,
            user_id=user_id
        )
        self.session.add(vocab)
        self.session.commit()
        self.session.refresh(vocab)
        return vocab
    
    def get_or_create(self, vocab_body: str, explanation: str,
                      source: str = "auto", is_starred: bool = False, user_id: int = None,
                      language: str = None) -> VocabExpression:
        """è·å–æˆ–åˆ›å»ºè¯æ±‡ï¼ˆå¦‚æœå·²å­˜åœ¨åˆ™è¿”å›ç°æœ‰è®°å½•ï¼Œä¸å­˜åœ¨åˆ™åˆ›å»ºï¼‰"""
        # ğŸ”§ å¦‚æœuser_idä¸ºNoneï¼Œç›´æ¥åˆ›å»ºï¼ˆå‘åå…¼å®¹ï¼‰
        if user_id is None:
            return self.create(vocab_body, explanation, source, is_starred, user_id, language)
        
        # ğŸ”§ æŸ¥æ‰¾å·²å­˜åœ¨çš„è¯æ±‡ï¼ˆæŒ‰user_idå’Œvocab_bodyï¼‰
        existing = self.session.query(VocabExpression).filter(
            VocabExpression.vocab_body == vocab_body,
            VocabExpression.user_id == user_id
        ).first()
        if existing:
            # ğŸ”§ å¦‚æœå·²å­˜åœ¨ï¼Œæ›´æ–°languageå­—æ®µï¼ˆå¦‚æœæä¾›äº†languageä¸”ç°æœ‰è®°å½•çš„languageä¸ºNoneï¼‰
            if language and existing.language is None:
                existing.language = language
                self.session.commit()
                self.session.refresh(existing)
                print(f"ğŸ” [DEBUG] æ›´æ–°å·²å­˜åœ¨è¯æ±‡çš„language: {vocab_body} -> {language}")
            return existing
        # ğŸ”§ ä¸å­˜åœ¨åˆ™åˆ›å»ºæ–°è¯æ±‡
        return self.create(vocab_body, explanation, source, is_starred, user_id, language)
    
    def get_by_id(self, vocab_id: int) -> Optional[VocabExpression]:
        """æ ¹æ®IDè·å–è¯æ±‡"""
        return self.session.query(VocabExpression).filter(
            VocabExpression.vocab_id == vocab_id
        ).first()
    
    def get_by_body(self, vocab_body: str) -> Optional[VocabExpression]:
        """æ ¹æ®è¯æ±‡å†…å®¹è·å–"""
        return self.session.query(VocabExpression).filter(
            VocabExpression.vocab_body == vocab_body
        ).first()
    
    def get_all(self, skip: int = 0, limit: int = 100) -> List[VocabExpression]:
        """è·å–æ‰€æœ‰è¯æ±‡"""
        return self.session.query(VocabExpression).offset(skip).limit(limit).all()
    
    def get_starred(self) -> List[VocabExpression]:
        """è·å–æ”¶è—çš„è¯æ±‡"""
        return self.session.query(VocabExpression).filter(
            VocabExpression.is_starred == True
        ).all()
    
    def search(self, keyword: str) -> List[VocabExpression]:
        """æœç´¢è¯æ±‡"""
        return self.session.query(VocabExpression).filter(
            or_(
                VocabExpression.vocab_body.contains(keyword),
                VocabExpression.explanation.contains(keyword)
            )
        ).all()
    
    def update(self, vocab_id: int, **kwargs) -> Optional[VocabExpression]:
        """æ›´æ–°è¯æ±‡"""
        vocab = self.get_by_id(vocab_id)
        if vocab:
            for key, value in kwargs.items():
                if key == "source":
                    value = self._coerce_source(value)
                elif key == "learn_status":
                    value = self._coerce_learn_status(value)
                if hasattr(vocab, key):
                    setattr(vocab, key, value)
            self.session.commit()
            self.session.refresh(vocab)
        return vocab
    
    def delete(self, vocab_id: int) -> bool:
        """åˆ é™¤è¯æ±‡"""
        vocab = self.get_by_id(vocab_id)
        if vocab:
            self.session.delete(vocab)
            self.session.commit()
            return True
        return False
    
    def create_example(self, *, vocab_id: int, text_id: int,
                      sentence_id: int, context_explanation: Optional[str] = None,
                      token_indices: Optional[list] = None) -> VocabExpressionExample:
        """
        åˆ›å»ºè¯æ±‡ä¾‹å¥ï¼ˆå¸¦æŸ¥é‡é€»è¾‘ï¼Œé¿å…é‡å¤åˆ›å»ºï¼‰
        
        å¦‚æœå·²å­˜åœ¨ç›¸åŒçš„ exampleï¼ˆåŸºäº vocab_id, text_id, sentence_id, token_indicesï¼‰ï¼Œ
        åˆ™è¿”å›ç°æœ‰çš„ exampleï¼Œå¦åˆ™åˆ›å»ºæ–°çš„ã€‚
        """
        # ğŸ”§ æŸ¥é‡ï¼šæ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒçš„ example
        # å…ˆåŸºäº (vocab_id, text_id, sentence_id) æŸ¥è¯¢
        existing_examples = self.session.query(VocabExpressionExample).filter(
            VocabExpressionExample.vocab_id == vocab_id,
            VocabExpressionExample.text_id == text_id,
            VocabExpressionExample.sentence_id == sentence_id
        ).all()
        
        # å¦‚æœæœ‰åŒ¹é…çš„è®°å½•ï¼Œæ¯”è¾ƒ token_indices
        normalized_token_indices = sorted(token_indices or [])
        for existing in existing_examples:
            existing_indices = sorted(existing.token_indices or [])
            # å¦‚æœ token_indices ç›¸åŒï¼ˆæˆ–éƒ½ä¸ºç©ºï¼‰ï¼Œè®¤ä¸ºæ˜¯é‡å¤çš„
            if existing_indices == normalized_token_indices:
                print(f"ğŸ” [VocabCRUD] å‘ç°å·²å­˜åœ¨çš„ example: vocab_id={vocab_id}, text_id={text_id}, sentence_id={sentence_id}, token_indices={normalized_token_indices}")
                return existing
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°é‡å¤çš„ï¼Œåˆ›å»ºæ–°çš„
        example = VocabExpressionExample(
            vocab_id=vocab_id,
            text_id=text_id,
            sentence_id=sentence_id,
            context_explanation=context_explanation,
            token_indices=token_indices or [],
        )
        self.session.add(example)
        self.session.commit()
        self.session.refresh(example)
        print(f"âœ… [VocabCRUD] åˆ›å»ºæ–° example: vocab_id={vocab_id}, text_id={text_id}, sentence_id={sentence_id}, token_indices={normalized_token_indices}")
        return example

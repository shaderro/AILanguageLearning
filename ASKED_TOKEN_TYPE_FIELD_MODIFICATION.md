# Asked Token Type å­—æ®µä¿®æ”¹æ€»ç»“

## ğŸ“‹ ä¿®æ”¹æ¦‚è¿°

ä¸º `AskedToken` æ•°æ®ç»“æ„æ·»åŠ  `type` å­—æ®µï¼Œç”¨äºåŒºåˆ†æ ‡è®°çš„æ˜¯**å•è¯ï¼ˆtokenï¼‰**è¿˜æ˜¯**å¥å­ï¼ˆsentenceï¼‰**çš„è¯­æ³•çŸ¥è¯†ç‚¹ã€‚

### éœ€æ±‚èƒŒæ™¯

- **åŸæœ‰é€»è¾‘**: AskedToken åªèƒ½æ ‡è®°å•è¯ï¼ˆéœ€è¦ `sentence_token_id`ï¼‰
- **æ–°å¢éœ€æ±‚**: éœ€è¦æ”¯æŒæ ‡è®°æ•´ä¸ªå¥å­çš„è¯­æ³•çŸ¥è¯†ç‚¹
- **å‘åå…¼å®¹**: ç°æœ‰æ•°æ®ä¸å—å½±å“ï¼Œé»˜è®¤ä¸º `type='token'`

---

## ğŸ”§ ä¿®æ”¹è¯¦æƒ…

### 1. æ•°æ®åº“æ¨¡å‹ä¿®æ”¹

**æ–‡ä»¶**: `database_system/business_logic/models.py`

#### æ–°å¢æšä¸¾ç±»å‹
```python
class AskedTokenType(enum.Enum):
    TOKEN = 'token'      # æ ‡è®°çš„æ˜¯å•è¯ï¼ˆéœ€è¦ sentence_token_idï¼‰
    SENTENCE = 'sentence'  # æ ‡è®°çš„æ˜¯å¥å­ï¼ˆsentence_token_id å¯ä¸ºç©ºï¼‰
```

#### ä¿®æ”¹ AskedToken æ¨¡å‹
- **æ–°å¢å­—æ®µ**: `type` (Enum(AskedTokenType), é»˜è®¤å€¼='token')
- **ä¿®æ”¹å­—æ®µ**: `sentence_token_id` (nullable=Trueï¼ŒåŸä¸º nullable=False)
- **ä¿®æ”¹çº¦æŸ**: UniqueConstraint å¢åŠ  `type` å­—æ®µ

```python
class AskedToken(Base):
    __tablename__ = 'asked_tokens'
    
    id = Column(Integer, primary_key=True, autoincrement=True)
    user_id = Column(String(255), nullable=False)
    text_id = Column(Integer, ForeignKey('original_texts.text_id', ondelete='CASCADE'), nullable=False)
    sentence_id = Column(Integer, nullable=False)
    sentence_token_id = Column(Integer, nullable=True)  # âœ… æ”¹ä¸ºå¯ç©º
    type = Column(Enum(AskedTokenType), default=AskedTokenType.TOKEN, nullable=False)  # âœ… æ–°å¢
    created_at = Column(DateTime, default=datetime.now, nullable=False)
    
    __table_args__ = (
        # ... çœç•¥ ...
        UniqueConstraint('user_id', 'text_id', 'sentence_id', 'sentence_token_id', 'type', ...)  # âœ… æ–°å¢ type
    )
```

---

### 2. æ•°æ®ç±» (DTO) ä¿®æ”¹

#### æ–‡ä»¶ 1: `backend/data_managers/data_classes_new.py`
```python
@dataclass
class AskedToken:
    """å·²æé—®çš„ token è®°å½•"""
    user_id: str
    text_id: int
    sentence_id: int
    sentence_token_id: Optional[int] = None  # âœ… æ”¹ä¸ºå¯é€‰
    type: Literal["token", "sentence"] = "token"  # âœ… æ–°å¢
```

#### æ–‡ä»¶ 2: `backend/data_managers/data_classes.py`
```python
@dataclass
class AskedToken:
    """å·²æé—®çš„ token è®°å½•"""
    user_id: str
    text_id: int
    sentence_id: int
    sentence_token_id: Optional[int] = None  # âœ… æ”¹ä¸ºå¯é€‰
    type: str = "token"  # âœ… æ–°å¢
    asked_at: Optional[int] = None
```

---

### 3. CRUD æ“ä½œä¿®æ”¹

**æ–‡ä»¶**: `database_system/business_logic/crud/asked_token_crud.py`

#### create æ–¹æ³•
```python
def create(self, user_id: str, text_id: int, 
           sentence_id: int, sentence_token_id: Optional[int] = None,
           type: str = 'token') -> AskedToken:
    """
    åˆ›å»ºå·²æé—®tokenè®°å½•
    
    å‘åå…¼å®¹é€»è¾‘ï¼š
    - å¦‚æœ type æœªæŒ‡å®šä½† sentence_token_id ä¸ä¸ºç©ºï¼Œåˆ™é»˜è®¤ type='token'
    - å¦‚æœ type='sentence'ï¼Œsentence_token_id å¯ä»¥ä¸º None
    """
    # å‘åå…¼å®¹ï¼šå¦‚æœ type æœªæ˜ç¡®æŒ‡å®šä¸” sentence_token_id ä¸ä¸ºç©ºï¼Œé»˜è®¤ä¸º 'token'
    if type is None and sentence_token_id is not None:
        type = 'token'
    
    asked_type = AskedTokenType.TOKEN if type == 'token' else AskedTokenType.SENTENCE
    
    asked_token = AskedToken(
        user_id=user_id,
        text_id=text_id,
        sentence_id=sentence_id,
        sentence_token_id=sentence_token_id,
        type=asked_type
    )
    # ... ä¿å­˜é€»è¾‘ ...
```

#### get æ–¹æ³•
```python
def get(self, user_id: str, text_id: int, 
        sentence_id: int, sentence_token_id: Optional[int] = None,
        type: Optional[str] = None) -> Optional[AskedToken]:
    """æ”¯æŒæ ¹æ® type æŸ¥è¯¢"""
    conditions = [
        AskedToken.user_id == user_id,
        AskedToken.text_id == text_id,
        AskedToken.sentence_id == sentence_id
    ]
    
    if sentence_token_id is not None:
        conditions.append(AskedToken.sentence_token_id == sentence_token_id)
    
    if type is not None:
        asked_type = AskedTokenType.TOKEN if type == 'token' else AskedTokenType.SENTENCE
        conditions.append(AskedToken.type == asked_type)
    
    return self.session.query(AskedToken).filter(and_(*conditions)).first()
```

#### delete æ–¹æ³•
```python
def delete(self, user_id: str, text_id: int, 
           sentence_id: int, sentence_token_id: Optional[int] = None,
           type: Optional[str] = None) -> bool:
    """æ”¯æŒæ ¹æ® type åˆ é™¤"""
    asked_token = self.get(user_id, text_id, sentence_id, sentence_token_id, type)
    if asked_token:
        self.session.delete(asked_token)
        self.session.commit()
        return True
    return False
```

---

### 4. æ•°æ®è®¿é—®å±‚ä¿®æ”¹

**æ–‡ä»¶**: `database_system/business_logic/data_access_layer.py`

æ‰€æœ‰æ–¹æ³•ç­¾åéƒ½æ·»åŠ äº† `type` å‚æ•°æ”¯æŒï¼š

```python
class AskedTokenDataAccessLayer:
    def create_asked_token(self, user_id: str, text_id: int, 
                          sentence_id: int, sentence_token_id: Optional[int] = None,
                          type: str = 'token'):
        """åˆ›å»ºå·²æé—®tokenè®°å½•"""
        return self._crud.create(user_id, text_id, sentence_id, sentence_token_id, type)
    
    def get_asked_token(self, user_id: str, text_id: int, 
                        sentence_id: int, sentence_token_id: Optional[int] = None,
                        type: Optional[str] = None):
        """è·å–æŒ‡å®šçš„å·²æé—®tokenè®°å½•"""
        return self._crud.get(user_id, text_id, sentence_id, sentence_token_id, type)
    
    def delete_asked_token(self, user_id: str, text_id: int, 
                           sentence_id: int, sentence_token_id: Optional[int] = None,
                           type: Optional[str] = None) -> bool:
        """åˆ é™¤å·²æé—®tokenè®°å½•"""
        return self._crud.delete(user_id, text_id, sentence_id, sentence_token_id, type)
```

---

### 5. ç®¡ç†å™¨ä¿®æ”¹

**æ–‡ä»¶**: `database_system/business_logic/managers/asked_token_manager.py`

```python
class AskedTokenManager:
    def mark_token_as_asked(self, user_id: str, text_id: int, 
                           sentence_id: int, sentence_token_id: Optional[int] = None,
                           type: str = 'token') -> AskedToken:
        """æ ‡è®°tokenæˆ–sentenceä¸ºå·²æé—®"""
        return self.dal.create_asked_token(user_id, text_id, sentence_id, sentence_token_id, type)
    
    def is_token_asked(self, user_id: str, text_id: int, 
                      sentence_id: int, sentence_token_id: Optional[int] = None,
                      type: Optional[str] = None) -> bool:
        """æ£€æŸ¥tokenæˆ–sentenceæ˜¯å¦å·²è¢«æé—®"""
        return self.dal.get_asked_token(user_id, text_id, sentence_id, sentence_token_id, type) is not None
    
    def unmark_token_as_asked(self, user_id: str, text_id: int, 
                             sentence_id: int, sentence_token_id: Optional[int] = None,
                             type: Optional[str] = None) -> bool:
        """å–æ¶ˆæ ‡è®°tokenæˆ–sentenceä¸ºå·²æé—®"""
        return self.dal.delete_asked_token(user_id, text_id, sentence_id, sentence_token_id, type)
```

---

### 6. API è·¯ç”±ä¿®æ”¹

**æ–‡ä»¶**: `server.py`

#### POST /api/user/asked-tokens
```python
@app.post("/api/user/asked-tokens")
async def mark_token_asked(payload: dict):
    """
    æ ‡è®° token æˆ– sentence ä¸ºå·²æé—®
    
    æ”¯æŒä¸¤ç§ç±»å‹çš„æ ‡è®°ï¼š
    1. type='token': æ ‡è®°å•è¯ï¼ˆéœ€è¦ sentence_token_idï¼‰
    2. type='sentence': æ ‡è®°å¥å­ï¼ˆsentence_token_id å¯é€‰ï¼‰
    
    å‘åå…¼å®¹ï¼šå¦‚æœ type æœªæŒ‡å®šä½† sentence_token_id å­˜åœ¨ï¼Œé»˜è®¤ä¸º 'token'
    """
    user_id = payload.get("user_id", "default_user")
    text_id = payload.get("text_id")
    sentence_id = payload.get("sentence_id")
    sentence_token_id = payload.get("sentence_token_id")
    type_param = payload.get("type", None)  # æ–°å¢ï¼šæ ‡è®°ç±»å‹
    
    # å‘åå…¼å®¹é€»è¾‘ï¼šå¦‚æœ type æœªæŒ‡å®šä½† sentence_token_id ä¸ä¸ºç©ºï¼Œé»˜è®¤ä¸º 'token'
    if type_param is None:
        if sentence_token_id is not None:
            type_param = "token"
        else:
            type_param = "sentence"
    
    # éªŒè¯ï¼šå¦‚æœæ˜¯ token ç±»å‹ï¼Œsentence_token_id å¿…é¡»æä¾›
    if type_param == "token" and sentence_token_id is None:
        return {"success": False, "error": "type='token' æ—¶ï¼Œsentence_token_id æ˜¯å¿…éœ€çš„"}
    
    # ... è°ƒç”¨ manager æ ‡è®° ...
```

---

### 7. æ—§ç®¡ç†å™¨ä¿®æ”¹ï¼ˆJSON æ¨¡å¼ï¼‰

**æ–‡ä»¶**: `backend/data_managers/asked_tokens_manager.py`

```python
class AskedTokensManager:
    def mark_token_asked(self, user_id: str, text_id: int, sentence_id: int, 
                        sentence_token_id: int = None, type: str = "token") -> bool:
        """
        æ ‡è®° token æˆ– sentence ä¸ºå·²æé—®
        
        å‘åå…¼å®¹ï¼šå¦‚æœ type æœªæŒ‡å®šä½† sentence_token_id ä¸ä¸ºç©ºï¼Œé»˜è®¤ä¸º 'token'
        """
        # å‘åå…¼å®¹é€»è¾‘
        if type is None and sentence_token_id is not None:
            type = "token"
        
        asked_token = AskedToken(
            user_id=user_id,
            text_id=text_id,
            sentence_id=sentence_id,
            sentence_token_id=sentence_token_id,
            type=type
        )
        
        if self.use_database:
            return self._mark_asked_database(asked_token)
        else:
            return self._mark_asked_json(asked_token)
```

#### æ•°æ®åº“æ¨¡å¼
```python
def _mark_asked_database(self, asked_token: AskedToken) -> bool:
    cursor.execute("""
        INSERT OR REPLACE INTO asked_tokens 
        (user_id, text_id, sentence_id, sentence_token_id, type)
        VALUES (?, ?, ?, ?, ?)
    """, (
        asked_token.user_id,
        asked_token.text_id,
        asked_token.sentence_id,
        asked_token.sentence_token_id,
        asked_token.type
    ))
```

#### JSON æ¨¡å¼
```python
def _mark_asked_json(self, asked_token: AskedToken) -> bool:
    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ï¼ˆéœ€è¦æ¯”è¾ƒ type å­—æ®µï¼‰
    for token_data in asked_tokens:
        if (token_data.get("text_id") == asked_token.text_id and
            token_data.get("sentence_id") == asked_token.sentence_id and
            token_data.get("sentence_token_id") == asked_token.sentence_token_id and
            token_data.get("type", "token") == asked_token.type):  # å‘åå…¼å®¹
            existing = True
            break
```

---

## ğŸ”„ æ•°æ®åº“è¿ç§»

### è¿ç§»è„šæœ¬

**æ–‡ä»¶**: `migrate_asked_tokens_add_type.py`

#### åŠŸèƒ½
1. å¤‡ä»½ç°æœ‰ `asked_tokens` è¡¨æ•°æ®
2. é‡å»ºè¡¨ç»“æ„ï¼ˆæ·»åŠ  `type` å­—æ®µï¼Œä¿®æ”¹ `sentence_token_id` ä¸ºå¯ç©ºï¼‰
3. æ¢å¤æ•°æ®ï¼Œæ‰€æœ‰ç°æœ‰è®°å½•è®¾ç½® `type='token'`
4. éªŒè¯è¿ç§»ç»“æœ

#### ä½¿ç”¨æ–¹æ³•
```bash
python migrate_asked_tokens_add_type.py
```

#### è¿ç§»å†…å®¹
- ä¸ºæ‰€æœ‰ç°æœ‰è®°å½•è®¾ç½® `type='token'`ï¼ˆå‘åå…¼å®¹ï¼‰
- `sentence_token_id` ä¿æŒåŸå€¼ä¸å˜
- ä¿ç•™ `created_at` æ—¶é—´æˆ³

---

## ğŸ“ ä½¿ç”¨ç¤ºä¾‹

### 1. æ ‡è®°å•è¯ï¼ˆTokenï¼‰

```python
# API è¯·æ±‚
POST /api/user/asked-tokens
{
  "user_id": "user123",
  "text_id": 1,
  "sentence_id": 2,
  "sentence_token_id": 5,
  "type": "token"  # æˆ–è€…ä¸ä¼ ï¼Œå‘åå…¼å®¹
}
```

```python
# Python ä»£ç 
manager.mark_token_as_asked(
    user_id="user123",
    text_id=1,
    sentence_id=2,
    sentence_token_id=5,
    type="token"
)
```

### 2. æ ‡è®°å¥å­ï¼ˆSentence/è¯­æ³•çŸ¥è¯†ç‚¹ï¼‰

```python
# API è¯·æ±‚
POST /api/user/asked-tokens
{
  "user_id": "user123",
  "text_id": 1,
  "sentence_id": 2,
  "type": "sentence"
  // sentence_token_id å¯ä»¥ä¸ä¼ æˆ–ä¼  null
}
```

```python
# Python ä»£ç 
manager.mark_token_as_asked(
    user_id="user123",
    text_id=1,
    sentence_id=2,
    sentence_token_id=None,  # æˆ–ä¸ä¼ 
    type="sentence"
)
```

### 3. å‘åå…¼å®¹ï¼ˆæ—§ä»£ç ï¼‰

```python
# æ—§ä»£ç ä»ç„¶æœ‰æ•ˆ
manager.mark_token_asked(
    user_id="user123",
    text_id=1,
    sentence_id=2,
    sentence_token_id=5
)
# è‡ªåŠ¨è¯†åˆ«ä¸º type="token"
```

---

## âœ… å‘åå…¼å®¹æ€§

### è‡ªåŠ¨è¯†åˆ«è§„åˆ™
1. **å¦‚æœ `type` æœªæŒ‡å®š ä¸” `sentence_token_id` ä¸ä¸ºç©º** â†’ é»˜è®¤ `type='token'`
2. **å¦‚æœ `type` æœªæŒ‡å®š ä¸” `sentence_token_id` ä¸ºç©º** â†’ é»˜è®¤ `type='sentence'`
3. **å¦‚æœ `type='token'` ä½† `sentence_token_id` ä¸ºç©º** â†’ æŠ¥é”™

### ç°æœ‰æ•°æ®
- æ‰€æœ‰ç°æœ‰æ•°æ®åœ¨è¿ç§»åè‡ªåŠ¨è®¾ç½®ä¸º `type='token'`
- ç°æœ‰ API è°ƒç”¨æ— éœ€ä¿®æ”¹ï¼Œè‡ªåŠ¨å‘åå…¼å®¹

---

## ğŸ¯ ä¿®æ”¹ç‚¹æ€»ç»“

### å¿…é¡»ä¿®æ”¹çš„æ–‡ä»¶ï¼ˆå…± 7 ä¸ªï¼‰

1. âœ… `database_system/business_logic/models.py` - æ•°æ®åº“æ¨¡å‹
2. âœ… `backend/data_managers/data_classes_new.py` - æ•°æ®ç±» (æ–°)
3. âœ… `backend/data_managers/data_classes.py` - æ•°æ®ç±» (æ—§)
4. âœ… `database_system/business_logic/crud/asked_token_crud.py` - CRUD æ“ä½œ
5. âœ… `database_system/business_logic/data_access_layer.py` - æ•°æ®è®¿é—®å±‚
6. âœ… `database_system/business_logic/managers/asked_token_manager.py` - ç®¡ç†å™¨
7. âœ… `server.py` - API è·¯ç”±

### å¯é€‰ä¿®æ”¹çš„æ–‡ä»¶ï¼ˆå‘åå…¼å®¹ï¼Œä½†å»ºè®®æ›´æ–°ï¼‰

8. âœ… `backend/data_managers/asked_tokens_manager.py` - æ—§ç®¡ç†å™¨ (JSONæ¨¡å¼)

### æ–°å¢æ–‡ä»¶

9. âœ… `migrate_asked_tokens_add_type.py` - æ•°æ®åº“è¿ç§»è„šæœ¬
10. âœ… `ASKED_TOKEN_TYPE_FIELD_MODIFICATION.md` - æœ¬æ–‡æ¡£

---

## ğŸš€ éƒ¨ç½²æ­¥éª¤

1. **å¤‡ä»½æ•°æ®åº“**
   ```bash
   cp database_system/data_storage/data/dev.db database_system/data_storage/data/dev.db.backup
   ```

2. **è¿è¡Œè¿ç§»è„šæœ¬**
   ```bash
   python migrate_asked_tokens_add_type.py
   ```

3. **éªŒè¯è¿ç§»ç»“æœ**
   - æ£€æŸ¥ `asked_tokens` è¡¨ç»“æ„
   - ç¡®è®¤æ‰€æœ‰è®°å½•çš„ `type` å­—æ®µä¸º 'token'

4. **æ›´æ–°ä»£ç **
   - æ‰€æœ‰ä¿®æ”¹å·²å®Œæˆï¼Œç›´æ¥éƒ¨ç½²å³å¯

5. **æµ‹è¯•**
   - æµ‹è¯•æ ‡è®°å•è¯åŠŸèƒ½ï¼ˆåŸæœ‰åŠŸèƒ½ï¼‰
   - æµ‹è¯•æ ‡è®°å¥å­åŠŸèƒ½ï¼ˆæ–°åŠŸèƒ½ï¼‰
   - éªŒè¯å‘åå…¼å®¹æ€§

---

## ğŸ“ æ³¨æ„äº‹é¡¹

1. **æ•°æ®åº“è¿ç§»**ï¼šè¿è¡Œè¿ç§»è„šæœ¬å‰è¯·åŠ¡å¿…å¤‡ä»½æ•°æ®åº“
2. **API å…¼å®¹æ€§**ï¼šæ—§çš„ API è°ƒç”¨ä»ç„¶æœ‰æ•ˆï¼Œæ— éœ€ä¿®æ”¹å‰ç«¯ä»£ç 
3. **ç±»å‹éªŒè¯**ï¼šæ–°ä»£ç ä¼šéªŒè¯ `type='token'` æ—¶ `sentence_token_id` å¿…é¡»å­˜åœ¨
4. **å”¯ä¸€çº¦æŸ**ï¼šåŒä¸€ç”¨æˆ·å¯ä»¥å¯¹åŒä¸€å¥å­æ—¢æ ‡è®°å•è¯ï¼Œåˆæ ‡è®°å¥å­ï¼ˆå› ä¸º type ä¸åŒï¼‰

---

## ğŸ“… ä¿®æ”¹æ—¥æœŸ

2025-10-16

---

**ä¿®æ”¹å®Œæˆï¼æ‰€æœ‰ä»£ç å·²æ›´æ–°ï¼Œæ•°æ®åº“è¿ç§»è„šæœ¬å·²å‡†å¤‡å°±ç»ªã€‚**



# Token ID ä½¿ç”¨åˆ†ææŠ¥å‘Š

## ğŸ“Š Token ID ç±»å‹å®šä¹‰

### Token æ•°æ®ç»“æ„ï¼ˆ`data_classes_new.py`ï¼‰

```python
@dataclass(frozen=True)
class Token:
    token_body: str
    token_type: Literal["text", "punctuation", "space"]
    global_token_id: Optional[int] = None      # å…¨æ–‡çº§åˆ« IDï¼ˆä»0å¼€å§‹ï¼‰
    sentence_token_id: Optional[int] = None    # å¥å­å†… IDï¼ˆä»1å¼€å§‹ï¼‰
    ...
```

### ç¤ºä¾‹æ•°æ®ï¼ˆ`hp1_processed_20250916_123831.json`ï¼‰

```json
{
  "token_body": "Mr",
  "token_type": "text",
  "global_token_id": 0,      // â† å…¨æ–‡ç¬¬1ä¸ªtoken
  "sentence_token_id": 1     // â† å¥å­å†…ç¬¬1ä¸ªtoken
}
```

---

## ğŸ¯ å„åŠŸèƒ½ä½¿ç”¨çš„ Token ID

### 1ï¸âƒ£ **Asked Tokensï¼ˆå·²æé—®æ ‡è®°ï¼‰** - ä½¿ç”¨ `sentence_token_id` âœ…

#### æ•°æ®ç»“æ„ï¼š
```python
@dataclass
class AskedToken:
    user_id: str
    text_id: int
    sentence_id: int
    sentence_token_id: Optional[int]  # â† ä½¿ç”¨å¥å†…ID
    type: Literal["token", "sentence"] = "token"
```

#### å­˜å‚¨é”®æ ¼å¼ï¼š
```
{text_id}:{sentence_id}:{sentence_token_id}
ä¾‹: "1:3:5"  // æ–‡ç« 1ï¼Œå¥å­3ï¼Œå¥å†…ç¬¬5ä¸ªtoken
```

#### å‰ç«¯ä½¿ç”¨ï¼š
```javascript
// ChatView.jsx ç¬¬224è¡Œ
const sentenceTokenId = token.sentence_token_id
markAsAsked(textId, sentenceId, sentenceTokenId)

// TokenSpan.jsx ç¬¬44-47è¡Œ
const tokenSentenceTokenId = token?.sentence_token_id
isTokenAsked(articleId, tokenSentenceId, tokenSentenceTokenId)
```

#### åç«¯ APIï¼š
```python
# server_frontend_mock.py ç¬¬917-945è¡Œ
@app.post('/api/user/asked-tokens')
async def mark_token_asked(payload: dict):
    sentence_token_id = payload.get('sentence_token_id')  # â† å¥å†…ID
    manager.mark_token_asked(user_id, text_id, sentence_id, sentence_token_id)
```

**âœ… ä¼˜ç‚¹**ï¼š
- ç¨³å®šï¼šå¥å­å†… token é¡ºåºç›¸å¯¹å›ºå®š
- ç®€å•ï¼šæ¯ä¸ªå¥å­ç‹¬ç«‹ç¼–å·ï¼Œæ˜“äºç†è§£
- é€‚åˆç”¨æˆ·äº¤äº’ï¼šç”¨æˆ·çœ‹åˆ°çš„æ˜¯"å¥å­å†…ç¬¬å‡ ä¸ªè¯"

---

### 2ï¸âƒ£ **Vocab Exampleï¼ˆè¯æ±‡ä¾‹å¥ï¼‰** - ä½¿ç”¨ `token_indices` ï¼ˆæœªæŒ‡å®šç±»å‹ï¼‰âš ï¸

#### æ•°æ®ç»“æ„ï¼š
```python
@dataclass
class VocabExpressionExample:
    vocab_id: int
    text_id: int
    sentence_id: int
    context_explanation: str
    token_indices: list[int] = field(default_factory=list)  # âš ï¸ æœªæ˜ç¡®è¯´æ˜
```

#### å½“å‰å®é™…æ•°æ®ï¼ˆ`vocab.json`ï¼‰ï¼š
```json
{
  "vocab_id": 1,
  "examples": [{
    "text_id": 1,
    "sentence_id": 1,
    "token_indices": []  // â† å½“å‰éƒ½ä¸ºç©º
  }]
}
```

#### åç«¯æ·»åŠ ä¾‹å¥ï¼š
```python
# vocab_manager.py ç¬¬67-73è¡Œ
new_example = NewVocabExpressionExample(
    vocab_id=vocab_id,
    text_id=text_id,
    sentence_id=sentence_id,
    context_explanation=context_explanation,
    token_indices=[]  # â† ç¡¬ç¼–ç ä¸ºç©ºæ•°ç»„ï¼Œæœªè®¾ç½®å®é™…å€¼
)
```

**âš ï¸ é—®é¢˜**ï¼š
- `token_indices` å§‹ç»ˆä¸ºç©ºï¼Œæœªå®é™…ä½¿ç”¨
- æœªæ˜ç¡®æ˜¯ `global_token_id` è¿˜æ˜¯ `sentence_token_id`

---

### 3ï¸âƒ£ **Token Selectionï¼ˆå‰ç«¯é€‰æ‹©ï¼‰** - æ··åˆä½¿ç”¨ âš ï¸

#### å‰ç«¯ä»£ç ï¼ˆ`useTokenSelection.js`ï¼‰ï¼š

```javascript
// ä½¿ç”¨ global_token_id ä½œä¸ºå”¯ä¸€æ ‡è¯†
const tokenId = token.global_token_id

// ä½†ä¼ ç»™åç«¯æ—¶ä½¿ç”¨ sentence_token_id
updatePayload.token = {
  token_body: token.token_body,
  sentence_token_id: token.sentence_token_id,  // â† å¥å†…ID
  global_token_id: token.global_token_id       // â† å…¨æ–‡ID
}
```

#### åç«¯ SelectedTokenï¼š
```python
# selected_token.py (ç®€åŒ–ç‰ˆæœ¬)
# ä½¿ç”¨è¯ä½ç½®ç´¢å¼•ï¼ˆåŸºäº split() åˆ†è¯ï¼‰
token_indices = []  # ç›¸å¯¹ä½ç½®ï¼Œä¸æ˜¯ token_id
```

**âš ï¸ é—®é¢˜**ï¼š
- å‰ç«¯ç”¨ `global_token_id` åšé€‰æ‹©çŠ¶æ€ç®¡ç†
- ä¼ ç»™åç«¯æ—¶å¸¦äº†ä¸¤ä¸ª IDï¼Œä½†åç«¯åªç”¨äº† `sentence_token_id`
- SelectedToken çš„ `token_indices` æ˜¯åˆ†è¯ä½ç½®ï¼Œä¸æ˜¯ token_id

---

## ğŸ“‹ æ¨èä½¿ç”¨è§„èŒƒ

### âœ… **æ¨èï¼šç»Ÿä¸€ä½¿ç”¨ `sentence_token_id`**

#### ç†ç”±ï¼š
1. **ç¨³å®šæ€§**ï¼šå¥å­å†…ç¼–å·ä¸å—æ–‡ç« ä¿®æ”¹å½±å“
2. **å·²æœ‰åŸºç¡€**ï¼šAsked Tokens å·²å…¨é¢ä½¿ç”¨
3. **è¯­ä¹‰æ¸…æ™°**ï¼š`text_id + sentence_id + sentence_token_id` ç»„åˆå”¯ä¸€å®šä½
4. **ç®€åŒ–é€»è¾‘**ï¼šé¿å…ç»´æŠ¤ä¸¤å¥—IDä½“ç³»

#### å»ºè®®ä¿®æ”¹ï¼š

**1. Vocab Example çš„ token_indices**
```python
# ä¿®æ”¹å‰
token_indices=[]  # ç©ºæ•°ç»„

# ä¿®æ”¹åï¼ˆå»ºè®®ï¼‰
token_indices=[sentence_token_id]  # ä½¿ç”¨å¥å†…ID
# æˆ–è€…å¯¹äºå¤šè¯è¡¨è¾¾
token_indices=[3, 4, 5]  # å¥å†…ç¬¬3ã€4ã€5ä¸ªtoken
```

**2. å‰ç«¯é€‰æ‹©çŠ¶æ€ç®¡ç†**
```javascript
// ä¿®æ”¹å‰
const tokenId = token.global_token_id  // å…¨æ–‡ID

// ä¿®æ”¹åï¼ˆå»ºè®®ï¼Œå¯é€‰ï¼‰
const tokenId = `${sentenceIdx}:${token.sentence_token_id}`  // å¤åˆé”®
// ä¼˜ç‚¹ï¼šé¿å…è·¨å¥å­IDå†²çª
```

---

## ğŸ”„ Global Token ID çš„ä»·å€¼

è™½ç„¶æ¨èä¸»è¦ä½¿ç”¨ `sentence_token_id`ï¼Œä½† `global_token_id` ä¹Ÿæœ‰ç”¨é€”ï¼š

### é€‚ç”¨åœºæ™¯ï¼š
1. **å…¨æ–‡ç»Ÿè®¡**ï¼šç»Ÿè®¡æ•´ç¯‡æ–‡ç« çš„è¯é¢‘ã€éš¾åº¦åˆ†å¸ƒ
2. **è·¨å¥å­å¼•ç”¨**ï¼šå¦‚æœéœ€è¦æ ‡è®°"æ–‡ç« ç¬¬Xä¸ªè¯"
3. **æ–‡ç« çº§åˆ«æ ‡æ³¨**ï¼šå…¨æ–‡èŒƒå›´çš„è¯­æ³•ç»“æ„åˆ†æ

### ä¸é€‚åˆï¼š
- âŒ ç”¨æˆ·äº¤äº’ï¼ˆç”¨æˆ·ä¸å…³å¿ƒ"å…¨æ–‡ç¬¬å‡ ä¸ªè¯"ï¼‰
- âŒ å¥å­çº§åˆ«æ“ä½œï¼ˆå¥å­æ”¹å˜ä¼šå½±å“åç»­æ‰€æœ‰ tokenï¼‰

---

## âœ… ä½¿ç”¨çŠ¶å†µæ€»ç»“ï¼ˆä¼˜åŒ–åï¼‰

| åŠŸèƒ½ | ä½¿ç”¨çš„ ID | çŠ¶æ€ | è¯´æ˜ |
|------|----------|------|------|
| **Asked Tokens** | `sentence_token_id` | âœ… æ­£ç¡® | ä¿æŒä¸å˜ |
| **å‰ç«¯é€‰æ‹©ï¼ˆå”¯ä¸€é”®ï¼‰** | `sentence_token_id` | âœ… **å·²ä¼˜åŒ–** | åªä½¿ç”¨å¥å†…ID |
| **å‰ç«¯ä¼ å‚** | `sentence_token_id` | âœ… **å·²ä¼˜åŒ–** | ç§»é™¤ global_token_id |
| **åç«¯ SelectedToken** | è¯ä½ç½®ç´¢å¼• | âš ï¸ é—ç•™ | åŠŸèƒ½æ­£å¸¸ï¼Œæœªæ¥å¯ä¼˜åŒ– |
| **Vocab Example** | `token_indices` | âœ… **å·²ä¿®å¤** | å­˜å‚¨å®é™… sentence_token_id |
| **Grammar Example** | æ—  token_indices | âœ… åˆç† | è¯­æ³•æ˜¯å¥å­çº§åˆ«ï¼Œä¸éœ€è¦ |

---

## âœ… å·²å®Œæˆçš„ä¼˜åŒ–

### ä¿®å¤1ï¼šVocab Example çš„ token_indices âœ…

**ä¿®æ”¹æ–‡ä»¶**ï¼š
- `backend/data_managers/vocab_manager.py` ç¬¬54è¡Œ
- `backend/data_managers/data_controller.py` ç¬¬187-198è¡Œ  
- `backend/assistants/main_assistant.py` ç¬¬426-434è¡Œã€ç¬¬547-555è¡Œ

**æ”¹è¿›å†…å®¹**ï¼š
```python
# ä¿®å¤å‰
new_example = NewVocabExpressionExample(
    token_indices=[]  # âŒ ç¡¬ç¼–ç ç©ºæ•°ç»„
)

# ä¿®å¤å
new_example = NewVocabExpressionExample(
    token_indices=token_indices  # âœ… ä½¿ç”¨å®é™…å€¼
)
```

**æ–°å¢è¾…åŠ©æ–¹æ³•**ï¼š
```python
# main_assistant.py ç¬¬565-613è¡Œ
def _get_token_indices_from_selection(self, sentence):
    """ä» session_state æå– sentence_token_id åˆ—è¡¨"""
    # 1. è·å–é€‰ä¸­çš„æ–‡æœ¬
    # 2. åœ¨å¥å­çš„ tokens ä¸­æŸ¥æ‰¾åŒ¹é…
    # 3. è¿”å› sentence_token_id åˆ—è¡¨
```

**æ•ˆæœ**ï¼š
- âœ… `token_indices` ç°åœ¨å­˜å‚¨å®é™…çš„ `sentence_token_id`
- âœ… æ•°æ®å®Œæ•´ï¼Œå¯ç”¨äºæœªæ¥é«˜äº®æ˜¾ç¤º
- âœ… ç¤ºä¾‹ï¼š`"token_indices": [3, 4, 5]` è¡¨ç¤ºå¥å†…ç¬¬3ã€4ã€5ä¸ªtoken

---

### ä¿®å¤2ï¼šå‰ç«¯ç»Ÿä¸€ä½¿ç”¨ sentence_token_id âœ…

**ä¿®æ”¹æ–‡ä»¶**ï¼š
- `frontend/my-web-ui/src/modules/article/utils/tokenUtils.js` ç¬¬24-32è¡Œ
- `frontend/my-web-ui/src/modules/article/components/ChatView.jsx` ç¬¬184è¡Œã€ç¬¬499è¡Œ

**æ”¹è¿›å†…å®¹**ï¼š
```javascript
// ä¿®å¤å‰
export const getTokenId = (token) => {
  const gid = token?.global_token_id
  const sid = token?.sentence_token_id
  return `${gid}-${sid}`  // âŒ ä½¿ç”¨å…¨æ–‡ID
}

// ä¿®å¤å
export const getTokenId = (token) => {
  const sid = token?.sentence_token_id
  return sid  // âœ… åªä½¿ç”¨å¥å†…ID
}
```

```javascript
// å‰ç«¯ä¼ å‚ä¼˜åŒ–
updatePayload.token = {
  token_body: token.token_body,
  sentence_token_id: token.sentence_token_id
  // âœ… ç§»é™¤äº† global_token_id
}
```

**æ•ˆæœ**ï¼š
- âœ… å‰åç«¯ç»Ÿä¸€ä½¿ç”¨ `sentence_token_id`
- âœ… å‡å°‘æ•°æ®ä¼ è¾“ï¼ˆç§»é™¤å†—ä½™å­—æ®µï¼‰
- âœ… ä»£ç æ›´ç®€æ´
- âœ… ä¸ Asked Tokens åŠŸèƒ½ä¿æŒä¸€è‡´

---

## ğŸ”§ é—ç•™ä¼˜åŒ–ï¼ˆå¯é€‰ï¼Œä½ä¼˜å…ˆçº§ï¼‰

### SelectedToken çš„ token_indices ä¼˜åŒ– ğŸŸ¢
- **å½“å‰çŠ¶æ€**ï¼šä½¿ç”¨è¯ä½ç½®ç´¢å¼•ï¼ˆåŸºäº `split()`ï¼‰
- **å»ºè®®**ï¼šæ”¹ä¸ºç›´æ¥ä½¿ç”¨ `sentence_token_id`
- **å½±å“**ï¼šåŠŸèƒ½æ­£å¸¸ï¼Œä¼˜å…ˆçº§ä½

---

## ğŸ’¡ æ€»ç»“

**âœ… ç³»ç»Ÿç°å·²å®Œå…¨ç»Ÿä¸€ä½¿ç”¨ `sentence_token_id`ï¼ˆå¥å†…IDï¼‰ï¼**

### å·²å®Œæˆçš„ä¼˜åŒ–ï¼š
- âœ… **Vocab Example** - ç°åœ¨å­˜å‚¨å®é™…çš„ `sentence_token_id`
- âœ… **å‰ç«¯é€‰æ‹©** - åªä½¿ç”¨ `sentence_token_id` ä½œä¸ºå”¯ä¸€é”®
- âœ… **å‰ç«¯ä¼ å‚** - ç§»é™¤å†—ä½™çš„ `global_token_id`
- âœ… **Asked Tokens** - å·²ç»åœ¨ä½¿ç”¨ `sentence_token_id`
- âœ… **å‰åç«¯ä¸€è‡´** - ç»Ÿä¸€çš„æ ‡è¯†ä½“ç³»

### Global Token ID çš„ä¿ç•™ï¼š
- ğŸ“Š **ä¿ç•™åœ¨æ•°æ®ä¸­**ï¼Œç”¨äºå…¨æ–‡ç»Ÿè®¡å’Œåˆ†æ
- ğŸ¯ **ä¸ç”¨äºç”¨æˆ·äº¤äº’**ï¼Œé¿å…å¤æ‚æ€§
- ğŸ“ˆ **æœªæ¥æ‰©å±•**ï¼šå…¨æ–‡è¯é¢‘åˆ†æã€éš¾åº¦åˆ†å¸ƒç­‰

### ç³»ç»Ÿä¼˜åŠ¿ï¼š
- âœ… **ç¨³å®šæ€§**ï¼šå¥å­ä¿®æ”¹ä¸å½±å“å¥å†…ç¼–å·
- âœ… **ç®€æ´æ€§**ï¼š`text_id + sentence_id + sentence_token_id` ä¸‰å…ƒç»„å”¯ä¸€å®šä½
- âœ… **ä¸€è‡´æ€§**ï¼šå‰åç«¯ä½¿ç”¨ç›¸åŒçš„æ ‡è¯†ä½“ç³»
- âœ… **å¯æ‰©å±•**ï¼štoken_indices æ”¯æŒå¤šè¯è¡¨è¾¾ï¼ˆå¦‚ [3, 4, 5]ï¼‰


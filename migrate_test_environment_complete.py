#!/usr/bin/env python3
"""
æµ‹è¯•ç¯å¢ƒæ•°æ®åº“è¿ç§»ï¼šå®Œæ•´è¿ç§»ï¼ˆæ·»åŠ user_idå’Œlanguageå­—æ®µï¼Œè¿ç§»æ•°æ®ï¼‰

æ‰§è¡Œæ­¥éª¤ï¼š
1. å¤‡ä»½å½“å‰æ•°æ®åº“
2. å¯¼å‡ºç°æœ‰æ•°æ®
3. é‡å»ºè¡¨ç»“æ„ï¼ˆåŒ…å«user_idå’Œlanguageå­—æ®µï¼‰
4. å¯¼å…¥æ•°æ®ï¼ˆè®¾ç½®user_id=1ï¼Œlanguage=å¾·æ–‡ï¼‰
5. éªŒè¯è¿ç§»ç»“æœ
"""

import sys
import os
import shutil
from datetime import datetime

# æ·»åŠ è·¯å¾„
BACKEND_DIR = os.path.join(os.path.dirname(__file__), "backend")
sys.path.insert(0, BACKEND_DIR)

from database_system.database_manager import DatabaseManager
from database_system.data_storage.config.config import DB_FILES
from database_system.business_logic.models import Base
from sqlalchemy import inspect, text


def backup_database(db_path):
    """å¤‡ä»½æ•°æ®åº“"""
    if os.path.exists(db_path):
        backup_path = db_path.replace('.db', f'_backup_{datetime.now().strftime("%Y%m%d_%H%M%S")}.db')
        shutil.copy2(db_path, backup_path)
        print(f"âœ… æ•°æ®åº“å·²å¤‡ä»½åˆ°: {backup_path}")
        return backup_path
    return None


def export_existing_data(session, table_name):
    """å¯¼å‡ºç°æœ‰æ•°æ®"""
    try:
        # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
        inspector = inspect(session.bind)
        table_names = inspector.get_table_names()
        
        if table_name not in table_names:
            return []
        
        # å¯¼å‡ºæ‰€æœ‰æ•°æ®
        result = session.execute(text(f"SELECT * FROM {table_name}")).fetchall()
        
        # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
        data = []
        for row in result:
            # å°è¯•è½¬æ¢ä¸ºå­—å…¸
            if hasattr(row, '_mapping'):
                row_dict = dict(row._mapping)
            elif hasattr(row, '_asdict'):
                row_dict = row._asdict()
            else:
                # å¦‚æœæ˜¯å…ƒç»„ï¼Œéœ€è¦çŸ¥é“åˆ—å
                cursor = session.execute(text(f"PRAGMA table_info({table_name})"))
                columns = [col[1] for col in cursor.fetchall()]
                row_dict = dict(zip(columns, row))
            data.append(row_dict)
        
        return data
    except Exception as e:
        print(f"   âš ï¸  å¯¼å‡º {table_name} æ•°æ®æ—¶å‡ºé”™: {e}")
        return []


def rebuild_test_environment_tables(environment, db_path):
    """é‡å»ºæµ‹è¯•ç¯å¢ƒè¡¨ç»“æ„"""
    print(f"\nğŸ“‹ é‡å»º {environment} ç¯å¢ƒæ•°æ®åº“è¡¨ç»“æ„...")
    print(f"   ğŸ“ æ•°æ®åº“è·¯å¾„: {db_path}")
    
    # 1. æ£€æŸ¥æ•°æ®åº“æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(db_path):
        print(f"   âš ï¸  æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨: {db_path}")
        return False
    
    # 2. å¤‡ä»½æ•°æ®åº“
    backup_path = backup_database(db_path)
    
    # 3. è¿æ¥æ•°æ®åº“
    try:
        db_manager = DatabaseManager(environment)
        engine = db_manager.get_engine()
        session = db_manager.get_session()
    except Exception as e:
        print(f"   âŒ è¿æ¥æ•°æ®åº“å¤±è´¥: {e}")
        return False
    
    try:
        # 4. å¯¼å‡ºç°æœ‰æ•°æ®
        print(f"\nğŸ“¤ å¯¼å‡ºç°æœ‰æ•°æ®...")
        data = {
            'vocabs': export_existing_data(session, 'vocab_expressions'),
            'grammar_rules': export_existing_data(session, 'grammar_rules'),
            'texts': export_existing_data(session, 'original_texts'),
        }
        
        vocab_count = len(data['vocabs'])
        grammar_count = len(data['grammar_rules'])
        text_count = len(data['texts'])
        
        print(f"   ğŸ“Š å¯¼å‡ºç»“æœ:")
        print(f"      - è¯æ±‡: {vocab_count} æ¡")
        print(f"      - è¯­æ³•è§„åˆ™: {grammar_count} æ¡")
        print(f"      - æ–‡ç« : {text_count} æ¡")
        
        if vocab_count > 0:
            print(f"   ğŸ“ ç¤ºä¾‹è¯æ±‡: {data['vocabs'][0] if data['vocabs'] else 'N/A'}")
        if grammar_count > 0:
            print(f"   ğŸ“ ç¤ºä¾‹è¯­æ³•è§„åˆ™: {data['grammar_rules'][0] if data['grammar_rules'] else 'N/A'}")
        
        session.close()
        
        # 5. åˆ é™¤æ—§è¡¨ï¼ˆæŒ‰ä¾èµ–é¡ºåºï¼‰
        print(f"\nğŸ”„ åˆ é™¤æ—§è¡¨...")
        tables_to_drop = [
            'vocab_expression_examples',  # ä¾èµ–vocab_expressions
            'grammar_examples',  # ä¾èµ–grammar_rules
            'vocab_notations',  # ä¾èµ–vocab_expressions
            'grammar_notations',  # ä¾èµ–grammar_rules
            'tokens',  # ä¾èµ–original_texts
            'sentences',  # ä¾èµ–original_texts
            'asked_tokens',  # ä¾èµ–users
            'vocab_expressions',  # ä¾èµ–users
            'grammar_rules',  # ä¾èµ–users
            'original_texts',  # ä¾èµ–users
            # æ³¨æ„ï¼šä¸è¦åˆ é™¤usersè¡¨
        ]
        
        for table in tables_to_drop:
            try:
                engine.execute(text(f"DROP TABLE IF EXISTS {table}"))
                print(f"   âœ… åˆ é™¤è¡¨: {table}")
            except Exception as e:
                print(f"   âš ï¸  åˆ é™¤è¡¨ {table} æ—¶å‡ºé”™: {e}")
        
        # 6. åˆ›å»ºæ–°è¡¨ç»“æ„
        print(f"\nğŸ†• åˆ›å»ºæ–°è¡¨ç»“æ„...")
        from database_system.business_logic.models import (
            VocabExpression, GrammarRule, OriginalText,
            Sentence, Token, VocabExpressionExample, GrammarExample
        )
        
        # åˆ›å»ºè¡¨ï¼ˆåŒ…å«user_idå’Œlanguageå­—æ®µï¼‰
        Base.metadata.create_all(engine, tables=[
            VocabExpression.__table__,
            GrammarRule.__table__,
            OriginalText.__table__,
            Sentence.__table__,
            Token.__table__,
            VocabExpressionExample.__table__,
            GrammarExample.__table__,
        ])
        print(f"   âœ… æ–°è¡¨å·²åˆ›å»º")
        
        # 7. å¯¼å…¥æ•°æ®ï¼ˆå¦‚æœæœ‰ï¼‰
        if vocab_count > 0 or grammar_count > 0 or text_count > 0:
            print(f"\nğŸ“¥ å¯¼å…¥æ•°æ®åˆ° user_id=1, language=å¾·æ–‡...")
            session = db_manager.get_session()
            
            # å¯¼å…¥è¯æ±‡
            if vocab_count > 0:
                print(f"   ğŸ“ å¯¼å…¥ {vocab_count} æ¡è¯æ±‡...")
                imported_count = 0
                for v in data['vocabs']:
                    try:
                        # è·å–æ‰€æœ‰å­—æ®µ
                        vocab_id = v.get('vocab_id')
                        vocab_body = v.get('vocab_body')
                        explanation = v.get('explanation')
                        source = v.get('source', 'auto')
                        is_starred = v.get('is_starred', False)
                        created_at = v.get('created_at')
                        updated_at = v.get('updated_at')
                        
                        session.execute(text("""
                            INSERT INTO vocab_expressions 
                            (vocab_id, user_id, vocab_body, explanation, language, source, is_starred, created_at, updated_at)
                            VALUES (:vocab_id, 1, :vocab_body, :explanation, 'å¾·æ–‡', :source, :is_starred, :created_at, :updated_at)
                        """), {
                            'vocab_id': vocab_id,
                            'vocab_body': vocab_body,
                            'explanation': explanation,
                            'source': source,
                            'is_starred': is_starred,
                            'created_at': created_at,
                            'updated_at': updated_at,
                        })
                        imported_count += 1
                    except Exception as e:
                        print(f"   âš ï¸  å¯¼å…¥è¯æ±‡ {v.get('vocab_id')} æ—¶å‡ºé”™: {e}")
                
                session.commit()
                print(f"   âœ… æˆåŠŸå¯¼å…¥ {imported_count}/{vocab_count} æ¡è¯æ±‡")
            
            # å¯¼å…¥è¯­æ³•è§„åˆ™
            if grammar_count > 0:
                print(f"   ğŸ“ å¯¼å…¥ {grammar_count} æ¡è¯­æ³•è§„åˆ™...")
                imported_count = 0
                for g in data['grammar_rules']:
                    try:
                        rule_id = g.get('rule_id')
                        rule_name = g.get('rule_name')
                        rule_summary = g.get('rule_summary')
                        source = g.get('source', 'auto')
                        is_starred = g.get('is_starred', False)
                        created_at = g.get('created_at')
                        updated_at = g.get('updated_at')
                        
                        session.execute(text("""
                            INSERT INTO grammar_rules 
                            (rule_id, user_id, rule_name, rule_summary, language, source, is_starred, created_at, updated_at)
                            VALUES (:rule_id, 1, :rule_name, :rule_summary, 'å¾·æ–‡', :source, :is_starred, :created_at, :updated_at)
                        """), {
                            'rule_id': rule_id,
                            'rule_name': rule_name,
                            'rule_summary': rule_summary,
                            'source': source,
                            'is_starred': is_starred,
                            'created_at': created_at,
                            'updated_at': updated_at,
                        })
                        imported_count += 1
                    except Exception as e:
                        print(f"   âš ï¸  å¯¼å…¥è¯­æ³•è§„åˆ™ {g.get('rule_id')} æ—¶å‡ºé”™: {e}")
                
                session.commit()
                print(f"   âœ… æˆåŠŸå¯¼å…¥ {imported_count}/{grammar_count} æ¡è¯­æ³•è§„åˆ™")
            
            # å¯¼å…¥æ–‡ç« 
            if text_count > 0:
                print(f"   ğŸ“ å¯¼å…¥ {text_count} æ¡æ–‡ç« ...")
                imported_count = 0
                for t in data['texts']:
                    try:
                        text_id = t.get('text_id')
                        text_title = t.get('text_title')
                        created_at = t.get('created_at')
                        updated_at = t.get('updated_at')
                        
                        session.execute(text("""
                            INSERT INTO original_texts 
                            (text_id, user_id, text_title, language, created_at, updated_at)
                            VALUES (:text_id, 1, :text_title, 'å¾·æ–‡', :created_at, :updated_at)
                        """), {
                            'text_id': text_id,
                            'text_title': text_title,
                            'created_at': created_at,
                            'updated_at': updated_at,
                        })
                        imported_count += 1
                    except Exception as e:
                        print(f"   âš ï¸  å¯¼å…¥æ–‡ç«  {t.get('text_id')} æ—¶å‡ºé”™: {e}")
                
                session.commit()
                print(f"   âœ… æˆåŠŸå¯¼å…¥ {imported_count}/{text_count} æ¡æ–‡ç« ")
            
            session.close()
        
        # 8. éªŒè¯è¡¨ç»“æ„
        print(f"\nğŸ” éªŒè¯è¡¨ç»“æ„...")
        session = db_manager.get_session()
        inspector = inspect(engine)
        
        tables_to_check = ['vocab_expressions', 'grammar_rules', 'original_texts']
        for table_name in tables_to_check:
            columns = [col['name'] for col in inspector.get_columns(table_name)]
            has_user_id = 'user_id' in columns
            has_language = 'language' in columns
            
            status = "âœ…" if has_user_id and has_language else "âŒ"
            print(f"   {status} {table_name}:")
            print(f"      - user_id: {'æœ‰' if has_user_id else 'æ— '}")
            print(f"      - language: {'æœ‰' if has_language else 'æ— '}")
            
            # éªŒè¯æ•°æ®
            count_result = session.execute(text(f"SELECT COUNT(*) FROM {table_name}")).fetchone()
            count = count_result[0] if count_result else 0
            print(f"      - è®°å½•æ•°: {count}")
            
            if count > 0 and has_user_id:
                user_count_result = session.execute(text(f"SELECT COUNT(*) FROM {table_name} WHERE user_id = 1")).fetchone()
                user_count = user_count_result[0] if user_count_result else 0
                print(f"      - user_id=1çš„è®°å½•æ•°: {user_count}")
            
            if count > 0 and has_language:
                lang_count_result = session.execute(text(f"SELECT COUNT(*) FROM {table_name} WHERE language = 'å¾·æ–‡'")).fetchone()
                lang_count = lang_count_result[0] if lang_count_result else 0
                print(f"      - language='å¾·æ–‡'çš„è®°å½•æ•°: {lang_count}")
        
        session.close()
        
        return True
            
    except Exception as e:
        session.rollback()
        print(f"   âŒ {environment} ç¯å¢ƒæ›´æ–°å¤±è´¥: {e}")
        if backup_path:
            print(f"   ğŸ’¾ å¯ä»¥ä»å¤‡ä»½æ¢å¤: {backup_path}")
        import traceback
        traceback.print_exc()
        return False


def main():
    print("\n" + "="*60)
    print("æµ‹è¯•ç¯å¢ƒæ•°æ®åº“è¿ç§»ï¼šå®Œæ•´è¿ç§»ï¼ˆæ·»åŠ user_idå’Œlanguageå­—æ®µï¼‰")
    print("="*60)
    print("\nâš ï¸  æ³¨æ„ï¼šæ­¤è„šæœ¬ä¼šé‡å»ºè¡¨ç»“æ„")
    print("âš ï¸  è¯·ç¡®ä¿å·²ç»å¤‡ä»½æ•°æ®åº“")
    print("âš ï¸  ç°æœ‰æ•°æ®å°†è¿ç§»åˆ° user_id=1, language=å¾·æ–‡")
    print("\nğŸ“‹ æ­¤è„šæœ¬å°†ï¼š")
    print("  1. å¤‡ä»½æ•°æ®åº“")
    print("  2. å¯¼å‡ºç°æœ‰æ•°æ®ï¼ˆ3ä¸ªvocab, 2ä¸ªgrammarï¼‰")
    print("  3. åˆ é™¤æ—§è¡¨")
    print("  4. åˆ›å»ºæ–°è¡¨ç»“æ„ï¼ˆåŒ…å«user_idå’Œlanguageå­—æ®µï¼‰")
    print("  5. å¯¼å…¥æ•°æ®ï¼ˆè®¾ç½®user_id=1, language=å¾·æ–‡ï¼‰")
    print("  6. éªŒè¯è¿ç§»ç»“æœ")
    
    response = input("\nâ“ æ˜¯å¦ç»§ç»­ï¼Ÿ(y/n): ")
    if response.lower() != 'y':
        print("â­ï¸  å·²å–æ¶ˆ")
        return
    
    # è¿ç§»æµ‹è¯•ç¯å¢ƒæ•°æ®åº“
    environment = 'testing'
    db_path = DB_FILES['test']
    
    if rebuild_test_environment_tables(environment, db_path):
        print("\n" + "="*60)
        print("âœ… è¿ç§»å®Œæˆï¼")
        print("="*60)
        print("\nä¸‹ä¸€æ­¥ï¼š")
        print("1. éªŒè¯æ•°æ®åº“ä¸­çš„ user_id å’Œ language å­—æ®µ")
        print("2. æµ‹è¯•ç”¨æˆ·éš”ç¦»åŠŸèƒ½")
        print("3. ç¡®è®¤APIæ­£å¸¸å·¥ä½œ")
        print("4. ç¡®è®¤æ‰€æœ‰æ•°æ®éƒ½å½’å±åˆ° user_id=1, language=å¾·æ–‡")
    else:
        print("\n" + "="*60)
        print("âŒ è¿ç§»å¤±è´¥")
        print("="*60)
        print("è¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯å¹¶ä¿®å¤")


if __name__ == "__main__":
    main()


from fastapi import FastAPI, Query, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from typing import Optional
import json

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å?from models import ApiResponse
from services import data_service
from utils import create_success_response, create_error_response
import os
from datetime import datetime

# è®¡ç®— real_data_raw/result ç›®å½•ï¼ˆç›¸å¯¹æœ¬æ–‡ä»¶ä½ç½®ï¼?RESULT_DIR = os.path.abspath(
    os.path.join(os.path.dirname(__file__), "..", "..", "..", "real_data_raw", "result")
)

def _ensure_result_dir() -> str:
    os.makedirs(RESULT_DIR, exist_ok=True)
    return RESULT_DIR

def _parse_timestamp_from_filename(name: str) -> str:
    # å½¢å¦‚: hp1_processed_20250916_123831.json
    try:
        ts = name.rsplit("_", 2)[-2:]  # [YYYYMMDD, HHMMSS.json]
        ts_s = ts[0] + "_" + ts[1].replace(".json", "")
        # è¿”å› ISO-ish æ ¼å¼
        dt = datetime.strptime(ts_s, "%Y%m%d_%H%M%S")
        return dt.isoformat()
    except Exception:
        return ""

def _iter_processed_files():
    base = _ensure_result_dir()
    try:
        for fname in os.listdir(base):
            if fname.endswith(".json") and "_processed_" in fname:
                yield os.path.join(base, fname)
    except FileNotFoundError:
        return

def _load_json_file(path: str):
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)

def _collect_articles_summary():
    summaries = []
    for path in _iter_processed_files():
        try:
            data = _load_json_file(path)
            text_id = int(data.get("text_id", 0))
            title = data.get("text_title", "")
            total_sentences = int(data.get("total_sentences", len(data.get("sentences", []) or [])))
            total_tokens = int(data.get("total_tokens", 0))

            # ç»Ÿè®¡å¯é€‰æ‹© tokenï¼ˆä»… text ç±»å‹ï¼?            selectable = 0
            for s in data.get("sentences", []) or []:
                for t in s.get("tokens", []) or []:
                    if t.get("token_type") == "text":
                        selectable += 1

            summaries.append({
                "text_id": text_id,
                "text_title": title,
                "total_sentences": total_sentences,
                "total_tokens": total_tokens,
                "text_tokens": selectable,
                "created_at": _parse_timestamp_from_filename(os.path.basename(path)),
                "filename": os.path.basename(path),
            })
        except Exception:
            # å¿½ç•¥æŸåæ–‡ä»¶
            continue

    # æŒ?text_idã€created_at æ’åºï¼ˆé™åºï¼‰
    summaries.sort(key=lambda x: (x.get("text_id", 0), x.get("created_at", "")), reverse=True)
    return summaries

def _find_article_file_by_id(article_id: int) -> Optional[str]:
    # ä¼˜å…ˆæ‰¾åŒ¹é…?text_id çš„æœ€æ–?processed æ–‡ä»¶
    candidates = []
    for path in _iter_processed_files():
        try:
            data = _load_json_file(path)
            if int(data.get("text_id", -1)) == int(article_id):
                candidates.append((path, _parse_timestamp_from_filename(os.path.basename(path))))
        except Exception:
            continue
    if not candidates:
        return None
    candidates.sort(key=lambda x: x[1], reverse=True)
    return candidates[0][0]

def _mark_tokens_selectable(data: dict) -> dict:
    # æ·±æ‹·è´ä¸å¼ºæ±‚ï¼Œè¿™é‡Œå°±åœ°æ·»åŠ å­—æ®µï¼ˆFastAPI ä¼šå¤åˆ¶è¿”å›ï¼‰
    total_selectable = 0
    for s in data.get("sentences", []) or []:
        selectable_count = 0
        for t in s.get("tokens", []) or []:
            is_text = (t.get("token_type") == "text")
            t["selectable"] = bool(is_text)
            t["is_selected"] = False
            if is_text:
                selectable_count += 1
        s["selectable_token_count"] = selectable_count
        total_selectable += selectable_count
    data["selectable_tokens"] = total_selectable
    return data

app = FastAPI(
    title="è¯­è¨€å­¦ä¹  API", 
    description="è¯æ±‡å’Œè¯­æ³•å­¦ä¹?APIï¼Œæ”¯æŒç»Ÿä¸€å“åº”æ ¼å¼",
    version="1.0.0"
)

# å¯ç”¨ CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=[" *\,
        "http://localhost:5173",
        "http://127.0.0.1:5173",
        "http://localhost:5174",
        "http://127.0.0.1:5174",
        "http://localhost:5175",
        "http://127.0.0.1:5175",
        "http://localhost:5176",
        "http://127.0.0.1:5176",
    ],  # React/Vite å¼€å‘ä¸é¢„è§ˆæœåŠ¡å™?    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


@app.get("/", response_model=ApiResponse)
async def root():
    """æ ¹è·¯å¾„ï¼Œè¿”å› API çŠ¶æ€ä¿¡æ?""
    return create_success_response(
        data={
            "message": "è¯­è¨€å­¦ä¹  API æ­£åœ¨è¿è¡Œï¼?,
            "version": "1.0.0",
            "endpoints": {
                "health": "/api/health",
                "word": "/api/word",
                "vocab": "/api/vocab",
                "grammar": "/api/grammar",
                "docs": "/docs"
            }
        },
        message="API æœåŠ¡æ­£å¸¸"
    )


@app.get("/api/health", response_model=ApiResponse)
async def health_check():
    """å¥åº·æ£€æŸ?""
    return create_success_response(
        data={
            "status": "healthy",
            "timestamp": "2024-08-28T16:00:00Z"
        },
        message="æœåŠ¡å¥åº·"
    )


@app.get("/api/word", response_model=ApiResponse)
async def get_word_info(text: str = Query(..., description="è¦æŸ¥è¯¢çš„å•è¯")):
    """æŒ‰è¯æŸ¥è¯¢"""
    try:
        word = text.lower().strip()
        vocab_list = data_service.get_vocab_data()
        
        # æŸ¥æ‰¾åŒ¹é…çš„è¯æ±?        for vocab in vocab_list:
            if vocab.vocab_body.lower() == word:
                data = {
                    "word": vocab.vocab_body,
                    "definition": vocab.explanation,
                    "examples": vocab.examples,
                    "source": vocab.source,
                    "is_starred": vocab.is_starred
                }
                return create_success_response(
                    data=data,
                    message=f"æ‰¾åˆ°è¯æ±‡: {vocab.vocab_body}"
                )
        
        # æœªæ‰¾åˆ°å•è¯?        return create_error_response(f"æœªæ‰¾åˆ°å•è¯? {word}")
        
    except Exception as e:
        return create_error_response(f"æŸ¥è¯¢å•è¯å¤±è´¥: {str(e)}")


@app.get("/api/grammar/{rule_id}", response_model=ApiResponse)
async def get_grammar_by_id(rule_id: int):
    """æŒ‰è§„åˆ™IDæŸ¥è¯¢"""
    try:
        grammar = data_service.get_grammar_by_id(rule_id)
        
        if grammar is None:
            return create_error_response(f"æœªæ‰¾åˆ?ID ä¸?{rule_id} çš„è¯­æ³•è§„åˆ?)
        
        data = {
            "rule_id": grammar.rule_id,
            "rule_name": grammar.rule_name,
            "rule_summary": grammar.rule_summary,
            "examples": grammar.examples,
            "source": grammar.source,
            "is_starred": grammar.is_starred
        }
        
        return create_success_response(
            data=data,
            message=f"æˆåŠŸè·å–è¯­æ³•è§„åˆ™: {grammar.rule_name}"
        )
        
    except Exception as e:
        return create_error_response(f"è·å–è¯­æ³•è§„åˆ™å¤±è´¥: {str(e)}")


@app.get("/api/vocab", response_model=ApiResponse)
async def get_vocab_list():
    """è·å–è¯æ±‡åˆ—è¡¨"""
    try:
        vocab_list = data_service.get_vocab_data()
        
        return create_success_response(
            data=[vocab.model_dump() for vocab in vocab_list],
            message=f"æˆåŠŸè·å–è¯æ±‡åˆ—è¡¨ï¼Œå…± {len(vocab_list)} æ¡è®°å½?
        )
        
    except Exception as e:
        return create_error_response(f"è·å–è¯æ±‡åˆ—è¡¨å¤±è´¥: {str(e)}")


@app.get("/api/vocab/{vocab_id}", response_model=ApiResponse)
async def get_vocab_by_id(vocab_id: int):
    """æ ¹æ® ID è·å–å•ä¸ªè¯æ±‡è¯¦æƒ…"""
    try:
        vocab = data_service.get_vocab_by_id(vocab_id)
        
        if vocab is None:
            return create_error_response(f"æœªæ‰¾åˆ?ID ä¸?{vocab_id} çš„è¯æ±?)
        
        return create_success_response(
            data=vocab.model_dump(),
            message=f"æˆåŠŸè·å–è¯æ±‡: {vocab.vocab_body}"
        )
        
    except Exception as e:
        return create_error_response(f"è·å–è¯æ±‡è¯¦æƒ…å¤±è´¥: {str(e)}")


@app.get("/api/grammar", response_model=ApiResponse)
async def get_grammar_list():
    """è·å–è¯­æ³•è§„åˆ™åˆ—è¡¨"""
    try:
        grammar_list = data_service.get_grammar_data()
        
        return create_success_response(
            data=[grammar.model_dump() for grammar in grammar_list],
            message=f"æˆåŠŸè·å–è¯­æ³•è§„åˆ™åˆ—è¡¨ï¼Œå…± {len(grammar_list)} æ¡è®°å½?
        )
        
    except Exception as e:
        return create_error_response(f"è·å–è¯­æ³•è§„åˆ™åˆ—è¡¨å¤±è´¥: {str(e)}")


@app.get("/api/stats", response_model=ApiResponse)
async def get_stats():
    """è·å–æ•°æ®ç»Ÿè®¡ä¿¡æ¯"""
    try:
        vocab_list = data_service.get_vocab_data()
        grammar_list = data_service.get_grammar_data()
        
        stats = {
            "vocab": {
                "total": len(vocab_list),
                "starred": len([v for v in vocab_list if v.is_starred])
            },
            "grammar": {
                "total": len(grammar_list),
                "starred": len([g for g in grammar_list if g.is_starred])
            }
        }
        
        return create_success_response(
            data=stats,
            message="æˆåŠŸè·å–ç»Ÿè®¡æ•°æ®"
        )
        
    except Exception as e:
        return create_error_response(f"è·å–ç»Ÿè®¡æ•°æ®å¤±è´¥: {str(e)}")


@app.get("/api/articles", response_model=ApiResponse)
async def list_articles():
    """è·å–æ–‡ç« åˆ—è¡¨æ‘˜è¦ï¼ˆä» real_data_raw/result ç›®å½•æ‰«æ processed JSONï¼?""
    try:
        summaries = _collect_articles_summary()
        return create_success_response(
            data=summaries,
            message=f"æˆåŠŸè·å–æ–‡ç« åˆ—è¡¨ï¼Œå…± {len(summaries)} ç¯?
        )
    except Exception as e:
        return create_error_response(f"è·å–æ–‡ç« åˆ—è¡¨å¤±è´¥: {str(e)}")


@app.get("/api/articles/{article_id}", response_model=ApiResponse)
async def get_article_detail(article_id: int):
    """è·å–å•ç¯‡æ–‡ç« è¯¦æƒ…ï¼Œå¹¶æ ‡è®° token çš„å¯é€‰æ‹©æ€§ï¼ˆä»?text ç±»å‹å¯é€‰ï¼‰"""
    try:
        path = _find_article_file_by_id(article_id)
        if not path:
            return create_error_response(f"æ–‡ç« ä¸å­˜åœ? {article_id}")

        data = _load_json_file(path)
        data = _mark_tokens_selectable(data)

        return create_success_response(
            data=data,
            message=f"æˆåŠŸè·å–æ–‡ç« è¯¦æƒ…: {data.get('text_title', '')}"
        )
    except Exception as e:
        return create_error_response(f"è·å–æ–‡ç« è¯¦æƒ…å¤±è´¥: {str(e)}")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000) 

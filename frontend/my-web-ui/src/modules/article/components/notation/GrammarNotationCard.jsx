import { useState, useEffect } from 'react'
import { apiService } from '../../../../services/api'
import { colors } from '../../../../design-tokens'
import { useUIText } from '../../../../i18n/useUIText'

// Ëß£ÊûêÂíåÊ†ºÂºèÂåñËß£ÈáäÊñáÊú¨
const parseExplanation = (text) => {
  if (!text) return ''
  
  let cleanText = text
  
  // 1. Â§ÑÁêÜÂ≠óÂÖ∏Ê†ºÂºèÁöÑÂ≠óÁ¨¶‰∏≤ÔºàÂ¶Ç "{'explanation': '...'}" Êàñ '{"explanation": "..."}'Ôºâ
  if (text.includes("'explanation'") || text.includes('"explanation"')) {
    try {
      // Â∞ùËØïËß£Êûê JSON Ê†ºÂºè
      const jsonMatch = text.match(/\{[\s\S]*\}/)
      if (jsonMatch) {
        const jsonStr = jsonMatch[0]
        // ÂÖàÂ∞ùËØïÊ†áÂáÜ JSON Ëß£Êûê
        try {
          const parsed = JSON.parse(jsonStr)
          cleanText = parsed.explanation || parsed.definition || text
        } catch (e) {
          // Â¶ÇÊûú‰∏çÊòØÊ†áÂáÜ JSONÔºåÂ∞ùËØïÂ§ÑÁêÜ Python Â≠óÂÖ∏Ê†ºÂºèÔºàÂçïÂºïÂè∑Ôºâ
          // ‰ΩøÁî®Êõ¥Êô∫ËÉΩÁöÑÊñπÊ≥ïÔºöÂè™ÊõøÊç¢ÈîÆÂíåÂ≠óÁ¨¶‰∏≤ÂàÜÈöîÁ¨¶ÁöÑÂçïÂºïÂè∑
          // ÂÖàÂ∞ùËØïÁõ¥Êé•ÊèêÂèñ explanation Â≠óÊÆµÁöÑÂÄºÔºàÊîØÊåÅÂ§öË°åÂíåËΩ¨‰πâÂ≠óÁ¨¶Ôºâ
          // üîß ‰øÆÂ§çÔºöÂ§ÑÁêÜË¢´Êà™Êñ≠ÁöÑ JSONÔºàÁº∫Â∞ëÁªìÊùüÂºïÂè∑ÊàñÂè≥Â§ßÊã¨Âè∑Ôºâ
          // ÂÖàÂ∞ùËØïÂÆåÊï¥ÂåπÈÖçÔºàÊúâÁªìÊùüÂºïÂè∑Ôºâ
          let explanationMatch = text.match(/['"]explanation['"]\s*:\s*['"]([\s\S]*?)['"]\s*[,}]/s)
          if (!explanationMatch) {
            // Â¶ÇÊûúÂÆåÊï¥ÂåπÈÖçÂ§±Ë¥•ÔºåÂ∞ùËØïÂåπÈÖçÂà∞Â≠óÁ¨¶‰∏≤Êú´Â∞æÔºàÂ§ÑÁêÜË¢´Êà™Êñ≠ÁöÑ JSONÔºâ
            explanationMatch = text.match(/['"]explanation['"]\s*:\s*['"]([\s\S]*?)(?:['"]\s*[,}]|$)/s)
          }
          if (explanationMatch) {
            cleanText = explanationMatch[1]
              .replace(/\\n/g, '\n')  // Â§ÑÁêÜËΩ¨‰πâÁöÑÊç¢Ë°åÁ¨¶
              .replace(/\\'/g, "'")   // Â§ÑÁêÜËΩ¨‰πâÁöÑÂçïÂºïÂè∑
              .replace(/\\"/g, '"')   // Â§ÑÁêÜËΩ¨‰πâÁöÑÂèåÂºïÂè∑
          } else {
            // Â¶ÇÊûúÊ≠£ÂàôÂåπÈÖçÂ§±Ë¥•ÔºåÂ∞ùËØïÂ∞ÜÂçïÂºïÂè∑ÊõøÊç¢‰∏∫ÂèåÂºïÂè∑ÔºàÁÆÄÂçïÂ§ÑÁêÜÔºâ
            const normalized = jsonStr.replace(/'/g, '"')
            try {
              const parsed = JSON.parse(normalized)
              cleanText = parsed.explanation || parsed.definition || text
            } catch (e2) {
              // Â¶ÇÊûúËøòÊòØÂ§±Ë¥•ÔºåÂ∞ùËØï‰ªéÊà™Êñ≠ÁöÑ JSON ‰∏≠ÊèêÂèñ explanation ÂÄº
              // Êü•Êâæ "explanation": " ‰πãÂêéÁöÑÊâÄÊúâÂÜÖÂÆπÔºàÁõ¥Âà∞Â≠óÁ¨¶‰∏≤ÁªìÊùüÊàñÊâæÂà∞ÂºïÂè∑Ôºâ
              const truncatedMatch = text.match(/['"]explanation['"]\s*:\s*['"]([\s\S]*)/)
              if (truncatedMatch) {
                cleanText = truncatedMatch[1]
                  .replace(/\\n/g, '\n')
                  .replace(/\\'/g, "'")
                  .replace(/\\"/g, '"')
              } else {
                // Â¶ÇÊûúËøòÊòØÂ§±Ë¥•Ôºå‰ΩøÁî®ÂéüÂßãÊñáÊú¨
                cleanText = text
              }
            }
          }
        }
      } else {
        // üîß ‰øÆÂ§çÔºöÂ¶ÇÊûúÊ≤°ÊúâÊâæÂà∞ÂÆåÊï¥ÁöÑ JSON ÂØπË±°ÔºàÂèØËÉΩË¢´Êà™Êñ≠ÔºâÔºåÂ∞ùËØïÁõ¥Êé•ÊèêÂèñ explanation Â≠óÊÆµ
        const truncatedMatch = text.match(/['"]explanation['"]\s*:\s*['"]([\s\S]*)/)
        if (truncatedMatch) {
          cleanText = truncatedMatch[1]
            .replace(/\\n/g, '\n')
            .replace(/\\'/g, "'")
            .replace(/\\"/g, '"')
        }
      }
    } catch (e) {
      // Ëß£ÊûêÂ§±Ë¥•Ôºå‰ΩøÁî®ÂéüÂßãÊñáÊú¨
    }
  }
  
  // 2. Â§ÑÁêÜ‰ª£Á†ÅÂùóÊ†ºÂºèÔºà```json ... ```Ôºâ
  if (cleanText.includes('```json') && cleanText.includes('```')) {
    try {
      const jsonMatch = cleanText.match(/```json\n(.*?)\n```/s)
      if (jsonMatch) {
        const jsonStr = jsonMatch[1]
        const parsed = JSON.parse(jsonStr)
        cleanText = parsed.explanation || parsed.definition || cleanText
      }
    } catch (e) {
      // Ëß£ÊûêÂ§±Ë¥•ÔºåÁªßÁª≠‰ΩøÁî® cleanText
    }
  }
  
  // 3. Ê∏ÖÁêÜÂ§ö‰ΩôÁöÑËΩ¨‰πâÂ≠óÁ¨¶ÂíåÊ†ºÂºèÂåñ
  // Â∞Ü \n ËΩ¨Êç¢‰∏∫ÂÆûÈôÖÁöÑÊç¢Ë°å
  cleanText = cleanText.replace(/\\n/g, '\n')
  // ÁßªÈô§Â§ö‰ΩôÁöÑÁ©∫ÁôΩË°åÔºàËøûÁª≠‰∏§‰∏™‰ª•‰∏äÁöÑÊç¢Ë°åÁ¨¶Ôºâ
  cleanText = cleanText.replace(/\n{3,}/g, '\n\n')
  // ÂéªÈô§È¶ñÂ∞æÁ©∫ÁôΩ
  cleanText = cleanText.trim()
  
  return cleanText
}

/**
 * GrammarNotationCard - ËØ≠Ê≥ïÊ≥®ÈáäÂç°ÁâáÁªÑ‰ª∂Ôºà‰ªé components/ ËøÅÁßªËá≥ notation/Ôºâ
 */
export default function GrammarNotationCard({ 
  isVisible = false, 
  textId = null,
  sentenceId = null,
  position = { top: 0, left: 0, right: 'auto' },
  onClose = null,
  onMouseEnter = null,
  onMouseLeave = null,
  cachedGrammarRules = null,
  getGrammarRuleById = null
}) {
  const t = useUIText()
  const [grammarRules, setGrammarRules] = useState([])
  const [isLoading, setIsLoading] = useState(false)
  const [error, setError] = useState(null)

  useEffect(() => {
    if (isVisible && textId && sentenceId) {
      if (cachedGrammarRules && getGrammarRuleById) {
        const rules = cachedGrammarRules.map(notation => {
          const rule = getGrammarRuleById(notation.grammar_id)
          if (!rule) {
            console.warn(`‚ö†Ô∏è [GrammarNotationCard] Grammar rule not found in cache for grammar_id=${notation.grammar_id}`)
            return null
          }
          let contextExplanation = notation.context_explanation || notation.explanation_context || ''
          if (rule.examples && Array.isArray(rule.examples)) {
            const matchingExample = rule.examples.find(ex => 
              Number(ex.text_id) === Number(notation.text_id) && 
              Number(ex.sentence_id) === Number(notation.sentence_id)
            )
            if (matchingExample) {
              contextExplanation = matchingExample.explanation_context || ''
            }
          }
          const result = {
            ...rule,
            context_explanation: contextExplanation,
            notation_id: notation.notation_id || `${notation.text_id}:${notation.sentence_id}`,
            marked_token_ids: notation.marked_token_ids || [],
            grammar_id: notation.grammar_id,
            text_id: notation.text_id,
            sentence_id: notation.sentence_id
          }
          return result
        }).filter(Boolean)
        setGrammarRules(rules)
        setIsLoading(false)
        setError(null)
      } else {
        setIsLoading(true)
        setError(null)
        fetchSentenceGrammarRules(textId, sentenceId)
          .then(rules => {
            setGrammarRules(rules)
            setIsLoading(false)
          })
          .catch(error => {
            console.error('‚ùå [GrammarNotationCard] Error fetching sentence grammar rules:', error)
            setError(error.message || 'Failed to load grammar rules')
            setIsLoading(false)
          })
      }
    } else {
      setGrammarRules([])
      setError(null)
    }
  }, [isVisible, textId, sentenceId, cachedGrammarRules, getGrammarRuleById])

  const fetchSentenceGrammarRules = async (textId, sentenceId) => {
    try {
      const response = await apiService.getSentenceGrammarRules(textId, sentenceId)
      if (response && response.data) {
        if (Array.isArray(response.data)) return response.data
        if (response.data.grammar_rules) return response.data.grammar_rules
        if (response.data.rule_id) return [response.data]
        if (response.data.grammar_id) {
          try {
            const ruleResponse = await apiService.getGrammarById(response.data.grammar_id)
            if (ruleResponse && ruleResponse.data) {
              return [{
                ...ruleResponse.data,
                context_explanation: response.data.context_explanation || '',
                notation_id: response.data.notation_id || `${response.data.text_id}:${response.data.sentence_id}`,
                marked_token_ids: response.data.marked_token_ids || []
              }]
            }
          } catch (ruleError) {
            console.warn(`Failed to fetch grammar rule ${response.data.grammar_id}:`, ruleError)
          }
        }
      }
      return []
    } catch (error) {
      console.error('Error in fetchSentenceGrammarRules:', error)
      try {
        const notationsResponse = await apiService.getGrammarNotations(textId)
        const notations = Array.isArray(notationsResponse) ? notationsResponse : 
                         (notationsResponse?.data && Array.isArray(notationsResponse.data) ? notationsResponse.data : [])
        const sentenceNotations = notations.filter(notation => 
          notation.sentence_id === sentenceId
        )
        const grammarRules = []
        for (const notation of sentenceNotations) {
          try {
            const ruleResponse = await apiService.getGrammarById(notation.grammar_id)
            if (ruleResponse && ruleResponse.data) {
              grammarRules.push({
                ...ruleResponse.data,
                context_explanation: notation.context_explanation || '',
                notation_id: notation.notation_id
              })
            }
          } catch (ruleError) {
            console.warn(`Failed to fetch grammar rule ${notation.grammar_id}:`, ruleError)
          }
        }
        return grammarRules
      } catch (fallbackError) {
        console.error('Fallback method also failed:', fallbackError)
        throw fallbackError
      }
    }
  }

  if (!isVisible) return null

  return (
    <div 
      className="fixed bg-white border border-gray-300 rounded-lg shadow-lg z-50 notation-card"
      style={{
        top: `${position.top}px`,
        left: position.left !== 'auto' ? `${position.left}px` : 'auto',
        right: position.right !== 'auto' ? `${position.right}px` : 'auto',
        transform: position.left !== 'auto' ? 'none' : 'translateX(-50%)',
        width: '100%',
        maxWidth: '1200px',  // ‚úÖ Â¢ûÂä†ÊúÄÂ§ßÂÆΩÂ∫¶Ôºö‰ªé 800px Â¢ûÂä†Âà∞ 1200px
        minWidth: '300px',
        maxHeight: '600px',  // ‚úÖ Â¢ûÂä†ÊúÄÂ§ßÈ´òÂ∫¶Ôºö‰ªé 200px Â¢ûÂä†Âà∞ 600pxÔºåÈÅøÂÖçÂÜÖÂÆπÊà™Êñ≠
        minHeight: '80px',
        height: 'auto',
        padding: '16px',
        boxSizing: 'border-box',
        display: 'block'
      }}
      onMouseEnter={onMouseEnter}
      onMouseLeave={onMouseLeave}
      onClick={(e) => e.stopPropagation()}
    >
      <div 
        style={{ 
          maxHeight: 'calc(600px - 16px - 16px)',  // ‚úÖ ÂêåÊ≠•Êõ¥Êñ∞ÂÜÖÈÉ®ÂÆπÂô®ÊúÄÂ§ßÈ´òÂ∫¶
          height: 'auto',
          overflowY: 'auto',
          overflowX: 'hidden',
          wordWrap: 'break-word',  // ‚úÖ Á°Æ‰øùÈïøÂçïËØçÂèØ‰ª•Êç¢Ë°å
          wordBreak: 'break-word'  // ‚úÖ Èò≤Ê≠¢ÊñáÊú¨Ê∫¢Âá∫
        }}
      >
        {isLoading && (
          <div style={{ display: 'flex', alignItems: 'center', justifyContent: 'center', padding: '16px 0' }}>
            <div style={{ 
              animation: 'spin 1s linear infinite',
              borderRadius: '50%',
              height: '24px',
              width: '24px',
              borderBottom: `2px solid ${colors.primary[600]}`
            }}></div>
            <span style={{ marginLeft: '8px', color: '#6b7280' }}>Âä†ËΩΩ‰∏≠...</span>
          </div>
        )}

        {error && (
          <div style={{ color: '#ef4444', fontSize: '14px', padding: '8px 0' }}>
            Âä†ËΩΩÂ§±Ë¥•: {error}
          </div>
        )}

        {!isLoading && !error && grammarRules.length === 0 && (
          <div style={{ color: '#6b7280', fontSize: '14px', padding: '8px 0' }}>
            ËØ•Âè•Â≠êÊöÇÊó†ËØ≠Ê≥ïÊ≥®Èáä
          </div>
        )}

        {!isLoading && !error && grammarRules.length > 0 && (
          <div style={{ display: 'flex', flexDirection: 'column', gap: '16px' }}>
            {grammarRules.map((rule, index) => (
              <div 
                key={rule.notation_id || index} 
                style={{ 
                  borderBottom: index < grammarRules.length - 1 ? '1px solid #f3f4f6' : 'none',
                  paddingBottom: '12px'
                }}
              >
                <div style={{ 
                  fontWeight: '600', 
                  color: colors.primary[600], 
                  marginBottom: '8px',
                  fontSize: '16px'
                }}>
                  {rule.rule_name || rule.name}
                </div>
                <div style={{ fontSize: '14px', color: '#374151', marginBottom: '8px' }}>
                  <span style={{ fontWeight: '500' }}>{t('ËßÑÂàôËß£Èáä:')}</span>
                  <div style={{ 
                    marginTop: '4px', 
                    paddingLeft: '8px', 
                    borderLeft: `2px solid ${colors.primary[100]}`,
                    padding: '4px 0 4px 8px',
                    whiteSpace: 'pre-wrap',
                    wordWrap: 'break-word',  // ‚úÖ Á°Æ‰øùÈïøÊñáÊú¨ÂèØ‰ª•Êç¢Ë°å
                    wordBreak: 'break-word',  // ‚úÖ Èò≤Ê≠¢ÊñáÊú¨Ê∫¢Âá∫
                    overflowWrap: 'break-word'  // ‚úÖ È¢ùÂ§ñÁöÑÊç¢Ë°å‰øùÊä§
                  }}>
                    {parseExplanation(rule.rule_summary || rule.explanation || '')}
                  </div>
                </div>
                {rule.context_explanation && (
                  <div style={{ fontSize: '14px', color: '#6b7280' }}>
                    <span style={{ fontWeight: '500' }}>{t('‰∏ä‰∏ãÊñáËß£Èáä:')}</span>
                    <div style={{ 
                      marginTop: '4px', 
                      paddingLeft: '8px', 
                      borderLeft: '2px solid #dcfce7',
                      padding: '4px 0 4px 8px',
                      whiteSpace: 'pre-wrap',
                      wordWrap: 'break-word',  // ‚úÖ Á°Æ‰øùÈïøÊñáÊú¨ÂèØ‰ª•Êç¢Ë°å
                      wordBreak: 'break-word',  // ‚úÖ Èò≤Ê≠¢ÊñáÊú¨Ê∫¢Âá∫
                      overflowWrap: 'break-word'  // ‚úÖ È¢ùÂ§ñÁöÑÊç¢Ë°å‰øùÊä§
                    }}>
                      {parseExplanation(rule.context_explanation || '')}
                    </div>
                  </div>
                )}
              </div>
            ))}
          </div>
        )}
      </div>
    </div>
  )
}



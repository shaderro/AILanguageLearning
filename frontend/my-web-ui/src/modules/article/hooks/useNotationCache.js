import { useState, useEffect, useCallback } from 'react'
import { apiService } from '../../../services/api'

/**
 * Áªü‰∏ÄÁöÑNotationÁºìÂ≠òÁÆ°ÁêÜÂô®
 * Âú®ÊñáÁ´†È°µÈù¢Âä†ËΩΩÊó∂È¢ÑÂä†ËΩΩÊâÄÊúâgrammar notationÂíåvocab notationÊï∞ÊçÆ
 */
export function useNotationCache(articleId) {
  // Grammar notationsÁºìÂ≠ò
  const [grammarNotations, setGrammarNotations] = useState([])
  const [grammarRulesCache, setGrammarRulesCache] = useState(new Map()) // grammarId -> grammarRule
  
  // Vocab notationsÁºìÂ≠ò
  const [vocabNotations, setVocabNotations] = useState([])
  const [vocabExamplesCache, setVocabExamplesCache] = useState(new Map()) // key -> vocabExample
  
  // Âä†ËΩΩÁä∂ÊÄÅ
  const [isLoading, setIsLoading] = useState(false)
  const [error, setError] = useState(null)
  const [isInitialized, setIsInitialized] = useState(false)

  // È¢ÑÂä†ËΩΩÊâÄÊúâÊï∞ÊçÆ
  const loadAllNotations = useCallback(async (textId) => {
    if (!textId) return

    // ÁßªÈô§ËØ¶ÁªÜÊó•ÂøóÔºàÂ∑≤ÈÄöËøáÊµãËØïÔºåÂáèÂ∞ë‰∏çÂøÖË¶ÅÁöÑÊó•ÂøóËæìÂá∫Ôºâ
    setIsLoading(true)
    setError(null)

    try {
      // Âπ∂Ë°åÂä†ËΩΩgrammar notationsÂíåvocab notations
      const [grammarResponse, vocabResponse] = await Promise.all([
        apiService.getGrammarNotations(textId),
        apiService.getVocabNotations(textId)
      ])

      // ÁßªÈô§ËØ¶ÁªÜÂìçÂ∫îÊó•ÂøóÔºàÂäüËÉΩÂ∑≤ÈÄöËøáÊµãËØïÔºâ

      // Â§ÑÁêÜgrammar notations
      console.log('üîç [useNotationCache] Grammar response:', grammarResponse)
      if (grammarResponse && grammarResponse.data) {
        const grammarData = grammarResponse.data.notations || grammarResponse.data
        const grammarList = Array.isArray(grammarData) ? grammarData : []
        console.log('üìù [useNotationCache] Loaded grammar notations:', grammarList.length, grammarList)
        setGrammarNotations(grammarList)

        // È¢ÑÂä†ËΩΩÊâÄÊúâgrammar rules
        const grammarRulesMap = new Map()
        for (const notation of grammarList) {
          if (notation.grammar_id && !grammarRulesMap.has(notation.grammar_id)) {
            try {
              const ruleResponse = await apiService.getGrammarById(notation.grammar_id)
              if (ruleResponse && ruleResponse.data) {
                grammarRulesMap.set(notation.grammar_id, ruleResponse.data)
                console.log('üìö [useNotationCache] Cached grammar rule:', notation.grammar_id, ruleResponse.data.rule_name)
              }
            } catch (err) {
              console.warn('‚ö†Ô∏è [useNotationCache] Failed to load grammar rule:', notation.grammar_id, err)
            }
          }
        }
        setGrammarRulesCache(grammarRulesMap)
        console.log('‚úÖ [useNotationCache] Grammar cache ready:', grammarRulesMap.size, 'rules')
      }

      // Â§ÑÁêÜvocab notationsÔºàÊñ∞APIÔºâ
      console.log('üîç [useNotationCache] Vocab response:', vocabResponse)
      console.log('üîç [useNotationCache] vocabResponse.success:', vocabResponse?.success)
      console.log('üîç [useNotationCache] vocabResponse.data:', vocabResponse?.data)
      
      if (vocabResponse && vocabResponse.success && vocabResponse.data) {
        // Êñ∞APIËøîÂõûÊ†ºÂºèÔºö{ success: true, data: { notations: [...], count: N } }
        const vocabData = vocabResponse.data.notations || vocabResponse.data
        const vocabList = Array.isArray(vocabData) ? vocabData : []
        
        console.log('üìù [useNotationCache] vocabData:', vocabData)
        console.log('üìù [useNotationCache] vocabList length:', vocabList.length)
        console.log('üìù [useNotationCache] vocabList:', vocabList)
        
        // ËΩ¨Êç¢‰∏∫ÂâçÁ´Ø‰ΩøÁî®ÁöÑÊ†ºÂºèÔºàÁ°Æ‰øùÊúâtoken_indexÂ≠óÊÆµÔºâ
        const formattedVocabNotations = vocabList.map(notation => ({
          user_id: notation.user_id,
          text_id: notation.text_id,
          sentence_id: notation.sentence_id,
          token_id: notation.token_id,
          token_index: notation.token_id, // Ê∑ªÂä†token_indexÂ≠óÊÆµ‰Ωú‰∏∫Âà´Âêç
          vocab_id: notation.vocab_id,
          created_at: notation.created_at
        }))
        
        console.log('‚úÖ [useNotationCache] Formatted vocab notations:', formattedVocabNotations)
        setVocabNotations(formattedVocabNotations)
        // ‰∏çÂÜçÈ¢ÑÂä†ËΩΩÊâÄÊúâ examplesÔºöÊîπ‰∏∫ÊåâÈúÄÊáíÂä†ËΩΩ + Êñ∞Âª∫ÂêéÂçïÊ¨°ÂÜôÁºìÂ≠ò
      } else if (vocabResponse && vocabResponse.data) {
        // ÂÖºÂÆπÊóßÁöÑAPIÊ†ºÂºèÔºàÁõ¥Êé•‰ªédata‰∏≠Ëé∑ÂèñÊï∞ÁªÑÔºâ
        const vocabData = Array.isArray(vocabResponse.data) ? vocabResponse.data : []
        const formattedVocabNotations = vocabData.map(notation => ({
          user_id: notation.user_id,
          text_id: notation.text_id,
          sentence_id: notation.sentence_id,
          token_id: notation.token_id,
          token_index: notation.token_id,
          vocab_id: notation.vocab_id,
          created_at: notation.created_at
        }))
        setVocabNotations(formattedVocabNotations)
        // ‰∏çÂÜçÈ¢ÑÂä†ËΩΩÊâÄÊúâ examplesÔºöÊîπ‰∏∫ÊåâÈúÄÊáíÂä†ËΩΩ + Êñ∞Âª∫ÂêéÂçïÊ¨°ÂÜôÁºìÂ≠ò
      } else {
        console.warn('‚ö†Ô∏è [useNotationCache] No vocab notations found or invalid response format')
        setVocabNotations([])
      }

      setIsInitialized(true)
      // ÁßªÈô§ÊàêÂäüÊó•ÂøóÔºàÂ∑≤ÈÄöËøáÊµãËØïÔºâ

    } catch (err) {
      console.error('‚ùå [useNotationCache] Error loading notations:', err)
      setError(err.message || 'Failed to load notations')
    } finally {
      setIsLoading(false)
    }
  }, [])

  // ÂàùÂßãÂåñÂä†ËΩΩ
  useEffect(() => {
    if (articleId && !isInitialized) {
      loadAllNotations(articleId)
    }
  }, [articleId, isInitialized, loadAllNotations])

  // Ëé∑ÂèñÂè•Â≠êÁöÑgrammar notations
  const getGrammarNotationsForSentence = useCallback((sentenceId) => {
    return grammarNotations.filter(notation => 
      notation.sentence_id === sentenceId
    )
  }, [grammarNotations])

  // Ëé∑ÂèñÂè•Â≠êÁöÑvocab notations
  const getVocabNotationsForSentence = useCallback((sentenceId) => {
    // Á°Æ‰øùÁ±ªÂûã‰∏ÄËá¥ÔºàÊï∞Â≠óÊØîËæÉÔºâ
    const sid = Number(sentenceId)
    
    const filtered = vocabNotations.filter(notation => 
      Number(notation.sentence_id) === sid
    )
    
    return filtered
  }, [vocabNotations])

  // Ëé∑ÂèñÁâπÂÆötokenÁöÑvocab exampleÔºàÈÄöËøáAPIÊåâÈúÄËé∑ÂèñÔºâ
  const getVocabExampleForToken = useCallback(async (textId, sentenceId, tokenIndex) => {
    const key = `${textId}:${sentenceId}:${tokenIndex}`
    
    // È¶ñÂÖàÊ£ÄÊü•ÁºìÂ≠ò
    if (vocabExamplesCache.has(key)) {
      return vocabExamplesCache.get(key)
    }
    
    // Â¶ÇÊûúÁºìÂ≠ò‰∏≠Ê≤°ÊúâÔºåÈÄöËøáAPIËé∑Âèñ
    try {
      const { apiService } = await import('../../../services/api')
      const axiosResp = await apiService.getVocabExampleByLocation(textId, sentenceId, tokenIndex)
      // axiosResp -> { data: { success, data } } in mock
      const payload = axiosResp?.data?.data ?? axiosResp?.data ?? axiosResp

      if (payload && payload.vocab_id) {
        // Ê†áÂáÜÂåñÔºöÁ°Æ‰øùÊúâ token_index ‰æõÁºìÂ≠ò key ‰ΩøÁî®
        const normalized = {
          vocab_id: payload.vocab_id,
          text_id: payload.text_id,
          sentence_id: payload.sentence_id,
          token_index: payload.token_index ?? tokenIndex,
          context_explanation: payload.context_explanation,
          token_indices: payload.token_indices || []
        }
        setVocabExamplesCache(prev => {
          const newCache = new Map(prev)
          newCache.set(key, normalized)
          return newCache
        })
        return normalized
      } else {
        return null
      }
    } catch (error) {
      console.error('‚ùå [getVocabExampleForToken] API error:', error)
      return null
    }
  }, [vocabExamplesCache])

  // Ëé∑Âèñgrammar ruleËØ¶ÊÉÖ
  const getGrammarRuleById = useCallback((grammarId) => {
    return grammarRulesCache.get(grammarId) || null
  }, [grammarRulesCache])

  // Ê£ÄÊü•Âè•Â≠êÊòØÂê¶Êúâgrammar notation
  const hasGrammarNotation = useCallback((sentenceId) => {
    return grammarNotations.some(notation => 
      notation.sentence_id === sentenceId
    )
  }, [grammarNotations])

  // Ê£ÄÊü•Âè•Â≠êÊòØÂê¶Êúâvocab notation
  const hasVocabNotation = useCallback((sentenceId) => {
    return vocabNotations.some(notation => 
      notation.sentence_id === sentenceId
    )
  }, [vocabNotations])

  // Âà∑Êñ∞ÁºìÂ≠òÔºàÂΩìÊúâÊñ∞ÁöÑnotationË¢´ÂàõÂª∫Êó∂Ë∞ÉÁî®Ôºâ
  const refreshCache = useCallback(() => {
    if (articleId) {
      console.log('üîÑ [useNotationCache] Refreshing cache for articleId:', articleId)
      setIsInitialized(false)
      loadAllNotations(articleId)
    }
  }, [articleId, loadAllNotations])

  // Ê∑ªÂä†Êñ∞ÁöÑgrammar notationÂà∞ÁºìÂ≠ò
  const addGrammarNotationToCache = useCallback((notation) => {
    console.log('‚ûï [useNotationCache] Adding grammar notation to cache:', notation)
    setGrammarNotations(prev => {
      // Ê£ÄÊü•ÊòØÂê¶Â∑≤Â≠òÂú®ÔºåÈÅøÂÖçÈáçÂ§çÊ∑ªÂä†
      const exists = prev.some(n => 
        n.text_id === notation.text_id && 
        n.sentence_id === notation.sentence_id && 
        n.grammar_id === notation.grammar_id
      )
      if (exists) {
        console.log('‚ö†Ô∏è [useNotationCache] Grammar notation already exists in cache')
        return prev
      }
      return [...prev, notation]
    })
  }, [])

  // Ê∑ªÂä†Êñ∞ÁöÑvocab notationÂà∞ÁºìÂ≠ò
  const addVocabNotationToCache = useCallback((notation) => {
    console.log('‚ûï [useNotationCache] Adding vocab notation to cache:', notation)
    setVocabNotations(prev => {
      // Ê£ÄÊü•ÊòØÂê¶Â∑≤Â≠òÂú®ÔºåÈÅøÂÖçÈáçÂ§çÊ∑ªÂä†
      const exists = prev.some(n => 
        n.text_id === notation.text_id && 
        n.sentence_id === notation.sentence_id && 
        n.token_index === notation.token_index
      )
      if (exists) {
        console.log('‚ö†Ô∏è [useNotationCache] Vocab notation already exists in cache')
        return prev
      }
      return [...prev, notation]
    })
  }, [])

  // Ê∑ªÂä†Êñ∞ÁöÑgrammar ruleÂà∞ÁºìÂ≠ò
  const addGrammarRuleToCache = useCallback((rule) => {
    console.log('‚ûï [useNotationCache] Adding grammar rule to cache:', rule)
    setGrammarRulesCache(prev => {
      const newCache = new Map(prev)
      newCache.set(rule.rule_id, rule)
      return newCache
    })
  }, [])

  // Ê∑ªÂä†Êñ∞ÁöÑvocab exampleÂà∞ÁºìÂ≠ò
  const addVocabExampleToCache = useCallback((example) => {
    console.log('‚ûï [useNotationCache] Adding vocab example to cache:', example)
    const key = `${example.text_id}:${example.sentence_id}:${example.token_index}`
    setVocabExamplesCache(prev => {
      const newCache = new Map(prev)
      newCache.set(key, example)
      return newCache
    })
  }, [])

  // ÂàõÂª∫vocab notationÔºà‰ΩøÁî®Êñ∞APIÔºâ
  const createVocabNotation = useCallback(async (textId, sentenceId, tokenId, vocabId = null, userId = 'default_user') => {
    try {
      console.log('‚ûï [useNotationCache] Creating vocab notation:', { textId, sentenceId, tokenId, vocabId, userId })
      
      const response = await apiService.createVocabNotation(userId, textId, sentenceId, tokenId, vocabId)
      
      // Â§ÑÁêÜÂìçÂ∫îÔºàÂèØËÉΩ‰ªéÊã¶Êà™Âô®ËøîÂõû‰∏çÂêåÁöÑÊ†ºÂºèÔºâ
      const result = response?.data || response
      const success = result?.success !== false && (result?.success === true || response?.status === 200)
      
      if (success) {
        // ÂàõÂª∫vocab notationÂØπË±°
        const newNotation = {
          user_id: userId,
          text_id: textId,
          sentence_id: sentenceId,
          token_id: tokenId,
          token_index: tokenId,  // Ê∑ªÂä†token_index‰Ωú‰∏∫Âà´Âêç
          vocab_id: vocabId,
          created_at: new Date().toISOString()
        }
        
        // Ê∑ªÂä†Âà∞ÁºìÂ≠ò
        addVocabNotationToCache(newNotation)
        
        // Âè™ÊãâÂèñ‰∏ÄÊ¨°ËØ•‰ΩçÁΩÆÁöÑ example Âπ∂ÂÜôÂÖ•ÁºìÂ≠òÔºåÈÅøÂÖçÂêéÁª≠ÊÇ¨ÊµÆÈáçÂ§çËØ∑Ê±Ç
        try {
          const exampleResp = await apiService.getVocabExampleByLocation(textId, sentenceId, tokenId)
          const payload = exampleResp?.data?.data ?? exampleResp?.data ?? exampleResp
          if (payload && (payload.vocab_id || vocabId)) {
            const example = {
              vocab_id: payload.vocab_id ?? vocabId,
              text_id: textId,
              sentence_id: sentenceId,
              token_index: payload.token_index ?? tokenId,
              context_explanation: payload.context_explanation || '',
              token_indices: payload.token_indices || [tokenId]
            }
            const key = `${textId}:${sentenceId}:${example.token_index}`
            setVocabExamplesCache(prev => {
              const next = new Map(prev)
              next.set(key, example)
              return next
            })
            console.log('‚úÖ [useNotationCache] Cached vocab example for new notation:', example)
          }
        } catch (e) {
          console.warn('‚ö†Ô∏è [useNotationCache] Failed to fetch example for new notation (cached will be missing until first hover fetch):', e?.message || e)
        }
        
        console.log('‚úÖ [useNotationCache] Vocab notation created and added to cache:', newNotation)
        return { success: true, notation: newNotation }
      } else {
        console.error('‚ùå [useNotationCache] Failed to create vocab notation:', result?.error || 'Unknown error')
        return { success: false, error: result?.error || 'Unknown error' }
      }
    } catch (error) {
      console.error('‚ùå [useNotationCache] Error creating vocab notation:', error)
      return { success: false, error: error.message || 'Failed to create vocab notation' }
    }
  }, [addVocabNotationToCache])

  return {
    // Áä∂ÊÄÅ
    isLoading,
    error,
    isInitialized,
    
    // Grammar notations
    grammarNotations,
    getGrammarNotationsForSentence,
    getGrammarRuleById,
    hasGrammarNotation,
    
    // Vocab notations
    vocabNotations,
    getVocabNotationsForSentence,
    getVocabExampleForToken,
    hasVocabNotation,
    
    // ÁºìÂ≠òÁÆ°ÁêÜ
    refreshCache,
    
    // ÂÆûÊó∂ÁºìÂ≠òÊõ¥Êñ∞
    addGrammarNotationToCache,
    addVocabNotationToCache,
    addGrammarRuleToCache,
    addVocabExampleToCache,
    
    // ÂàõÂª∫ÂäüËÉΩÔºàÊñ∞APIÔºâ
    createVocabNotation
  }
}

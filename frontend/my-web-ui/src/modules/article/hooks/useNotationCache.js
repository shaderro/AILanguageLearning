import { useState, useEffect, useCallback } from 'react'
import { apiService } from '../../../services/api'

/**
 * ç»Ÿä¸€çš„Notationç¼“å­˜ç®¡ç†å™¨
 * åœ¨æ–‡ç« é¡µé¢åŠ è½½æ—¶é¢„åŠ è½½æ‰€æœ‰grammar notationå’Œvocab notationæ•°æ®
 */
export function useNotationCache(articleId) {
  // Grammar notationsç¼“å­˜
  const [grammarNotations, setGrammarNotations] = useState([])
  const [grammarRulesCache, setGrammarRulesCache] = useState(new Map()) // grammarId -> grammarRule
  
  // Vocab notationsç¼“å­˜
  const [vocabNotations, setVocabNotations] = useState([])
  const [vocabExamplesCache, setVocabExamplesCache] = useState(new Map()) // key -> vocabExample
  
  // åŠ è½½çŠ¶æ€
  const [isLoading, setIsLoading] = useState(false)
  const [error, setError] = useState(null)
  const [isInitialized, setIsInitialized] = useState(false)

  // é¢„åŠ è½½æ‰€æœ‰æ•°æ®
  const loadAllNotations = useCallback(async (textId) => {
    if (!textId) return

    // ç§»é™¤è¯¦ç»†æ—¥å¿—ï¼ˆå·²é€šè¿‡æµ‹è¯•ï¼Œå‡å°‘ä¸å¿…è¦çš„æ—¥å¿—è¾“å‡ºï¼‰
    setIsLoading(true)
    setError(null)

    try {
      // å¹¶è¡ŒåŠ è½½grammar notationså’Œvocab notations
      const [grammarResponse, vocabResponse] = await Promise.all([
        apiService.getGrammarNotations(textId),
        apiService.getVocabNotations(textId)
      ])

      // ç§»é™¤è¯¦ç»†å“åº”æ—¥å¿—ï¼ˆåŠŸèƒ½å·²é€šè¿‡æµ‹è¯•ï¼‰

      // å¤„ç†grammar notations
      if (grammarResponse && grammarResponse.data) {
        const grammarData = Array.isArray(grammarResponse.data) ? grammarResponse.data : []
        setGrammarNotations(grammarData)
        // ç§»é™¤è¯¦ç»†æ—¥å¿—ï¼ˆå·²é€šè¿‡æµ‹è¯•ï¼‰

        // é¢„åŠ è½½æ‰€æœ‰grammar rules
        const grammarRulesMap = new Map()
        for (const notation of grammarData) {
          if (notation.grammar_id && !grammarRulesMap.has(notation.grammar_id)) {
            try {
              const ruleResponse = await apiService.getGrammarById(notation.grammar_id)
              if (ruleResponse && ruleResponse.data) {
                grammarRulesMap.set(notation.grammar_id, ruleResponse.data)
              }
            } catch (err) {
              console.warn('âš ï¸ [useNotationCache] Failed to load grammar rule:', notation.grammar_id, err)
            }
          }
        }
        setGrammarRulesCache(grammarRulesMap)
        // ç§»é™¤è¯¦ç»†æ—¥å¿—ï¼ˆå·²é€šè¿‡æµ‹è¯•ï¼‰
      }

      // å¤„ç†vocab notationsï¼ˆæ–°APIï¼‰
      if (vocabResponse && vocabResponse.success && vocabResponse.data) {
        // æ–°APIè¿”å›æ ¼å¼ï¼š{ success: true, data: { notations: [...], count: N } }
        const vocabData = vocabResponse.data.notations || vocabResponse.data
        const vocabList = Array.isArray(vocabData) ? vocabData : []
        
        // è½¬æ¢ä¸ºå‰ç«¯ä½¿ç”¨çš„æ ¼å¼ï¼ˆç¡®ä¿æœ‰token_indexå­—æ®µï¼‰
        const formattedVocabNotations = vocabList.map(notation => ({
          user_id: notation.user_id,
          text_id: notation.text_id,
          sentence_id: notation.sentence_id,
          token_id: notation.token_id,
          token_index: notation.token_id, // æ·»åŠ token_indexå­—æ®µä½œä¸ºåˆ«å
          vocab_id: notation.vocab_id,
          created_at: notation.created_at
        }))
        
        setVocabNotations(formattedVocabNotations)
        
        // é¢„åŠ è½½æ‰€æœ‰vocab examplesï¼ˆå¹¶è¡ŒåŠ è½½ä»¥æé«˜æ€§èƒ½ï¼‰
        const vocabExamplesMap = new Map()
        const loadPromises = formattedVocabNotations.map(async (notation) => {
          const key = `${notation.text_id}:${notation.sentence_id}:${notation.token_index}`
          // é¿å…é‡å¤åŠ è½½åŒä¸€ä¸ªexample
          if (vocabExamplesMap.has(key)) {
            return
          }
          try {
            const exampleResponse = await apiService.getVocabExampleByLocation(
              notation.text_id,
              notation.sentence_id,
              notation.token_index
            )
            const payload = exampleResponse?.data?.data ?? exampleResponse?.data ?? exampleResponse
            if (payload && payload.vocab_id) {
              const normalized = {
                vocab_id: payload.vocab_id,
                text_id: payload.text_id,
                sentence_id: payload.sentence_id,
                token_index: payload.token_index ?? notation.token_index,
                context_explanation: payload.context_explanation,
                token_indices: payload.token_indices || []
              }
              vocabExamplesMap.set(key, normalized)
            }
          } catch (err) {
            // é™é»˜å¤±è´¥ï¼Œé¿å…å•ä¸ªexampleåŠ è½½å¤±è´¥å½±å“æ•´ä½“
            console.warn(`âš ï¸ [useNotationCache] Failed to preload vocab example for ${key}:`, err)
          }
        })
        await Promise.all(loadPromises)
        setVocabExamplesCache(vocabExamplesMap)
        
      } else if (vocabResponse && vocabResponse.data) {
        // å…¼å®¹æ—§çš„APIæ ¼å¼ï¼ˆç›´æ¥ä»dataä¸­è·å–æ•°ç»„ï¼‰
        const vocabData = Array.isArray(vocabResponse.data) ? vocabResponse.data : []
        const formattedVocabNotations = vocabData.map(notation => ({
          user_id: notation.user_id,
          text_id: notation.text_id,
          sentence_id: notation.sentence_id,
          token_id: notation.token_id,
          token_index: notation.token_id,
          vocab_id: notation.vocab_id,
          created_at: notation.created_at
        }))
        setVocabNotations(formattedVocabNotations)
        
        // é¢„åŠ è½½æ‰€æœ‰vocab examplesï¼ˆå…¼å®¹æ—§æ ¼å¼ï¼Œå¹¶è¡ŒåŠ è½½ï¼‰
        const vocabExamplesMap = new Map()
        const loadPromises = formattedVocabNotations.map(async (notation) => {
          const key = `${notation.text_id}:${notation.sentence_id}:${notation.token_index}`
          if (vocabExamplesMap.has(key)) {
            return
          }
          try {
            const exampleResponse = await apiService.getVocabExampleByLocation(
              notation.text_id,
              notation.sentence_id,
              notation.token_index
            )
            const payload = exampleResponse?.data?.data ?? exampleResponse?.data ?? exampleResponse
            if (payload && payload.vocab_id) {
              const normalized = {
                vocab_id: payload.vocab_id,
                text_id: payload.text_id,
                sentence_id: payload.sentence_id,
                token_index: payload.token_index ?? notation.token_index,
                context_explanation: payload.context_explanation,
                token_indices: payload.token_indices || []
              }
              vocabExamplesMap.set(key, normalized)
            }
          } catch (err) {
            console.warn(`âš ï¸ [useNotationCache] Failed to preload vocab example for ${key}:`, err)
          }
        })
        await Promise.all(loadPromises)
        setVocabExamplesCache(vocabExamplesMap)
        
      } else {
        console.warn('âš ï¸ [useNotationCache] No vocab notations found or invalid response format')
        setVocabNotations([])
      }

      setIsInitialized(true)
      // ç§»é™¤æˆåŠŸæ—¥å¿—ï¼ˆå·²é€šè¿‡æµ‹è¯•ï¼‰

    } catch (err) {
      console.error('âŒ [useNotationCache] Error loading notations:', err)
      setError(err.message || 'Failed to load notations')
    } finally {
      setIsLoading(false)
    }
  }, [])

  // åˆå§‹åŒ–åŠ è½½
  useEffect(() => {
    if (articleId && !isInitialized) {
      loadAllNotations(articleId)
    }
  }, [articleId, isInitialized, loadAllNotations])

  // è·å–å¥å­çš„grammar notations
  const getGrammarNotationsForSentence = useCallback((sentenceId) => {
    return grammarNotations.filter(notation => 
      notation.sentence_id === sentenceId
    )
  }, [grammarNotations])

  // è·å–å¥å­çš„vocab notations
  const getVocabNotationsForSentence = useCallback((sentenceId) => {
    // ç¡®ä¿ç±»å‹ä¸€è‡´ï¼ˆæ•°å­—æ¯”è¾ƒï¼‰
    const sid = Number(sentenceId)
    
    const filtered = vocabNotations.filter(notation => 
      Number(notation.sentence_id) === sid
    )
    
    return filtered
  }, [vocabNotations])

  // è·å–ç‰¹å®štokençš„vocab exampleï¼ˆé€šè¿‡APIæŒ‰éœ€è·å–ï¼‰
  const getVocabExampleForToken = useCallback(async (textId, sentenceId, tokenIndex) => {
    const key = `${textId}:${sentenceId}:${tokenIndex}`
    
    // é¦–å…ˆæ£€æŸ¥ç¼“å­˜
    if (vocabExamplesCache.has(key)) {
      return vocabExamplesCache.get(key)
    }
    
    // å¦‚æœç¼“å­˜ä¸­æ²¡æœ‰ï¼Œé€šè¿‡APIè·å–
    try {
      const { apiService } = await import('../../../services/api')
      const axiosResp = await apiService.getVocabExampleByLocation(textId, sentenceId, tokenIndex)
      // axiosResp -> { data: { success, data } } in mock
      const payload = axiosResp?.data?.data ?? axiosResp?.data ?? axiosResp

      if (payload && payload.vocab_id) {
        // æ ‡å‡†åŒ–ï¼šç¡®ä¿æœ‰ token_index ä¾›ç¼“å­˜ key ä½¿ç”¨
        const normalized = {
          vocab_id: payload.vocab_id,
          text_id: payload.text_id,
          sentence_id: payload.sentence_id,
          token_index: payload.token_index ?? tokenIndex,
          context_explanation: payload.context_explanation,
          token_indices: payload.token_indices || []
        }
        setVocabExamplesCache(prev => {
          const newCache = new Map(prev)
          newCache.set(key, normalized)
          return newCache
        })
        return normalized
      } else {
        return null
      }
    } catch (error) {
      console.error('âŒ [getVocabExampleForToken] API error:', error)
      return null
    }
  }, [vocabExamplesCache])

  // è·å–grammar ruleè¯¦æƒ…
  const getGrammarRuleById = useCallback((grammarId) => {
    return grammarRulesCache.get(grammarId) || null
  }, [grammarRulesCache])

  // æ£€æŸ¥å¥å­æ˜¯å¦æœ‰grammar notation
  const hasGrammarNotation = useCallback((sentenceId) => {
    return grammarNotations.some(notation => 
      notation.sentence_id === sentenceId
    )
  }, [grammarNotations])

  // æ£€æŸ¥å¥å­æ˜¯å¦æœ‰vocab notation
  const hasVocabNotation = useCallback((sentenceId) => {
    return vocabNotations.some(notation => 
      notation.sentence_id === sentenceId
    )
  }, [vocabNotations])

  // åˆ·æ–°ç¼“å­˜ï¼ˆå½“æœ‰æ–°çš„notationè¢«åˆ›å»ºæ—¶è°ƒç”¨ï¼‰
  const refreshCache = useCallback(() => {
    if (articleId) {
      console.log('ğŸ”„ [useNotationCache] Refreshing cache for articleId:', articleId)
      setIsInitialized(false)
      loadAllNotations(articleId)
    }
  }, [articleId, loadAllNotations])

  // æ·»åŠ æ–°çš„grammar notationåˆ°ç¼“å­˜
  const addGrammarNotationToCache = useCallback((notation) => {
    console.log('â• [useNotationCache] Adding grammar notation to cache:', notation)
    setGrammarNotations(prev => {
      // æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ï¼Œé¿å…é‡å¤æ·»åŠ 
      const exists = prev.some(n => 
        n.text_id === notation.text_id && 
        n.sentence_id === notation.sentence_id && 
        n.grammar_id === notation.grammar_id
      )
      if (exists) {
        console.log('âš ï¸ [useNotationCache] Grammar notation already exists in cache')
        return prev
      }
      return [...prev, notation]
    })
  }, [])

  // æ·»åŠ æ–°çš„vocab notationåˆ°ç¼“å­˜
  const addVocabNotationToCache = useCallback((notation) => {
    console.log('â• [useNotationCache] Adding vocab notation to cache:', notation)
    setVocabNotations(prev => {
      // æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ï¼Œé¿å…é‡å¤æ·»åŠ 
      const exists = prev.some(n => 
        n.text_id === notation.text_id && 
        n.sentence_id === notation.sentence_id && 
        n.token_index === notation.token_index
      )
      if (exists) {
        console.log('âš ï¸ [useNotationCache] Vocab notation already exists in cache')
        return prev
      }
      return [...prev, notation]
    })
  }, [])

  // æ·»åŠ æ–°çš„grammar ruleåˆ°ç¼“å­˜
  const addGrammarRuleToCache = useCallback((rule) => {
    console.log('â• [useNotationCache] Adding grammar rule to cache:', rule)
    setGrammarRulesCache(prev => {
      const newCache = new Map(prev)
      newCache.set(rule.rule_id, rule)
      return newCache
    })
  }, [])

  // æ·»åŠ æ–°çš„vocab exampleåˆ°ç¼“å­˜
  const addVocabExampleToCache = useCallback((example) => {
    console.log('â• [useNotationCache] Adding vocab example to cache:', example)
    const key = `${example.text_id}:${example.sentence_id}:${example.token_index}`
    setVocabExamplesCache(prev => {
      const newCache = new Map(prev)
      newCache.set(key, example)
      return newCache
    })
  }, [])

  // åˆ›å»ºvocab notationï¼ˆä½¿ç”¨æ–°APIï¼‰
  const createVocabNotation = useCallback(async (textId, sentenceId, tokenId, vocabId = null, userId = 'default_user') => {
    try {
      console.log('â• [useNotationCache] Creating vocab notation:', { textId, sentenceId, tokenId, vocabId, userId })
      
      const response = await apiService.createVocabNotation(userId, textId, sentenceId, tokenId, vocabId)
      
      // å¤„ç†å“åº”ï¼ˆå¯èƒ½ä»æ‹¦æˆªå™¨è¿”å›ä¸åŒçš„æ ¼å¼ï¼‰
      const result = response?.data || response
      const success = result?.success !== false && (result?.success === true || response?.status === 200)
      
      if (success) {
        // åˆ›å»ºvocab notationå¯¹è±¡
        const newNotation = {
          user_id: userId,
          text_id: textId,
          sentence_id: sentenceId,
          token_id: tokenId,
          token_index: tokenId,  // æ·»åŠ token_indexä½œä¸ºåˆ«å
          vocab_id: vocabId,
          created_at: new Date().toISOString()
        }
        
        // æ·»åŠ åˆ°ç¼“å­˜
        addVocabNotationToCache(newNotation)
        
        console.log('âœ… [useNotationCache] Vocab notation created and added to cache:', newNotation)
        return { success: true, notation: newNotation }
      } else {
        console.error('âŒ [useNotationCache] Failed to create vocab notation:', result?.error || 'Unknown error')
        return { success: false, error: result?.error || 'Unknown error' }
      }
    } catch (error) {
      console.error('âŒ [useNotationCache] Error creating vocab notation:', error)
      return { success: false, error: error.message || 'Failed to create vocab notation' }
    }
  }, [addVocabNotationToCache])

  return {
    // çŠ¶æ€
    isLoading,
    error,
    isInitialized,
    
    // Grammar notations
    grammarNotations,
    getGrammarNotationsForSentence,
    getGrammarRuleById,
    hasGrammarNotation,
    
    // Vocab notations
    vocabNotations,
    getVocabNotationsForSentence,
    getVocabExampleForToken,
    hasVocabNotation,
    
    // ç¼“å­˜ç®¡ç†
    refreshCache,
    
    // å®æ—¶ç¼“å­˜æ›´æ–°
    addGrammarNotationToCache,
    addVocabNotationToCache,
    addGrammarRuleToCache,
    addVocabExampleToCache,
    
    // åˆ›å»ºåŠŸèƒ½ï¼ˆæ–°APIï¼‰
    createVocabNotation
  }
}

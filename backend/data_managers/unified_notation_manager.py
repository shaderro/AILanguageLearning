#!/usr/bin/env python3
"""
ç»Ÿä¸€æ ‡æ³¨ç®¡ç†å™¨
æä¾›ç»Ÿä¸€çš„æ¥å£æ¥ç®¡ç† VocabNotation å’Œ GrammarNotation
æ”¯æŒå‘åå…¼å®¹ AskedToken ç³»ç»Ÿ
"""

import os
from typing import Set, List, Optional, Union, Literal
from datetime import datetime

# å¯¼å…¥å„ä¸ªç®¡ç†å™¨
try:
    from .vocab_notation_manager import VocabNotationManager, get_vocab_notation_manager
    from .grammar_notation_manager import GrammarNotationManager, get_grammar_notation_manager
    from .asked_tokens_manager import AskedTokensManager, get_asked_tokens_manager
except ImportError:
    from vocab_notation_manager import VocabNotationManager, get_vocab_notation_manager
    from grammar_notation_manager import GrammarNotationManager, get_grammar_notation_manager
    from asked_tokens_manager import AskedTokensManager, get_asked_tokens_manager

# å¯¼å…¥æ•°æ®ç»“æ„
try:
    from .data_classes_new import VocabNotation, GrammarNotation, AskedToken
except ImportError:
    from data_classes_new import VocabNotation, GrammarNotation, AskedToken


class UnifiedNotationManager:
    """ç»Ÿä¸€æ ‡æ³¨ç®¡ç†å™¨"""
    
    def __init__(self, use_database: bool = True, use_legacy_compatibility: bool = True):
        """
        åˆå§‹åŒ–ç»Ÿä¸€ç®¡ç†å™¨
        
        Args:
            use_database: æ˜¯å¦ä½¿ç”¨æ•°æ®åº“å­˜å‚¨
            use_legacy_compatibility: æ˜¯å¦å¯ç”¨å‘åå…¼å®¹æ¨¡å¼
        """
        self.use_database = use_database
        self.use_legacy_compatibility = use_legacy_compatibility
        
        # åˆå§‹åŒ–å„ä¸ªç®¡ç†å™¨
        self.vocab_manager = get_vocab_notation_manager(use_database=use_database)
        self.grammar_manager = get_grammar_notation_manager(use_database=use_database)
        
        # å¦‚æœéœ€è¦å‘åå…¼å®¹ï¼Œä¹Ÿåˆå§‹åŒ– AskedTokensManager
        # ğŸ”§ asked_tokens ç°åœ¨æ˜¯ legacy ç³»ç»Ÿï¼Œåªä½¿ç”¨ JSON æ–‡ä»¶ï¼Œä¸ä½¿ç”¨æ•°æ®åº“
        if use_legacy_compatibility:
            self.asked_tokens_manager = get_asked_tokens_manager(use_database=False)
        
        print(f"[INFO] [UnifiedNotation] Initialized with database={use_database}, legacy={use_legacy_compatibility}")
    
    def mark_notation(self, notation_type: Literal["vocab", "grammar"], 
                     user_id: str, text_id: int, sentence_id: int,
                     token_id: Optional[int] = None,
                     vocab_id: Optional[int] = None,
                     grammar_id: Optional[int] = None,
                     marked_token_ids: Optional[List[int]] = None,
                     **kwargs) -> bool:
        """
        ç»Ÿä¸€çš„æ ‡æ³¨åˆ›å»ºæ¥å£
        
        Args:
            notation_type: æ ‡æ³¨ç±»å‹ï¼Œ"vocab" æˆ– "grammar"
            user_id: ç”¨æˆ·ID
            text_id: æ–‡ç« ID
            sentence_id: å¥å­ID
            token_id: Token IDï¼ˆè¯æ±‡æ ‡æ³¨å¿…éœ€ï¼‰
            vocab_id: è¯æ±‡IDï¼ˆè¯æ±‡æ ‡æ³¨å¯é€‰ï¼‰
            grammar_id: è¯­æ³•IDï¼ˆè¯­æ³•æ ‡æ³¨å¯é€‰ï¼‰
            marked_token_ids: æ ‡è®°çš„token IDåˆ—è¡¨ï¼ˆè¯­æ³•æ ‡æ³¨å¯é€‰ï¼‰
            **kwargs: å…¶ä»–å‚æ•°
        """
        print(f"[INFO] [UnifiedNotation] mark_notation called: type={notation_type}")
        
        try:
            if notation_type == "vocab":
                if token_id is None:
                    print(f"[ERROR] [UnifiedNotation] token_id is required for vocab notation")
                    return False
                
                success = self.vocab_manager.create_vocab_notation(
                    user_id=user_id,
                    text_id=text_id,
                    sentence_id=sentence_id,
                    token_id=token_id,
                    vocab_id=vocab_id
                )
                
                # å¦‚æœå¯ç”¨å‘åå…¼å®¹ï¼ŒåŒæ—¶åˆ›å»º AskedToken
                if success and self.use_legacy_compatibility:
                    self._create_legacy_asked_token(
                        user_id=user_id,
                        text_id=text_id,
                        sentence_id=sentence_id,
                        sentence_token_id=token_id,
                        type="token",
                        vocab_id=vocab_id,
                        grammar_id=None
                    )
                
                return success
                
            elif notation_type == "grammar":
                if marked_token_ids is None:
                    marked_token_ids = []
                
                success = self.grammar_manager.create_grammar_notation(
                    user_id=user_id,
                    text_id=text_id,
                    sentence_id=sentence_id,
                    grammar_id=grammar_id,
                    marked_token_ids=marked_token_ids
                )
                
                # å¦‚æœå¯ç”¨å‘åå…¼å®¹ï¼ŒåŒæ—¶åˆ›å»º AskedTokenï¼ˆé’ˆå¯¹å¥å­ï¼‰
                if success and self.use_legacy_compatibility:
                    self._create_legacy_asked_token(
                        user_id=user_id,
                        text_id=text_id,
                        sentence_id=sentence_id,
                        sentence_token_id=None,
                        type="sentence",
                        vocab_id=None,
                        grammar_id=grammar_id
                    )
                
                return success
            else:
                print(f"[ERROR] [UnifiedNotation] Invalid notation_type: {notation_type}")
                return False
                
        except Exception as e:
            print(f"[ERROR] [UnifiedNotation] Failed to mark notation: {e}")
            return False
    
    def _create_legacy_asked_token(self, user_id: str, text_id: int, sentence_id: int,
                                  sentence_token_id: Optional[int], type: str,
                                  vocab_id: Optional[int], grammar_id: Optional[int]) -> bool:
        """åˆ›å»ºå‘åå…¼å®¹çš„ AskedToken"""
        try:
            return self.asked_tokens_manager.mark_token_asked(
                user_id=user_id,
                text_id=text_id,
                sentence_id=sentence_id,
                sentence_token_id=sentence_token_id,
                type=type,
                vocab_id=vocab_id,
                grammar_id=grammar_id
            )
        except Exception as e:
            print(f"[WARN] [UnifiedNotation] Failed to create legacy AskedToken: {e}")
            return False
    
    def get_notations(self, notation_type: Literal["vocab", "grammar", "all"], 
                     text_id: int, user_id: Optional[str] = None) -> Set[str]:
        """
        ç»Ÿä¸€çš„æ ‡æ³¨æŸ¥è¯¢æ¥å£
        
        Args:
            notation_type: æ ‡æ³¨ç±»å‹ï¼Œ"vocab", "grammar", æˆ– "all"
            text_id: æ–‡ç« ID
            user_id: ç”¨æˆ·IDï¼ˆå¯é€‰ï¼‰
        """
        print(f"[INFO] [UnifiedNotation] get_notations called: type={notation_type}, text_id={text_id}")
        
        try:
            if notation_type == "vocab":
                return self.vocab_manager.get_vocab_notations_for_article(text_id, user_id)
            elif notation_type == "grammar":
                return self.grammar_manager.get_grammar_notations_for_article(text_id, user_id)
            elif notation_type == "all":
                # åˆå¹¶æ‰€æœ‰ç±»å‹çš„æ ‡æ³¨
                vocab_keys = self.vocab_manager.get_vocab_notations_for_article(text_id, user_id)
                grammar_keys = self.grammar_manager.get_grammar_notations_for_article(text_id, user_id)
                
                # ç»Ÿä¸€é”®æ ¼å¼ï¼švocab ä½¿ç”¨ "text_id:sentence_id:token_id"ï¼Œgrammar ä½¿ç”¨ "text_id:sentence_id"
                all_keys = set()
                all_keys.update(vocab_keys)
                all_keys.update(grammar_keys)
                
                return all_keys
            else:
                print(f"[ERROR] [UnifiedNotation] Invalid notation_type: {notation_type}")
                return set()
                
        except Exception as e:
            print(f"[ERROR] [UnifiedNotation] Failed to get notations: {e}")
            return set()
    
    def is_notation_exists(self, notation_type: Literal["vocab", "grammar"],
                          user_id: str, text_id: int, sentence_id: int,
                          token_id: Optional[int] = None) -> bool:
        """
        ç»Ÿä¸€çš„æ ‡æ³¨å­˜åœ¨æ€§æ£€æŸ¥æ¥å£
        
        Args:
            notation_type: æ ‡æ³¨ç±»å‹ï¼Œ"vocab" æˆ– "grammar"
            user_id: ç”¨æˆ·ID
            text_id: æ–‡ç« ID
            sentence_id: å¥å­ID
            token_id: Token IDï¼ˆè¯æ±‡æ ‡æ³¨å¿…éœ€ï¼‰
        """
        print(f"[INFO] [UnifiedNotation] is_notation_exists called: type={notation_type}")
        
        try:
            if notation_type == "vocab":
                if token_id is None:
                    print(f"[ERROR] [UnifiedNotation] token_id is required for vocab notation")
                    return False
                return self.vocab_manager.is_vocab_notation_exists(user_id, text_id, sentence_id, token_id)
            elif notation_type == "grammar":
                return self.grammar_manager.is_grammar_notation_exists(user_id, text_id, sentence_id)
            else:
                print(f"[ERROR] [UnifiedNotation] Invalid notation_type: {notation_type}")
                return False
                
        except Exception as e:
            print(f"[ERROR] [UnifiedNotation] Failed to check notation existence: {e}")
            return False
    
    def delete_notation(self, notation_type: Literal["vocab", "grammar"],
                       user_id: str, notation_key: str) -> bool:
        """
        ç»Ÿä¸€çš„æ ‡æ³¨åˆ é™¤æ¥å£
        
        Args:
            notation_type: æ ‡æ³¨ç±»å‹ï¼Œ"vocab" æˆ– "grammar"
            user_id: ç”¨æˆ·ID
            notation_key: æ ‡æ³¨é”®ï¼ˆæ ¼å¼ï¼štext_id:sentence_id[:token_id]ï¼‰
        """
        print(f"[INFO] [UnifiedNotation] delete_notation called: type={notation_type}, key={notation_key}")
        
        try:
            if notation_type == "vocab":
                return self.vocab_manager.delete_vocab_notation(user_id, notation_key)
            elif notation_type == "grammar":
                return self.grammar_manager.delete_grammar_notation(user_id, notation_key)
            else:
                print(f"[ERROR] [UnifiedNotation] Invalid notation_type: {notation_type}")
                return False
                
        except Exception as e:
            print(f"[ERROR] [UnifiedNotation] Failed to delete notation: {e}")
            return False
    
    def get_notation_details(self, notation_type: Literal["vocab", "grammar"],
                           user_id: str, text_id: int, sentence_id: int,
                           token_id: Optional[int] = None) -> Optional[Union[VocabNotation, GrammarNotation]]:
        """
        ç»Ÿä¸€çš„æ ‡æ³¨è¯¦æƒ…æŸ¥è¯¢æ¥å£
        
        Args:
            notation_type: æ ‡æ³¨ç±»å‹ï¼Œ"vocab" æˆ– "grammar"
            user_id: ç”¨æˆ·ID
            text_id: æ–‡ç« ID
            sentence_id: å¥å­ID
            token_id: Token IDï¼ˆè¯æ±‡æ ‡æ³¨å¿…éœ€ï¼‰
        """
        print(f"[INFO] [UnifiedNotation] get_notation_details called: type={notation_type}")
        
        try:
            if notation_type == "vocab":
                if token_id is None:
                    print(f"[ERROR] [UnifiedNotation] token_id is required for vocab notation")
                    return None
                return self.vocab_manager.get_vocab_notation_details(user_id, text_id, sentence_id, token_id)
            elif notation_type == "grammar":
                return self.grammar_manager.get_grammar_notation_details(user_id, text_id, sentence_id)
            else:
                print(f"[ERROR] [UnifiedNotation] Invalid notation_type: {notation_type}")
                return None
                
        except Exception as e:
            print(f"[ERROR] [UnifiedNotation] Failed to get notation details: {e}")
            return None
    
    def migrate_legacy_asked_tokens(self, user_id: str = "default_user") -> bool:
        """
        è¿ç§»ç°æœ‰çš„ AskedToken æ•°æ®åˆ°æ–°çš„æ ‡æ³¨ç³»ç»Ÿ
        è¿™æ˜¯ä¸€ä¸ªä¸€æ¬¡æ€§æ“ä½œï¼Œç”¨äºå°†ç°æœ‰çš„ AskedToken æ•°æ®è¿ç§»åˆ°æ–°ç³»ç»Ÿ
        
        Args:
            user_id: è¦è¿ç§»çš„ç”¨æˆ·ID
        """
        print(f"[INFO] [UnifiedNotation] Starting migration of legacy AskedToken data for user: {user_id}")
        
        try:
            if not self.use_legacy_compatibility:
                print(f"[WARN] [UnifiedNotation] Legacy compatibility is disabled, skipping migration")
                return True
            
            # è·å–ç°æœ‰çš„ AskedToken æ•°æ®
            if self.use_database:
                # ä»æ•°æ®åº“è·å–
                import sqlite3
                with sqlite3.connect(self.asked_tokens_manager.db_path) as conn:
                    cursor = conn.cursor()
                    cursor.execute("""
                        SELECT user_id, text_id, sentence_id, sentence_token_id, type, vocab_id, grammar_id
                        FROM asked_tokens 
                        WHERE user_id = ?
                    """, (user_id,))
                    asked_tokens = cursor.fetchall()
            else:
                # ä» JSON æ–‡ä»¶è·å–
                import json
                file_path = self.asked_tokens_manager._get_json_file_path(user_id)
                if not os.path.exists(file_path):
                    print(f"[INFO] [UnifiedNotation] No legacy data found for user: {user_id}")
                    return True
                
                with open(file_path, "r", encoding="utf-8") as f:
                    asked_tokens_data = json.load(f)
                asked_tokens = [(token["user_id"], token["text_id"], token["sentence_id"], 
                               token["sentence_token_id"], token["type"], token["vocab_id"], token["grammar_id"]) 
                               for token in asked_tokens_data]
            
            migrated_count = 0
            for token_data in asked_tokens:
                user_id, text_id, sentence_id, sentence_token_id, type, vocab_id, grammar_id = token_data
                
                if type == "token" and sentence_token_id is not None:
                    # è¿ç§»ä¸º VocabNotation
                    success = self.vocab_manager.create_vocab_notation(
                        user_id=user_id,
                        text_id=text_id,
                        sentence_id=sentence_id,
                        token_id=sentence_token_id,
                        vocab_id=vocab_id
                    )
                    if success:
                        migrated_count += 1
                        print(f"[OK] [UnifiedNotation] Migrated vocab notation: {text_id}:{sentence_id}:{sentence_token_id}")
                
                elif type == "sentence":
                    # è¿ç§»ä¸º GrammarNotation
                    success = self.grammar_manager.create_grammar_notation(
                        user_id=user_id,
                        text_id=text_id,
                        sentence_id=sentence_id,
                        grammar_id=grammar_id,
                        marked_token_ids=[]  # æš‚æ—¶ä¸ºç©ºï¼Œåç»­å¯ä»¥å®Œå–„
                    )
                    if success:
                        migrated_count += 1
                        print(f"[OK] [UnifiedNotation] Migrated grammar notation: {text_id}:{sentence_id}")
            
            print(f"[SUCCESS] [UnifiedNotation] Migration completed: {migrated_count} notations migrated")
            return True
            
        except Exception as e:
            print(f"[ERROR] [UnifiedNotation] Migration failed: {e}")
            import traceback
            traceback.print_exc()
            return False


# å…¨å±€å®ä¾‹
_unified_notation_manager = None

def get_unified_notation_manager(use_database: bool = True, use_legacy_compatibility: bool = True) -> UnifiedNotationManager:
    """è·å– UnifiedNotationManager å®ä¾‹"""
    global _unified_notation_manager
    if _unified_notation_manager is None:
        _unified_notation_manager = UnifiedNotationManager(use_database=use_database, use_legacy_compatibility=use_legacy_compatibility)
    return _unified_notation_manager

import json
from typing import List, Dict
from dataclasses import asdict
from data_managers.data_classes import VocabExpression, VocabExpressionExample, VocabExpressionBundle
import os
import chardet
from data_managers.original_text_manager import OriginalTextManager

# å¯¼å…¥æ–°çš„æ•°æ®ç»“æ„ç±»
try:
    from data_managers.data_classes_new import VocabExpression as NewVocabExpression, VocabExpressionExample as NewVocabExpressionExample
    NEW_STRUCTURE_AVAILABLE = True
except ImportError:
    NEW_STRUCTURE_AVAILABLE = False
    print("âš ï¸ æ–°æ•°æ®ç»“æ„ç±»ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨æ—§ç»“æ„")

class VocabManager:
    def __init__(self, use_new_structure: bool = False):
        self.vocab_bundles: Dict[int, VocabExpressionBundle] = {}  # vocab_id -> Bundle
        self.use_new_structure = use_new_structure and NEW_STRUCTURE_AVAILABLE
        
        if self.use_new_structure:
            print("âœ… VocabManager: å·²å¯ç”¨æ–°æ•°æ®ç»“æ„æ¨¡å¼")
        else:
            print("âœ… VocabManager: ä½¿ç”¨æ—§æ•°æ®ç»“æ„æ¨¡å¼")

    def get_new_vocab_id(self) -> int:
        if not self.vocab_bundles:
            return 1
        return max(self.vocab_bundles.keys()) + 1

    def add_new_vocab(self, vocab_body: str, explanation: str) -> int:
        new_vocab_id = self.get_new_vocab_id()
        
        if self.use_new_structure:
            # ä½¿ç”¨æ–°ç»“æ„åˆ›å»ºè¯æ±‡
            new_vocab = NewVocabExpression(
                vocab_id=new_vocab_id, 
                vocab_body=vocab_body, 
                explanation=explanation,
                source="qa",  # æ–°ç»“æ„é»˜è®¤sourceä¸ºqa
                is_starred=False,  # æ–°ç»“æ„é»˜è®¤is_starredä¸ºFalse
                examples=[]  # æ–°ç»“æ„ç›´æ¥åŒ…å«examplesåˆ—è¡¨
            )
            # æ–°ç»“æ„ä¸éœ€è¦BundleåŒ…è£…
            self.vocab_bundles[new_vocab_id] = new_vocab
        else:
            # ä½¿ç”¨æ—§ç»“æ„åˆ›å»ºè¯æ±‡
            new_vocab = VocabExpression(vocab_id=new_vocab_id, vocab_body=vocab_body, explanation=explanation)
            self.vocab_bundles[new_vocab_id] = VocabExpressionBundle(vocab=new_vocab, example=[])
        
        return new_vocab_id

    def add_vocab_example(self, text_manager: OriginalTextManager, vocab_id: int, text_id: int, sentence_id: int, context_explanation: str, token_indices: list = None):
        if vocab_id not in self.vocab_bundles:
            raise ValueError(f"Vocab ID {vocab_id} does not exist.")
        
        # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨ä¼ å…¥çš„ token_indicesï¼Œé»˜è®¤ä¸ºç©ºåˆ—è¡¨
        if token_indices is None:
            token_indices = []
        
        if self.use_new_structure:
            # æ–°ç»“æ„ï¼šç›´æ¥æ·»åŠ åˆ°è¯æ±‡çš„examplesåˆ—è¡¨
            vocab = self.vocab_bundles[vocab_id]
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
            for example in vocab.examples:
                if example.text_id == text_id and example.sentence_id == sentence_id and example.vocab_id == vocab_id:
                    print(f"Example for vocab_id {vocab_id}, text_id {text_id}, sentence_id {sentence_id} already exists.")
                    return
            
            new_example = NewVocabExpressionExample(
                vocab_id=vocab_id,
                text_id=text_id,
                sentence_id=sentence_id,
                context_explanation=context_explanation,
                token_indices=token_indices  # âœ… ä½¿ç”¨ä¼ å…¥çš„å®é™…å€¼
            )
            print(f"ğŸ” [VocabManager] æ·»åŠ ä¾‹å¥ï¼Œtoken_indices={token_indices}")
            vocab.examples.append(new_example)
        else:
            # æ—§ç»“æ„ï¼šä½¿ç”¨BundleåŒ…è£…
            for example in self.vocab_bundles[vocab_id].example:
                if example.text_id == text_id and example.sentence_id == sentence_id and example.vocab_id == vocab_id:
                    print(f"Example for vocab_id {vocab_id}, text_id {text_id}, sentence_id {sentence_id} already exists.")
                    return
            
            new_example = VocabExpressionExample(
                vocab_id=vocab_id,
                text_id=text_id,
                sentence_id=sentence_id,
                context_explanation=context_explanation
            )
            self.vocab_bundles[vocab_id].example.append(new_example)
        
        text_manager.add_vocab_example_to_sentence(text_id, sentence_id, vocab_id)
        
    def get_vocab_by_id(self, vocab_id: int) -> VocabExpression:
        if vocab_id not in self.vocab_bundles:
            raise ValueError(f"Vocab ID {vocab_id} does not exist.")
        
        if self.use_new_structure:
            # æ–°ç»“æ„ï¼šç›´æ¥è¿”å›è¯æ±‡
            return self.vocab_bundles[vocab_id]
        else:
            # æ—§ç»“æ„ï¼šé€šè¿‡Bundleè¿”å›è¯æ±‡
            return self.vocab_bundles[vocab_id].vocab

    def get_examples_by_vocab_id(self, vocab_id: int) -> List[VocabExpressionExample]:
        if vocab_id not in self.vocab_bundles:
            raise ValueError(f"Vocab ID {vocab_id} does not exist.")
        
        if self.use_new_structure:
            # æ–°ç»“æ„ï¼šç›´æ¥è¿”å›è¯æ±‡çš„examples
            return self.vocab_bundles[vocab_id].examples
        else:
            # æ—§ç»“æ„ï¼šé€šè¿‡Bundleè¿”å›examples
            return self.vocab_bundles[vocab_id].example

    def get_example_by_text_sentence_id(self, text_id: int, sentence_id: int) -> VocabExpressionExample:
        for bundle in self.vocab_bundles.values():
            if self.use_new_structure:
                # æ–°ç»“æ„ï¼šç›´æ¥éå†è¯æ±‡çš„examples
                for example in bundle.examples:
                    if example.text_id == text_id and example.sentence_id == sentence_id:
                        return example
            else:
                # æ—§ç»“æ„ï¼šé€šè¿‡Bundleéå†examples
                for example in bundle.example:
                    if example.text_id == text_id and example.sentence_id == sentence_id:
                        return example
        return None
    
    def get_id_by_vocab_body(self, vocab_body: str) -> int:
        for vocab_id, bundle in self.vocab_bundles.items():
            if self.use_new_structure:
                # æ–°ç»“æ„ï¼šç›´æ¥è®¿é—®è¯æ±‡
                if bundle.vocab_body == vocab_body:
                    return vocab_id
            else:
                # æ—§ç»“æ„ï¼šé€šè¿‡Bundleè®¿é—®è¯æ±‡
                if bundle.vocab.vocab_body == vocab_body:
                    return vocab_id
        raise ValueError(f"Vocab body '{vocab_body}' does not exist.")
    
    def get_all_vocab_body(self) -> List[str]:
        if self.use_new_structure:
            # æ–°ç»“æ„ï¼šç›´æ¥è·å–è¯æ±‡ä½“
            return [bundle.vocab_body for bundle in self.vocab_bundles.values()]
        else:
            # æ—§ç»“æ„ï¼šé€šè¿‡Bundleè·å–è¯æ±‡ä½“
            return [bundle.vocab.vocab_body for bundle in self.vocab_bundles.values()]

    def save_to_file(self, path: str):
        """
        ä¿å­˜æ•°æ®åˆ°æ–‡ä»¶ï¼Œå§‹ç»ˆä½¿ç”¨æ—§JSONæ ¼å¼ä»¥ç¡®ä¿å…¼å®¹æ€§
        """
        export_data = {}
        for vocab_id, bundle in self.vocab_bundles.items():
            if self.use_new_structure:
                # æ–°ç»“æ„ï¼šè½¬æ¢ä¸ºæ—§æ ¼å¼è¿›è¡Œä¿å­˜
                vocab = bundle
                bundle_data = {
                    'vocab': {
                        'vocab_id': vocab.vocab_id,
                        'vocab_body': vocab.vocab_body,
                        'explanation': vocab.explanation
                    },
                    'example': [
                        {
                            'vocab_id': ex.vocab_id,
                            'text_id': ex.text_id,
                            'sentence_id': ex.sentence_id,
                            'context_explanation': ex.context_explanation
                        } for ex in vocab.examples
                    ]
                }
            else:
                # æ—§ç»“æ„ï¼šç›´æ¥ä½¿ç”¨asdict
                bundle_data = asdict(bundle)
            
            export_data[vocab_id] = bundle_data
        
        with open(path, 'w', encoding='utf-8') as f:
            json.dump(export_data, f, indent=4, ensure_ascii=False)
    
    def save_to_new_format(self, path: str):
        """
        ä¿å­˜æ•°æ®ä¸ºæ–°ç»“æ„æ ¼å¼ï¼ˆæ•°ç»„æ ¼å¼ï¼ŒåŒ…å« sourceã€is_starredã€token_indices ç­‰æ–°å­—æ®µï¼‰
        """
        if not self.use_new_structure:
            print("âš ï¸ å½“å‰æœªä½¿ç”¨æ–°ç»“æ„ï¼Œæ— æ³•ä¿å­˜ä¸ºæ–°æ ¼å¼")
            return
            
        export_data = []
        for vocab_id, vocab in sorted(self.vocab_bundles.items()):
            # æ–°ç»“æ„ï¼šä¿å­˜ä¸ºæ•°ç»„æ ¼å¼ï¼ˆæ›´ç®€æ´ï¼‰
            vocab_data = {
                'vocab_id': vocab.vocab_id,
                'vocab_body': vocab.vocab_body,
                'explanation': vocab.explanation,
                'source': getattr(vocab, 'source', 'qa'),
                'is_starred': getattr(vocab, 'is_starred', False),
                'examples': [
                    {
                        'vocab_id': ex.vocab_id,
                        'text_id': ex.text_id,
                        'sentence_id': ex.sentence_id,
                        'context_explanation': ex.context_explanation,
                        'token_indices': getattr(ex, 'token_indices', [])
                    } for ex in vocab.examples
                ] if vocab.examples else []
            }
            export_data.append(vocab_data)
        
        with open(path, 'w', encoding='utf-8') as f:
            json.dump(export_data, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… å·²ä¿å­˜ {len(export_data)} ä¸ªè¯æ±‡è¡¨è¾¾åˆ°æ–‡ä»¶ï¼ˆæ•°ç»„æ ¼å¼ï¼‰: {path}")
    
    def load_from_file(self, path: str):
        """
        ä»æ–‡ä»¶åŠ è½½æ•°æ®ï¼Œæ”¯æŒæ–°æ—§ä¸¤ç§ç»“æ„
        """
        if not os.path.exists(path):
            raise FileNotFoundError(f"The file at path {path} does not exist.")
        if not os.path.isfile(path):
            raise ValueError(f"The path {path} is not a file.")

        with open(path, 'rb') as f:
            raw_data = f.read()

        detected = chardet.detect(raw_data)
        encoding = detected['encoding'] or 'utf-8'

        try:
            content = raw_data.decode(encoding).strip()
        except UnicodeDecodeError as e:
            print(f"â—ï¸æ— æ³•ç”¨ {encoding} è§£ç æ–‡ä»¶ {path}ï¼š{e}")
            raise e

        if not content:
            print(f"[Warning] File {path} is empty. Starting with empty record.")
            return

        data = json.loads(content)
        self.vocab_bundles = {}  # æ¸…ç©ºå½“å‰çŠ¶æ€
        
        try:
            # æ”¯æŒä¸¤ç§æ ¼å¼ï¼šæ•°ç»„æ ¼å¼ï¼ˆç®€åŒ–ï¼‰å’Œå­—å…¸æ ¼å¼ï¼ˆBundleï¼‰
            if isinstance(data, list):
                # æ•°ç»„æ ¼å¼ï¼š[{"vocab_id": 1, "vocab_body": "...", ...}, ...]
                items_to_process = [(item.get('vocab_id'), item) for item in data]
            elif isinstance(data, dict):
                # å­—å…¸æ ¼å¼ï¼š{"1": {"vocab": {...}, "example": [...]}, ...}
                items_to_process = list(data.items())
            else:
                raise ValueError(f"Unexpected data format: {type(data)}")
            
            for vocab_id, bundle_data in items_to_process:
                if self.use_new_structure:
                    # æ–°ç»“æ„ï¼šç›´æ¥åˆ›å»ºè¯æ±‡å¯¹è±¡
                    # åˆ¤æ–­æ˜¯æ•°ç»„æ ¼å¼è¿˜æ˜¯Bundleæ ¼å¼
                    if 'vocab' in bundle_data:
                        # Bundleæ ¼å¼ï¼š{"vocab": {...}, "example": [...]}
                        vocab_data = bundle_data['vocab']
                        examples_data = bundle_data.get('example', [])
                    else:
                        # æ•°ç»„æ ¼å¼ï¼šç›´æ¥æ˜¯è¯æ±‡æ•°æ®ï¼ˆç®€åŒ–æ ¼å¼ï¼Œç”¨äºMock serverï¼‰
                        vocab_data = bundle_data
                        examples_data = bundle_data.get('examples', [])  # æ³¨æ„ï¼šç®€åŒ–æ ¼å¼ä½¿ç”¨'examples'è€Œä¸æ˜¯'example'
                    
                    vocab = NewVocabExpression(
                        vocab_id=vocab_data['vocab_id'],
                        vocab_body=vocab_data['vocab_body'],
                        explanation=vocab_data['explanation'],
                        source=vocab_data.get('source', 'qa'),  # ä½¿ç”¨æ–‡ä»¶ä¸­çš„sourceï¼Œé»˜è®¤ä¸ºqa
                        is_starred=vocab_data.get('is_starred', False),  # ä½¿ç”¨æ–‡ä»¶ä¸­çš„is_starredï¼Œé»˜è®¤ä¸ºFalse
                        examples=[
                            NewVocabExpressionExample(
                                vocab_id=ex['vocab_id'],
                                text_id=ex['text_id'],
                                sentence_id=ex['sentence_id'],
                                context_explanation=ex['context_explanation'],
                                token_indices=ex.get('token_indices', [])  # ä»æ–‡ä»¶è¯»å–ï¼Œé»˜è®¤ç©ºåˆ—è¡¨
                            ) for ex in examples_data
                        ]
                    )
                    self.vocab_bundles[int(vocab_id)] = vocab
                else:
                    # æ—§ç»“æ„ï¼šä½¿ç”¨BundleåŒ…è£…
                    # åˆ¤æ–­æ˜¯æ•°ç»„æ ¼å¼è¿˜æ˜¯Bundleæ ¼å¼
                    if 'vocab' in bundle_data:
                        # Bundleæ ¼å¼
                        vocab = VocabExpression(**bundle_data['vocab'])
                        examples = [VocabExpressionExample(**ex) for ex in bundle_data['example']]
                    else:
                        # æ•°ç»„æ ¼å¼ï¼šè½¬æ¢ä¸ºBundleæ ¼å¼
                        vocab = VocabExpression(
                            vocab_id=bundle_data['vocab_id'],
                            vocab_body=bundle_data['vocab_body'],
                            explanation=bundle_data['explanation']
                        )
                        # ç®€åŒ–æ ¼å¼ä¸­çš„examplesæ˜¯å­—å…¸åˆ—è¡¨ï¼Œéœ€è¦è½¬æ¢ä¸ºVocabExpressionExample
                        examples = []
                        for ex in bundle_data.get('examples', []):
                            if isinstance(ex, dict):
                                examples.append(VocabExpressionExample(
                                    vocab_id=ex.get('vocab_id', bundle_data['vocab_id']),
                                    text_id=ex.get('text_id', 0),
                                    sentence_id=ex.get('sentence_id', 0),
                                    context_explanation=ex.get('context_explanation', ''),
                                    token_indices=ex.get('token_indices', [])
                                ))
                    self.vocab_bundles[int(vocab_id)] = VocabExpressionBundle(vocab=vocab, example=examples)
            
            print(f"âœ… æˆåŠŸåŠ è½½ {len(self.vocab_bundles)} ä¸ªè¯æ±‡è¡¨è¾¾")
            if self.use_new_structure:
                print("ğŸ“ ä½¿ç”¨æ–°æ•°æ®ç»“æ„ï¼ŒåŒ…å«examplesåˆ—è¡¨ã€source=qaã€is_starred=False")
            else:
                print("ğŸ“ ä½¿ç”¨æ—§æ•°æ®ç»“æ„")
                
        except Exception as e:
            print(f"[Error] Failed to load vocabulary expressions: {e}")
            raise e
    
    def switch_to_new_structure(self) -> bool:
        """
        åˆ‡æ¢åˆ°æ–°ç»“æ„æ¨¡å¼
        
        Returns:
            bool: åˆ‡æ¢æ˜¯å¦æˆåŠŸ
        """
        if not NEW_STRUCTURE_AVAILABLE:
            print("âŒ æ–°æ•°æ®ç»“æ„ç±»ä¸å¯ç”¨ï¼Œæ— æ³•åˆ‡æ¢")
            return False
            
        if self.use_new_structure:
            print("âœ… å·²ç»åœ¨ä½¿ç”¨æ–°ç»“æ„æ¨¡å¼")
            return True
            
        try:
            # é‡æ–°åŠ è½½æ‰€æœ‰æ•°æ®åˆ°æ–°ç»“æ„
            self.use_new_structure = True
            print("âœ… å·²åˆ‡æ¢åˆ°æ–°ç»“æ„æ¨¡å¼")
            return True
        except Exception as e:
            print(f"âŒ åˆ‡æ¢åˆ°æ–°ç»“æ„å¤±è´¥: {e}")
            self.use_new_structure = False
            return False
    
    def switch_to_old_structure(self) -> bool:
        """
        åˆ‡æ¢å›æ—§ç»“æ„æ¨¡å¼
        
        Returns:
            bool: åˆ‡æ¢æ˜¯å¦æˆåŠŸ
        """
        if not self.use_new_structure:
            print("âœ… å·²ç»åœ¨ä½¿ç”¨æ—§ç»“æ„æ¨¡å¼")
            return True
            
        try:
            # é‡æ–°åŠ è½½æ‰€æœ‰æ•°æ®åˆ°æ—§ç»“æ„
            self.use_new_structure = False
            print("âœ… å·²åˆ‡æ¢å›æ—§ç»“æ„æ¨¡å¼")
            return True
        except Exception as e:
            print(f"âŒ åˆ‡æ¢å›æ—§ç»“æ„å¤±è´¥: {e}")
            return False
    
    def get_structure_mode(self) -> str:
        """
        è·å–å½“å‰ä½¿ç”¨çš„æ•°æ®ç»“æ„æ¨¡å¼
        
        Returns:
            str: "new" æˆ– "old"
        """
        return "new" if self.use_new_structure else "old"

    def get_vocab_example_by_location(self, text_id: int, sentence_id: int = None, token_index: int = None):
        """
        æŒ‰å±‚çº§æŸ¥æ‰¾è¯æ±‡ä¾‹å¥ï¼šä¼˜å…ˆæŒ‰ text_id æŸ¥æ‰¾å”¯ä¸€ç»“æœï¼Œå¦åˆ™æŒ‰ sentence_idï¼Œæœ€åæŒ‰ token_index
        
        Args:
            text_id: æ–‡ç« IDï¼ˆå¿…éœ€ï¼‰
            sentence_id: å¥å­IDï¼ˆå¯é€‰ï¼‰
            token_index: Tokenç´¢å¼•ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            VocabExpressionExample æˆ– None
        """
        matching_examples = []
        
        # éå†æ‰€æœ‰è¯æ±‡çš„æ‰€æœ‰ä¾‹å¥
        for vocab_id, vocab_bundle in self.vocab_bundles.items():
            if self.use_new_structure:
                # æ–°ç»“æ„ï¼šç›´æ¥ä» vocab.examples è·å–
                examples = vocab_bundle.examples if hasattr(vocab_bundle, 'examples') else []
            else:
                # æ—§ç»“æ„ï¼šä» bundle.example è·å–
                examples = vocab_bundle.example if hasattr(vocab_bundle, 'example') else []
            
            for example in examples:
                # é¦–å…ˆæ£€æŸ¥ text_id æ˜¯å¦åŒ¹é…
                if example.text_id == text_id:
                    # å¦‚æœåªæä¾›äº† text_idï¼Œä¸”è¿™æ˜¯è¯¥ text_id çš„å”¯ä¸€ä¾‹å¥ï¼Œç›´æ¥è¿”å›
                    if sentence_id is None and token_index is None:
                        matching_examples.append(example)
                    # å¦‚æœæä¾›äº† sentence_idï¼Œæ£€æŸ¥æ˜¯å¦åŒ¹é…
                    elif sentence_id is not None and example.sentence_id == sentence_id:
                        # å¦‚æœåªæä¾›äº† sentence_idï¼Œä¸”è¿™æ˜¯è¯¥ sentence_id çš„å”¯ä¸€ä¾‹å¥ï¼Œç›´æ¥è¿”å›
                        if token_index is None:
                            matching_examples.append(example)
                        # å¦‚æœæä¾›äº† token_indexï¼Œæ£€æŸ¥æ˜¯å¦åœ¨ token_indices ä¸­
                        elif token_index is not None and hasattr(example, 'token_indices'):
                            if token_index in example.token_indices:
                                matching_examples.append(example)
                        # æ—§ç»“æ„æ²¡æœ‰ token_indicesï¼ŒæŒ‰ sentence_id åŒ¹é…
                        elif token_index is not None and not hasattr(example, 'token_indices'):
                            matching_examples.append(example)
        
        # è¿”å›å”¯ä¸€ç»“æœ
        if len(matching_examples) == 1:
            return matching_examples[0]
        elif len(matching_examples) > 1:
            print(f"âš ï¸ [VocabManager] æ‰¾åˆ°å¤šä¸ªåŒ¹é…çš„ä¾‹å¥: {len(matching_examples)} ä¸ª")
            return matching_examples[0]  # è¿”å›ç¬¬ä¸€ä¸ª
        else:
            print(f"ğŸ” [VocabManager] æœªæ‰¾åˆ°åŒ¹é…çš„ä¾‹å¥: text_id={text_id}, sentence_id={sentence_id}, token_index={token_index}")
            return None

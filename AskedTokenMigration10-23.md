# AskedToken è¿ç§»è®¡åˆ’ - 2024å¹´10æœˆ23æ—¥

## ğŸ“‹ è¿ç§»ç›®æ ‡

å°†ç°æœ‰çš„ `AskedToken` é€æ­¥æ›¿æ¢ä¸º `VocabNotation` å’Œ `GrammarNotation`ï¼Œå®ç°è¯æ±‡å’Œè¯­æ³•çŸ¥è¯†ç‚¹æ ‡æ³¨çš„åˆ†ç¦»ï¼Œæ›´å¥½ç®¡ç†å¹¶å®ç°ä»¥ååŠŸèƒ½ã€‚

### ğŸ¯ **è¿ç§»ç›®æ ‡**
- å°†ç°æœ‰çš„ `AskedToken` é€æ­¥æ›¿æ¢ä¸º `VocabNotation` å’Œ `GrammarNotation`
- å®ç°è¯æ±‡å’Œè¯­æ³•çŸ¥è¯†ç‚¹æ ‡æ³¨çš„åˆ†ç¦»
- ä¿æŒå‘åå…¼å®¹æ€§ï¼Œç¡®ä¿ç°æœ‰åŠŸèƒ½ä¸å—å½±å“

### ğŸ“Š **å½“å‰çŠ¶å†µåˆ†æ**
1. **æ•°æ®ç»“æ„**ï¼šç°æœ‰çš„ `AskedToken` å·²ç»åŒ…å« `type` å­—æ®µåŒºåˆ† token/sentence
2. **å­˜å‚¨æ–¹å¼**ï¼šåŒæ—¶æ”¯æŒ JSON æ–‡ä»¶å’Œ SQLite æ•°æ®åº“
3. **ä½¿ç”¨åœºæ™¯**ï¼šç›®å‰æ‰€æœ‰ `AskedToken` éƒ½æ˜¯ `type="token"`ï¼Œå¯¹åº”è¯æ±‡æ ‡æ³¨

---

## ğŸš€ **è¿ç§»è®¡åˆ’ï¼ˆ5ä¸ªé˜¶æ®µï¼‰**

### **é˜¶æ®µ1ï¼šåŸºç¡€æ¶æ„å‡†å¤‡** âš™ï¸
**ç›®æ ‡**ï¼šåˆ›å»ºæ–°çš„ç®¡ç†å™¨å’Œæ•°æ®ç»“æ„æ”¯æŒ

**ä»»åŠ¡**ï¼š
1. **åˆ›å»º VocabNotationManager**
   ```python
   # backend/data_managers/vocab_notation_manager.py
   class VocabNotationManager:
       def __init__(self, use_database: bool = True)
       def create_vocab_notation(self, user_id, text_id, sentence_id, token_id, vocab_id)
       def is_vocab_notation_exists(self, ...)
       def get_vocab_notations_for_article(self, ...)
   ```

2. **åˆ›å»º GrammarNotationManager**
   ```python
   # backend/data_managers/grammar_notation_manager.py  
   class GrammarNotationManager:
       def __init__(self, use_database: bool = True)
       def create_grammar_notation(self, user_id, text_id, sentence_id, grammar_id, marked_token_ids)
       def is_grammar_notation_exists(self, ...)
   ```

3. **æ·»åŠ æ•°æ®è¿ç§»å·¥å…·**
   ```python
   # backend/data_managers/migration_tools.py
   class NotationMigrationTool:
       def migrate_asked_tokens_to_vocab_notations(self)
       def backup_existing_data(self)
       def validate_migration(self)
   ```

### **é˜¶æ®µ2ï¼šå¹¶è¡Œè¿è¡ŒæœŸ** ğŸ”„
**ç›®æ ‡**ï¼šæ–°æ—§ç³»ç»Ÿå¹¶è¡Œè¿è¡Œï¼Œç¡®ä¿å…¼å®¹æ€§

**ä»»åŠ¡**ï¼š
1. **æ‰©å±• AskedTokensManager**
   ```python
   # æ·»åŠ å‘åå…¼å®¹æ–¹æ³•
   def mark_as_vocab_notation(self, ...) -> VocabNotation
   def mark_as_grammar_notation(self, ...) -> GrammarNotation
   ```

2. **åˆ›å»ºç»Ÿä¸€æ¥å£**
   ```python
   # backend/data_managers/unified_notation_manager.py
   class UnifiedNotationManager:
       def mark_notation(self, type: str, ...)  # 'vocab' æˆ– 'grammar'
       def get_notations(self, type: str, ...)
   ```

3. **å‰ç«¯é€‚é…**
   - ä¿®æ”¹å‰ç«¯è°ƒç”¨ï¼Œæ”¯æŒæ–°çš„æ•°æ®ç»“æ„
   - ä¿æŒç°æœ‰ UI ä¸å˜

### **é˜¶æ®µ3ï¼šæ•°æ®è¿ç§»** ğŸ“¦
**ç›®æ ‡**ï¼šå°†ç°æœ‰ AskedToken æ•°æ®è¿ç§»åˆ°æ–°ç»“æ„

**ä»»åŠ¡**ï¼š
1. **æ•°æ®è¿ç§»è„šæœ¬**
   ```python
   # è¿ç§»é€»è¾‘
   for asked_token in existing_asked_tokens:
       if asked_token.type == "token":
           # è½¬æ¢ä¸º VocabNotation
           vocab_notation = VocabNotation(
               user_id=asked_token.user_id,
               text_id=asked_token.text_id,
               sentence_id=asked_token.sentence_id,
               token_id=asked_token.sentence_token_id,
               vocab_id=asked_token.vocab_id
           )
       # ä¿å­˜åˆ°æ–°ç³»ç»Ÿ
   ```

2. **æ•°æ®éªŒè¯**
   - ç¡®ä¿è¿ç§»æ•°æ®å®Œæ•´æ€§
   - éªŒè¯æ–°æ—§ç³»ç»Ÿæ•°æ®ä¸€è‡´æ€§

### **é˜¶æ®µ4ï¼šé€æ­¥åˆ‡æ¢** ğŸ”„
**ç›®æ ‡**ï¼šé€æ­¥å°†åŠŸèƒ½åˆ‡æ¢åˆ°æ–°ç³»ç»Ÿ

**ä»»åŠ¡**ï¼š
1. **API å±‚åˆ‡æ¢**
   ```python
   # ä¿®æ”¹ API ç«¯ç‚¹
   @app.post("/api/user/vocab-notation")  # æ–°ç«¯ç‚¹
   @app.post("/api/user/grammar-notation")  # æ–°ç«¯ç‚¹
   
   # ä¿æŒæ—§ç«¯ç‚¹å…¼å®¹
   @app.post("/api/user/asked-tokens")  # æ ‡è®°ä¸ºåºŸå¼ƒ
   ```

2. **å‰ç«¯é€æ­¥åˆ‡æ¢**
   - æ–°åŠŸèƒ½ä½¿ç”¨æ–° API
   - æ—§åŠŸèƒ½ä¿æŒå…¼å®¹

### **é˜¶æ®µ5ï¼šæ¸…ç†å’Œä¼˜åŒ–** ğŸ§¹
**ç›®æ ‡**ï¼šç§»é™¤æ—§ç³»ç»Ÿï¼Œä¼˜åŒ–æ–°ç³»ç»Ÿ

**ä»»åŠ¡**ï¼š
1. **ç§»é™¤ AskedToken ç›¸å…³ä»£ç **
2. **ä¼˜åŒ–æ–°ç³»ç»Ÿæ€§èƒ½**
3. **æ›´æ–°æ–‡æ¡£å’Œæµ‹è¯•**

---

## ğŸ›¡ï¸ **å®‰å…¨ä¿éšœæªæ–½**

### **æ•°æ®å¤‡ä»½**
```python
# æ¯ä¸ªé˜¶æ®µå¼€å§‹å‰è‡ªåŠ¨å¤‡ä»½
def backup_data():
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    backup_file = f"asked_tokens_backup_{timestamp}.json"
    # å¤‡ä»½ç°æœ‰æ•°æ®
```

### **å›æ»šæœºåˆ¶**
```python
# æ¯ä¸ªé˜¶æ®µéƒ½æœ‰å›æ»šèƒ½åŠ›
def rollback_migration():
    # ä»å¤‡ä»½æ¢å¤æ•°æ®
    # åˆ‡æ¢å›æ—§ç³»ç»Ÿ
```

### **éªŒè¯æ£€æŸ¥**
```python
# æ•°æ®ä¸€è‡´æ€§éªŒè¯
def validate_migration():
    old_count = count_asked_tokens()
    new_count = count_vocab_notations() + count_grammar_notations()
    assert old_count == new_count
```

---

## ğŸ“… **æ—¶é—´å®‰æ’å»ºè®®**

- **é˜¶æ®µ1**ï¼š1-2å¤©ï¼ˆåŸºç¡€æ¶æ„ï¼‰
- **é˜¶æ®µ2**ï¼š2-3å¤©ï¼ˆå¹¶è¡Œè¿è¡Œï¼‰
- **é˜¶æ®µ3**ï¼š1å¤©ï¼ˆæ•°æ®è¿ç§»ï¼‰
- **é˜¶æ®µ4**ï¼š3-5å¤©ï¼ˆé€æ­¥åˆ‡æ¢ï¼‰
- **é˜¶æ®µ5**ï¼š1-2å¤©ï¼ˆæ¸…ç†ä¼˜åŒ–ï¼‰

**æ€»è®¡**ï¼š8-13å¤©

---

## ğŸ“ **æ•°æ®ç»“æ„å¯¹æ¯”**

### **å½“å‰ AskedToken**
```python
@dataclass
class AskedToken:
    user_id: str
    text_id: int
    sentence_id: int
    sentence_token_id: Optional[int] = None
    type: Literal["token", "sentence"] = "token"
    vocab_id: Optional[int] = None
    grammar_id: Optional[int] = None
```

### **æ–°çš„ VocabNotation**
```python
@dataclass
class VocabNotation:
    user_id: str
    text_id: int
    sentence_id: int
    token_id: int               # å½“å‰å¥å­ä¸­å“ªä¸ª token
    vocab_id: Optional[int]     # å¯¹åº”è¯æ±‡è¡¨ä¸­çš„è¯æ±‡
    created_at: Optional[str] = None  # æ—¶é—´æˆ³ï¼ˆå¯é€‰ï¼‰
```

### **æ–°çš„ GrammarNotation**
```python
@dataclass
class GrammarNotation:
    user_id: str
    text_id: int
    sentence_id: int
    grammar_id: Optional[int]   # å¯¹åº” grammar_rules è¡¨
    marked_token_ids: list[int] # å¥ä¸­é‡ç‚¹è¯­æ³•æˆåˆ†çš„ token id åˆ—è¡¨
    created_at: Optional[str] = None
```

---

## ğŸ” **å½“å‰ä½¿ç”¨æƒ…å†µåˆ†æ**

### **AskedToken ä½¿ç”¨ä½ç½®**
1. **æ•°æ®ç®¡ç†å™¨**ï¼š`backend/data_managers/asked_tokens_manager.py`
2. **æ•°æ®åº“æ¨¡å‹**ï¼š`database_system/business_logic/models.py`
3. **CRUD æ“ä½œ**ï¼š`database_system/business_logic/crud/asked_token_crud.py`
4. **ä¸šåŠ¡é€»è¾‘**ï¼š`database_system/business_logic/managers/asked_token_manager.py`
5. **å‰ç«¯è°ƒç”¨**ï¼šé€šè¿‡ API ç«¯ç‚¹ `/api/user/asked-tokens`

### **å½“å‰æ•°æ®ç¤ºä¾‹**
```json
[
  {
    "user_id": "default_user",
    "text_id": 1,
    "sentence_id": 3,
    "sentence_token_id": 22,
    "type": "token",
    "vocab_id": null,
    "grammar_id": null
  }
]
```

---

## â“ **éœ€è¦ç¡®è®¤çš„é—®é¢˜**

1. **æ˜¯å¦ç«‹å³å¼€å§‹é˜¶æ®µ1**ï¼Ÿ
2. **æ˜¯å¦éœ€è¦ä¿æŒ AskedToken ä½œä¸ºå…¼å®¹å±‚**ï¼Ÿ
3. **æ•°æ®åº“è¿ç§»ç­–ç•¥**ï¼ˆæ˜¯å¦éœ€è¦æ–°çš„æ•°æ®åº“è¡¨ï¼‰ï¼Ÿ
4. **å‰ç«¯åˆ‡æ¢çš„ä¼˜å…ˆçº§**ï¼ˆå“ªäº›åŠŸèƒ½ä¼˜å…ˆåˆ‡æ¢ï¼‰ï¼Ÿ

---

## ğŸ“‹ **æ£€æŸ¥æ¸…å•**

### é˜¶æ®µ1 æ£€æŸ¥æ¸…å•
- [x] åˆ›å»º VocabNotationManager ç±» âœ…
- [x] åˆ›å»º GrammarNotationManager ç±» âœ…
- [ ] åˆ›å»º NotationMigrationTool ç±»
- [x] ç¼–å†™å•å…ƒæµ‹è¯• âœ…
- [x] æ›´æ–°æ–‡æ¡£ âœ…

### é˜¶æ®µ2 æ£€æŸ¥æ¸…å•
- [x] æ‰©å±• AskedTokensManager âœ…
- [x] åˆ›å»º UnifiedNotationManager âœ…
- [ ] ä¿®æ”¹å‰ç«¯è°ƒç”¨
- [x] æµ‹è¯•å…¼å®¹æ€§ âœ…
- [ ] æ€§èƒ½æµ‹è¯•

### é˜¶æ®µ3 æ£€æŸ¥æ¸…å•
- [ ] ç¼–å†™æ•°æ®è¿ç§»è„šæœ¬
- [ ] æ‰§è¡Œæ•°æ®å¤‡ä»½
- [ ] è¿è¡Œè¿ç§»è„šæœ¬
- [ ] éªŒè¯æ•°æ®å®Œæ•´æ€§
- [ ] æµ‹è¯•åŠŸèƒ½æ­£å¸¸æ€§

### é˜¶æ®µ4 æ£€æŸ¥æ¸…å•
- [ ] åˆ›å»ºæ–° API ç«¯ç‚¹
- [ ] ä¿®æ”¹å‰ç«¯è°ƒç”¨
- [ ] æµ‹è¯•æ–°åŠŸèƒ½
- [ ] ç›‘æ§ç³»ç»Ÿç¨³å®šæ€§
- [ ] ç”¨æˆ·éªŒæ”¶æµ‹è¯•

### é˜¶æ®µ5 æ£€æŸ¥æ¸…å•
- [ ] ç§»é™¤æ—§ä»£ç 
- [ ] æ¸…ç†æ— ç”¨æ–‡ä»¶
- [ ] ä¼˜åŒ–æ€§èƒ½
- [ ] æ›´æ–°æ–‡æ¡£
- [ ] æœ€ç»ˆæµ‹è¯•

---

## ğŸ“š **ç›¸å…³æ–‡æ¡£**

- [æ•°æ®ç»“æ„å®šä¹‰](backend/data_managers/data_classes_new.py)
- [å½“å‰ AskedToken ç®¡ç†å™¨](backend/data_managers/asked_tokens_manager.py)
- [æ•°æ®åº“æ¨¡å‹](database_system/business_logic/models.py)
- [å‰ç«¯ API è°ƒç”¨](frontend/my-web-ui/src/services/api.js)

---

**åˆ›å»ºæ—¶é—´**ï¼š2024å¹´10æœˆ23æ—¥  
**æœ€åæ›´æ–°**ï¼š2024å¹´10æœˆ23æ—¥  
**çŠ¶æ€**ï¼šè®¡åˆ’é˜¶æ®µ

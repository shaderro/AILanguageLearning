#!/usr/bin/env python3
"""
æµ‹è¯•IDå¤„ç†å’Œæ–‡ä»¶ç»“æ„
éªŒè¯ process_article çš„IDå¤„ç†ä»¥åŠæ–‡ä»¶ç»“æ„æ˜¯å¦ç¬¦åˆè¦æ±‚
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from integrated_language_system import IntegratedLanguageSystem
import json

def test_id_handling():
    """æµ‹è¯•IDå¤„ç†"""
    print("ğŸ§ª æµ‹è¯•IDå¤„ç†")
    print("=" * 60)
    
    system = IntegratedLanguageSystem()
    
    # æµ‹è¯•æ–‡ç« 1
    article1 = "Learning a new language is challenging but rewarding."
    print("\nğŸ“‹ æµ‹è¯•æ–‡ç« 1 (ID: 1)")
    print("-" * 40)
    
    result1 = system.process_article(article1, text_id=1, title="Article 01")
    print(f"âœ… æ–‡ç« 1å¤„ç†å®Œæˆ")
    print(f"   è¿”å›çš„text_id: {result1['statistics']['text_id']}")
    print(f"   å¥å­æ•°é‡: {result1['statistics']['total_sentences']}")
    
    # æµ‹è¯•æ–‡ç« 2
    article2 = "Grammar and vocabulary are essential components of language study."
    print("\nğŸ“‹ æµ‹è¯•æ–‡ç« 2 (ID: 2)")
    print("-" * 40)
    
    result2 = system.process_article(article2, text_id=2, title="Article 02")
    print(f"âœ… æ–‡ç« 2å¤„ç†å®Œæˆ")
    print(f"   è¿”å›çš„text_id: {result2['statistics']['text_id']}")
    print(f"   å¥å­æ•°é‡: {result2['statistics']['total_sentences']}")
    
    # æµ‹è¯•æ–‡ç« 3
    article3 = "The internet has revolutionized the way we learn languages."
    print("\nğŸ“‹ æµ‹è¯•æ–‡ç« 3 (ID: 3)")
    print("-" * 40)
    
    result3 = system.process_article(article3, text_id=3, title="Article 03")
    print(f"âœ… æ–‡ç« 3å¤„ç†å®Œæˆ")
    print(f"   è¿”å›çš„text_id: {result3['statistics']['text_id']}")
    print(f"   å¥å­æ•°é‡: {result3['statistics']['total_sentences']}")
    
    # éªŒè¯IDæ˜¯å¦æ­£ç¡®ä¼ é€’
    print("\nğŸ“‹ IDéªŒè¯")
    print("-" * 40)
    
    for i, result in enumerate([result1, result2, result3], 1):
        expected_id = i
        actual_id = result['statistics']['text_id']
        if expected_id == actual_id:
            print(f"âœ… æ–‡ç« {i}: IDæ­£ç¡® ({actual_id})")
        else:
            print(f"âŒ æ–‡ç« {i}: IDé”™è¯¯ (æœŸæœ›: {expected_id}, å®é™…: {actual_id})")
        
        # æ£€æŸ¥å¥å­ä¸­çš„text_id
        for sentence in result['sentences']:
            if sentence.text_id == expected_id:
                print(f"   âœ… å¥å­text_idæ­£ç¡®: {sentence.text_id}")
            else:
                print(f"   âŒ å¥å­text_idé”™è¯¯: {sentence.text_id}")

def test_file_structure():
    """æµ‹è¯•æ–‡ä»¶ç»“æ„"""
    print("\nğŸ§ª æµ‹è¯•æ–‡ä»¶ç»“æ„")
    print("=" * 60)
    
    # æ£€æŸ¥å½“å‰æ–‡ä»¶ç»“æ„
    print("ğŸ“‹ å½“å‰dataç›®å½•æ–‡ä»¶ç»“æ„:")
    print("-" * 40)
    
    data_dir = "data"
    if os.path.exists(data_dir):
        files = os.listdir(data_dir)
        
        # åˆ†ç±»æ–‡ä»¶
        article_files = [f for f in files if "original_text" in f and f.endswith('.json')]
        vocab_files = [f for f in files if "vocab" in f and f.endswith('.json')]
        grammar_files = [f for f in files if "grammar" in f and f.endswith('.json')]
        
        print(f"ğŸ“„ æ–‡ç« æ–‡ä»¶: {len(article_files)} ä¸ª")
        for f in sorted(article_files):
            print(f"   - {f}")
        
        print(f"\nğŸ“š è¯æ±‡æ–‡ä»¶: {len(vocab_files)} ä¸ª")
        for f in sorted(vocab_files):
            print(f"   - {f}")
        
        print(f"\nğŸ“– è¯­æ³•æ–‡ä»¶: {len(grammar_files)} ä¸ª")
        for f in sorted(grammar_files):
            print(f"   - {f}")
    
    # æ£€æŸ¥æœŸæœ›çš„æ–‡ä»¶ç»“æ„
    print("\nğŸ“‹ æœŸæœ›çš„æ–‡ä»¶ç»“æ„:")
    print("-" * 40)
    print("ğŸ“ articleæ–‡ä»¶å¤¹:")
    print("   - article01.json")
    print("   - article02.json")
    print("   - article03.json")
    print("ğŸ“„ vocab.json")
    print("ğŸ“„ grammar.json")
    
    # æ£€æŸ¥æ˜¯å¦æŒ‰OriginalTextç»“æ„å­˜å‚¨
    print("\nğŸ“‹ æ£€æŸ¥OriginalTextæ•°æ®ç»“æ„:")
    print("-" * 40)
    
    try:
        # å°è¯•è¯»å–æœ€æ–°çš„æ–‡ç« æ–‡ä»¶
        latest_article_file = None
        for f in sorted(article_files, reverse=True):
            if "new_new.json" in f:
                latest_article_file = f
                break
        
        if latest_article_file:
            with open(os.path.join(data_dir, latest_article_file), 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            print(f"ğŸ“„ æ£€æŸ¥æ–‡ä»¶: {latest_article_file}")
            
            if isinstance(data, list) and len(data) > 0:
                first_article = data[0]
                print(f"âœ… æ•°æ®ç»“æ„æ˜¯åˆ—è¡¨")
                print(f"   æ–‡ç« æ•°é‡: {len(data)}")
                
                # æ£€æŸ¥æ˜¯å¦åŒ…å«OriginalTextçš„å­—æ®µ
                required_fields = ['text_id', 'text_title', 'text_by_sentence']
                missing_fields = [field for field in required_fields if field not in first_article]
                
                if not missing_fields:
                    print(f"âœ… åŒ…å«æ‰€æœ‰OriginalTextå­—æ®µ: {required_fields}")
                    print(f"   æ–‡ç« ID: {first_article['text_id']}")
                    print(f"   æ–‡ç« æ ‡é¢˜: {first_article['text_title']}")
                    print(f"   å¥å­æ•°é‡: {len(first_article['text_by_sentence'])}")
                    
                    # æ£€æŸ¥å¥å­ç»“æ„
                    if first_article['text_by_sentence']:
                        first_sentence = first_article['text_by_sentence'][0]
                        sentence_fields = ['text_id', 'sentence_id', 'sentence_body', 'sentence_difficulty_level', 'tokens']
                        sentence_missing = [field for field in sentence_fields if field not in first_sentence]
                        
                        if not sentence_missing:
                            print(f"âœ… å¥å­ç»“æ„å®Œæ•´: {sentence_fields}")
                        else:
                            print(f"âŒ å¥å­ç¼ºå°‘å­—æ®µ: {sentence_missing}")
                else:
                    print(f"âŒ ç¼ºå°‘OriginalTextå­—æ®µ: {missing_fields}")
            else:
                print(f"âŒ æ•°æ®ç»“æ„ä¸æ˜¯é¢„æœŸçš„åˆ—è¡¨æ ¼å¼")
        else:
            print("âŒ æœªæ‰¾åˆ°æœ€æ–°çš„æ–‡ç« æ–‡ä»¶")
            
    except Exception as e:
        print(f"âŒ æ£€æŸ¥æ–‡ä»¶ç»“æ„å¤±è´¥: {e}")

def test_article_folder_structure():
    """æµ‹è¯•æ–‡ç« æ–‡ä»¶å¤¹ç»“æ„"""
    print("\nğŸ§ª æµ‹è¯•æ–‡ç« æ–‡ä»¶å¤¹ç»“æ„")
    print("=" * 60)
    
    # æ£€æŸ¥æ˜¯å¦å­˜åœ¨articleæ–‡ä»¶å¤¹
    article_dir = "data/article"
    if os.path.exists(article_dir):
        print(f"âœ… articleæ–‡ä»¶å¤¹å­˜åœ¨: {article_dir}")
        
        files = os.listdir(article_dir)
        article_files = [f for f in files if f.startswith('article') and f.endswith('.json')]
        
        print(f"ğŸ“„ æ–‡ç« æ–‡ä»¶æ•°é‡: {len(article_files)}")
        for f in sorted(article_files):
            print(f"   - {f}")
    else:
        print(f"âŒ articleæ–‡ä»¶å¤¹ä¸å­˜åœ¨: {article_dir}")
        print("   å½“å‰æ–‡ä»¶ç»“æ„ä¸ç¬¦åˆæœŸæœ›")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ æµ‹è¯•IDå¤„ç†å’Œæ–‡ä»¶ç»“æ„")
    print("=" * 60)
    
    # æµ‹è¯•IDå¤„ç†
    test_id_handling()
    
    # æµ‹è¯•æ–‡ä»¶ç»“æ„
    test_file_structure()
    
    # æµ‹è¯•æ–‡ç« æ–‡ä»¶å¤¹ç»“æ„
    test_article_folder_structure()
    
    print("\nğŸ“‹ æ€»ç»“å’Œå»ºè®®:")
    print("-" * 40)
    print("1. IDå¤„ç†: éœ€è¦éªŒè¯text_idæ˜¯å¦æ­£ç¡®ä¼ é€’")
    print("2. æ–‡ä»¶ç»“æ„: å½“å‰ä¸ç¬¦åˆæœŸæœ›çš„articleæ–‡ä»¶å¤¹ç»“æ„")
    print("3. æ•°æ®ç»“æ„: éœ€è¦ç¡®è®¤æ˜¯å¦æŒ‰OriginalTextç»“æ„å­˜å‚¨")
    print("4. å»ºè®®: ä¿®æ”¹ä¿å­˜é€»è¾‘ä»¥ç¬¦åˆæœŸæœ›çš„æ–‡ä»¶ç»“æ„")

if __name__ == "__main__":
    main() 
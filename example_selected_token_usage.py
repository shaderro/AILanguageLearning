#!/usr/bin/env python3
"""
SelectedToken åŠŸèƒ½å®Œæ•´ä½¿ç”¨ç¤ºä¾‹
å±•ç¤ºå¦‚ä½•ä½¿ç”¨æ–°çš„tokené€‰æ‹©åŠŸèƒ½
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from integrated_language_system import IntegratedLanguageSystem
from assistants.chat_info.selected_token import SelectedToken, create_selected_token_from_text
from data_managers.data_classes_new import Sentence as NewSentence, Token

def create_sample_article() -> str:
    """åˆ›å»ºç¤ºä¾‹æ–‡ç« """
    return """
Learning a new language is challenging but rewarding. It requires dedication and practice, but the benefits are immense. 
When you learn a new language, you open doors to new cultures and opportunities. The process involves understanding grammar rules, 
building vocabulary, and developing listening and speaking skills. Although it may seem overwhelming at first, with consistent effort, 
you will see significant progress over time.
"""

def create_test_sentence() -> NewSentence:
    """åˆ›å»ºæµ‹è¯•å¥å­"""
    tokens = [
        Token(token_body="Learning", token_type="text", difficulty_level="easy", global_token_id=1, sentence_token_id=1, pos_tag="VERB", lemma="learn", is_grammar_marker=False, linked_vocab_id=None),
        Token(token_body="a", token_type="text", difficulty_level="easy", global_token_id=2, sentence_token_id=2, pos_tag="DET", lemma="a", is_grammar_marker=False, linked_vocab_id=None),
        Token(token_body="new", token_type="text", difficulty_level="easy", global_token_id=3, sentence_token_id=3, pos_tag="ADJ", lemma="new", is_grammar_marker=False, linked_vocab_id=None),
        Token(token_body="language", token_type="text", difficulty_level="easy", global_token_id=4, sentence_token_id=4, pos_tag="NOUN", lemma="language", is_grammar_marker=False, linked_vocab_id=None),
        Token(token_body="is", token_type="text", difficulty_level="easy", global_token_id=5, sentence_token_id=5, pos_tag="AUX", lemma="be", is_grammar_marker=True, linked_vocab_id=None),
        Token(token_body="challenging", token_type="text", difficulty_level="hard", global_token_id=6, sentence_token_id=6, pos_tag="ADJ", lemma="challenging", is_grammar_marker=False, linked_vocab_id=1),
        Token(token_body="but", token_type="text", difficulty_level="easy", global_token_id=7, sentence_token_id=7, pos_tag="CCONJ", lemma="but", is_grammar_marker=False, linked_vocab_id=None),
        Token(token_body="rewarding", token_type="text", difficulty_level="hard", global_token_id=8, sentence_token_id=8, pos_tag="ADJ", lemma="rewarding", is_grammar_marker=False, linked_vocab_id=2)
    ]
    
    return NewSentence(
        text_id=1,
        sentence_id=1,
        sentence_body="Learning a new language is challenging but rewarding.",
        grammar_annotations=(),
        vocab_annotations=(),
        sentence_difficulty_level="medium",
        tokens=tuple(tokens)
    )

def example_full_workflow():
    """å®Œæ•´å·¥ä½œæµç¨‹ç¤ºä¾‹"""
    print("ğŸš€ SelectedToken å®Œæ•´å·¥ä½œæµç¨‹ç¤ºä¾‹")
    print("=" * 80)
    
    # 1. åˆå§‹åŒ–é›†æˆç³»ç»Ÿ
    print("\nğŸ“‹ æ­¥éª¤1: åˆå§‹åŒ–é›†æˆç³»ç»Ÿ")
    print("-" * 50)
    
    system = IntegratedLanguageSystem()
    print("âœ… é›†æˆç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
    
    # 2. å¤„ç†æ–‡ç« 
    print("\nğŸ“‹ æ­¥éª¤2: å¤„ç†æ–‡ç« ")
    print("-" * 50)
    
    article_text = create_sample_article()
    print(f"ğŸ“– æ–‡ç« å†…å®¹: {article_text[:100]}...")
    
    try:
        result = system.process_article(article_text, "Language Learning Article")
        print("âœ… æ–‡ç« å¤„ç†å®Œæˆ")
        print(f"   å¤„ç†ç»“æœ: {result}")
    except Exception as e:
        print(f"âŒ æ–‡ç« å¤„ç†å¤±è´¥: {e}")
        return
    
    # 3. è·å–å¥å­åˆ—è¡¨
    print("\nğŸ“‹ æ­¥éª¤3: è·å–å¥å­åˆ—è¡¨")
    print("-" * 50)
    
    sentences = system.get_article_sentences(1)  # å‡è®¾æ–‡ç« IDä¸º1
    if not sentences:
        print("âš ï¸ æ²¡æœ‰æ‰¾åˆ°å¥å­ï¼Œä½¿ç”¨æµ‹è¯•å¥å­")
        sentences = [create_test_sentence()]
    
    target_sentence = sentences[0]
    print(f"ğŸ¯ ç›®æ ‡å¥å­: {target_sentence.sentence_body}")
    
    # 4. æµ‹è¯•ä¸åŒç±»å‹çš„æé—®
    print("\nğŸ“‹ æ­¥éª¤4: æµ‹è¯•ä¸åŒç±»å‹çš„æé—®")
    print("-" * 50)
    
    # 4.1 æ•´å¥æé—®
    print("\nğŸ” 4.1 æ•´å¥æé—®")
    print("-" * 30)
    
    try:
        system.process_and_ask(
            sentence=target_sentence,
            question="è¿™å¥è¯çš„æ•´ä½“æ„æ€æ˜¯ä»€ä¹ˆï¼Ÿ"
        )
        print("âœ… æ•´å¥æé—®æˆåŠŸ")
    except Exception as e:
        print(f"âŒ æ•´å¥æé—®å¤±è´¥: {e}")
    
    # 4.2 ç‰¹å®šå•è¯æé—®
    print("\nğŸ” 4.2 ç‰¹å®šå•è¯æé—®")
    print("-" * 30)
    
    try:
        system.process_and_ask(
            sentence=target_sentence,
            question="challengingæ˜¯ä»€ä¹ˆæ„æ€ï¼Ÿ",
            selected_text="challenging"
        )
        print("âœ… ç‰¹å®šå•è¯æé—®æˆåŠŸ")
    except Exception as e:
        print(f"âŒ ç‰¹å®šå•è¯æé—®å¤±è´¥: {e}")
    
    # 4.3 çŸ­è¯­æé—®
    print("\nğŸ” 4.3 çŸ­è¯­æé—®")
    print("-" * 30)
    
    try:
        system.process_and_ask(
            sentence=target_sentence,
            question="challenging but rewardingè¿™ä¸ªçŸ­è¯­æ€ä¹ˆç†è§£ï¼Ÿ",
            selected_text="challenging but rewarding"
        )
        print("âœ… çŸ­è¯­æé—®æˆåŠŸ")
    except Exception as e:
        print(f"âŒ çŸ­è¯­æé—®å¤±è´¥: {e}")
    
    # 4.4 è¯­æ³•ç»“æ„æé—®
    print("\nğŸ” 4.4 è¯­æ³•ç»“æ„æé—®")
    print("-" * 30)
    
    try:
        system.process_and_ask(
            sentence=target_sentence,
            question="è¿™é‡Œçš„butæ˜¯ä»€ä¹ˆç”¨æ³•ï¼Ÿ",
            selected_text="but"
        )
        print("âœ… è¯­æ³•ç»“æ„æé—®æˆåŠŸ")
    except Exception as e:
        print(f"âŒ è¯­æ³•ç»“æ„æé—®å¤±è´¥: {e}")
    
    # 5. æŸ¥çœ‹ç»“æœ
    print("\nğŸ“‹ æ­¥éª¤5: æŸ¥çœ‹å¤„ç†ç»“æœ")
    print("-" * 50)
    
    # è·å–è¯æ±‡åˆ—è¡¨
    vocab_list = system.get_vocab_list()
    print(f"ğŸ“š è¯æ±‡åˆ—è¡¨: {vocab_list}")
    
    # è·å–è¯­æ³•è§„åˆ™
    grammar_rules = system.get_grammar_rules()
    print(f"ğŸ“– è¯­æ³•è§„åˆ™: {grammar_rules}")
    
    print("\nğŸ‰ å®Œæ•´å·¥ä½œæµç¨‹ç¤ºä¾‹å®Œæˆï¼")
    print("=" * 80)

def example_selected_token_creation():
    """SelectedTokenåˆ›å»ºç¤ºä¾‹"""
    print("\nğŸ”§ SelectedToken åˆ›å»ºç¤ºä¾‹")
    print("=" * 60)
    
    sentence = create_test_sentence()
    print(f"ğŸ“– æµ‹è¯•å¥å­: {sentence.sentence_body}")
    
    # ç¤ºä¾‹1: æ•´å¥é€‰æ‹©
    print("\nğŸ“‹ ç¤ºä¾‹1: æ•´å¥é€‰æ‹©")
    full_token = SelectedToken.from_full_sentence(sentence)
    print(f"   é€‰æ‹©çš„æ–‡æœ¬: {full_token.token_text}")
    print(f"   tokenç´¢å¼•: {full_token.token_indices}")
    print(f"   æ˜¯å¦æ•´å¥: {full_token.is_full_sentence()}")
    
    # ç¤ºä¾‹2: ç‰¹å®šå•è¯é€‰æ‹©
    print("\nğŸ“‹ ç¤ºä¾‹2: ç‰¹å®šå•è¯é€‰æ‹©")
    word_token = create_selected_token_from_text(sentence, "challenging")
    print(f"   é€‰æ‹©çš„æ–‡æœ¬: {word_token.token_text}")
    print(f"   tokenç´¢å¼•: {word_token.token_indices}")
    print(f"   æ˜¯å¦å•ä¸ªtoken: {word_token.is_single_token()}")
    
    # ç¤ºä¾‹3: çŸ­è¯­é€‰æ‹©
    print("\nğŸ“‹ ç¤ºä¾‹3: çŸ­è¯­é€‰æ‹©")
    phrase_token = create_selected_token_from_text(sentence, "challenging but rewarding")
    print(f"   é€‰æ‹©çš„æ–‡æœ¬: {phrase_token.token_text}")
    print(f"   tokenç´¢å¼•: {phrase_token.token_indices}")
    print(f"   tokenæ•°é‡: {phrase_token.get_token_count()}")
    
    # ç¤ºä¾‹4: è½¬æ¢ä¸ºå­—å…¸
    print("\nğŸ“‹ ç¤ºä¾‹4: è½¬æ¢ä¸ºå­—å…¸")
    dict_data = word_token.to_dict()
    print(f"   å­—å…¸æ ¼å¼: {dict_data}")
    
    print("\nğŸ‰ SelectedToken åˆ›å»ºç¤ºä¾‹å®Œæˆï¼")
    print("=" * 60)

def interactive_demo():
    """äº¤äº’å¼æ¼”ç¤º"""
    print("\nğŸ® äº¤äº’å¼æ¼”ç¤º")
    print("=" * 60)
    
    system = IntegratedLanguageSystem()
    sentence = create_test_sentence()
    
    print(f"ğŸ“– ç¤ºä¾‹å¥å­: {sentence.sentence_body}")
    print("è¯·è¾“å…¥ä½ çš„é—®é¢˜ (è¾“å…¥ 'quit' é€€å‡º):")
    
    while True:
        question = input("\nâ“ é—®é¢˜: ").strip()
        
        if question.lower() in ['quit', 'exit', 'é€€å‡º']:
            break
        
        if not question:
            continue
        
        # è¯¢é—®æ˜¯å¦é€‰æ‹©ç‰¹å®šæ–‡æœ¬
        selected_text = input("ğŸ¯ é€‰æ‹©çš„æ–‡æœ¬ (ç›´æ¥å›è½¦è¡¨ç¤ºæ•´å¥): ").strip()
        if not selected_text:
            selected_text = None
        
        try:
            if selected_text:
                print(f"ğŸ¯ åˆ†æé€‰æ‹©çš„æ–‡æœ¬: '{selected_text}'")
            else:
                print("ğŸ“– åˆ†ææ•´å¥è¯")
            
            system.process_and_ask(
                sentence=sentence,
                question=question,
                selected_text=selected_text
            )
            
        except Exception as e:
            print(f"âŒ å¤„ç†å¤±è´¥: {e}")
    
    print("\nğŸ‘‹ å†è§ï¼")

if __name__ == "__main__":
    # è¿è¡Œç¤ºä¾‹
    example_selected_token_creation()
    example_full_workflow()
    
    # è¯¢é—®æ˜¯å¦è¿è¡Œäº¤äº’å¼æ¼”ç¤º
    choice = input("\næ˜¯å¦è¿è¡Œäº¤äº’å¼æ¼”ç¤ºï¼Ÿ(y/n): ").strip().lower()
    if choice in ['y', 'yes', 'æ˜¯']:
        interactive_demo() 